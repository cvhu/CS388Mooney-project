The identification of hidden data, such as feature-based control points in an image, from a set of observable data, such as the image, is achieved through a two-stage approach. The first stage involves a learning process, in which a number of sample data sets, e.g. images, are analyzed to identify the correspondence between observable data, such as visual aspects of the image, and the desired hidden data, such as the control points. Two models are created. A feature appearance-only model is created from aligned examples of the feature in the observed data. In addition, each labeled data set is processed to generate a coupled model of the aligned observed data and the associated hidden data. In the image processing embodiment, these two models might be affine manifold models of an object's appearance and of the coupling between that appearance and a set of locations on the object's surface. In the second stage of the process, the modeled feature is located in an unmarked, unaligned data set, using the feature appearance-only model. This location is used as an alignment point and the coupled model is then applied to the aligned data, giving an estimate of the hidden data values for that data set. In the image processing example, the object's appearance model is compared to different image locations. The matching locations are then used as alignment points for estimating the locations on the object's surface from the appearance in that aligned image and form the coupled model.
Claims What is claimed is: 1. A method for determining continuous-valued hidden data from observable data, comprising the steps of: A) conductive a training stage which includes the steps of: labelling a plurality of representative sets of unaligned observed data to identify correct alignment of the observed data and continuous-valued hidden data associated with each set of observed data; analyzing the observed data to generate a first model which represents the aligned observed data; analyzing the aligned and labelled data sets to generate a second model which explicitly represents the coupling between aligned observable data and the hidden data; B) for each set of unlabelled data, conducting a labelling stage which includes the steps of: analyzing the unlabelled set of unaligned observed data by means of the first model to determine alignment of the observable data associated therewith; applying the second model to said unlabelled set of aligned observed data; and determining hidden data for the unlabelled set of aligned data from said application of the second model. 2. The method of claim 1 wherein each set of unaligned observed data defines an image. 3. The method of claim 2 wherein said hidden data comprises control points which relate to fiduciary points on objects in an image. 4. The method of claim 3 wherein at least some of said control points relate to fiduciary points on obscured portions of objects in the images. 5. The method of claim 3 wherein control points are determined for at least two new images, and further including the step of morphing between said new images in accordance with the determined control points. 6. The method of claim 3 further including the step of creating a composite image by incorporating a new image into another image by means of the determined control points for each of the two images. 7. The method of claim 3 wherein said images include faces, and further including the step of analyzing the control points to recognize a known face in an image. 8. The method of claim 3 wherein said images comprise cartoons. 9. The method of claim 3 wherein said images include faces, and further including the step of analyzing the control points to recognize an expression on a face in an image. 10. The method of claim 3, further including the step of controlling a robot to grasp an object in accordance with the fiduciary points that are labeled in the image of the object. 11. The method of claim 1 wherein said sets of unaligned observed data comprise a sequence of video images. 12. The method of claim 11 further including the step of analyzing determined control points in said sequence of video images to recognize movement of an object in the images. 13. The method of claim 12 wherein said movement comprises nearly periodic motion. 14. The method of claim 1 wherein said sets of unaligned observed data comprise audio signals. 15. The method of claim 1 wherein said first model is derived from the results of the analysis that is used to generate the second model, such that computations are shared in the use of the two models. 16. The method of claim 1 further including the steps of selecting a plurality of said representative sets of data, using hidden data in said plurality of data sets to automatically generate interpolated data sets that are based on said plurality of data sets and that include both observable and hidden data, and including said interpolated data sets in the plurality of representative data sets that are analyzed to generate said second model. 17. The method of claim 16 wherein said second model is a multifaceted model, and said interpolated data sets are at the boundaries of facets in said second model. 18. The method of claim further including the steps of selecting a plurality of said representative sets of data, using hidden data in said plurality of data sets to automatically generate interpolated data sets that are based on said plurality of data sets and that contain observable data, and including said interpolated data sets in the plurality of representative data sets that are analyzed to generate said first model. 19. The method of claim 18 wherein said first model is a multifaceted model, and said interpolated data sets are at the boundaries of facets in said first model. 20. The method of claim 1 wherein said second model is a manifold model. 21. The method of claim 20 wherein said second model is an affine manifold model. 22. The method of claim 21 wherein the step of applying the second model to the unlabelled set of aligned observed data includes performing an orthonormal projection of the aligned observed unlabeled data onto a first space of the second mode; scaling the coordinates of the projected location in the first space in accordance with said second model; and performing an orthonormal projection into a second space of the second model to determine hidden data for the unlabelled data set. 23. The method of claim 22 wherein said scaling includes modification of the coordinates of said location in accordance with estimated noise levels in the unlabelled aligned observed data set to which said second model is applied. 24. The method of claim 1 wherein said first model is a manifold model. 25. The method of claim 21 wherein said first model is an affine manifold model. 26. The method of claim 24 wherein the step of aligning the observed data in an unlabelled data set comprises the steps of: i) selecting possible locations for the alignment of the data; ii) for each possible location, determining a lower bound for the distance between the unlabelled data set aligned at that location and an expected appearance of aligned data, in accordance with an average appearance defined by the first model; iii) removing the possible locations whose lower bound exceeds a threshold value; iv) for each possible location, determining the coordinate value for a dimension of the first model; v) for each possible location, determining a new lower bound by combining previously determined coordinate values with the distance between the data set aligned at that location and the appearance of the data set under said alignment in accordance with the previously determined coordinate values; and vi) repeating steps iii), iv) and v) for all of the dimensions of the model. 27. The method of claim 26 wherein said lower bounds are determined in accordance with expected variances along each of the dimensions of the manifold model. 28. The method of claim 27 wherein said expected variances are progressively smaller on each successive repetition of said steps. 29. The method of claim 25 wherein the step of applying the second model to the unlabelled set of aligned observed data includes projecting, with the use of an orthonormal transform, the aligned observed unlabeled data onto a subspace of the second model having fewer dimensions than said second model; performing a general matrix multiplication within said subspace; and projecting, with the use of an orthonormal transform, into a second space of the model to determine hidden data for the unlabelled data set. 30. The method of claim 29 wherein said general matrix multiplication is determined, in part, according to a gradual roll-off in manifold dimensions according to relative signal-plus-noise strength in the hidden and aligned observed data that is used to generate said second model. 31. The method of claim 25 wherein the step of applying the second model to the unlabelled set of aligned observed data includes: approximating a projection of the aligned observed unlabeled data onto a subspace of the second model by taking the dot product of renormalized basis vectors that correspond to dimensions of the observed data in the second model with the aligned unlabelled observed data; and approximating a projection into a second space of the model by using the hidden dimensions of the basis vectors with the same scaling. 32. The method of claim 1 wherein said representative data sets are normalized to provide uniform expected energy across both the hidden and observed dimensions of the aligned data, and said second model minimizes expected error relative to the normalized data set. 33. The method of claim 32 wherein said second model minimizes expected error with respect to hidden data. 34. The method of claim 1 further including the step defining the alignment of the observed data in the representative sets of data from an analysis of the hidden data with which the data sets are labelled. 35. The method of claim 34 wherein an analysis of the observed data is also employed in said alignment process. 36. The method of claim 34 wherein said defining step comprises dividing the hidden data into separate groups, and assigning a different definition of aligned observed data in each representative data set to the respective groups. 37. The method of claim 36 wherein the division of the hidden data into separate groups is determined in accordance with analysis of the hidden data. 38. The method of claim 36 wherein the definition of aligned observed data is determined in accordance with analysis of the hidden data. 39. The method of claim 38 wherein the definition of aligned observed data is also determined in accordance with analysis of the observed data. 40. The method of claim 37 wherein the observed data is also used to divide the hidden data into said groups. 41. The method of claim 37 wherein the division of hidden data into groups is carried out by measuring the coherence of the hidden data. 42. The method for establishing a relationship between at least two unlabelled images, comprising the steps of: A) conducting a training stage which includes the steps of: analyzing a plurality of representative labelled images to generate a model which identifies specific locations on one or more objects based on pixel values within each image; B) for each set of unlabeled images to be compared, conducting a model application stage which includes the steps of: matching each of said unlabelled images to the model to identify locations on objects within each unlabelled image; and determining correspondence between the unlabeled images based on the identified locations. 43. A method for establishing a relationship between at least two unlabelled images, comprising the steps of: A) conducting a training stage which includes the steps of: analyzing a first set of labelled images to generate a first model which identifies specific locations on one or more objects based on pixel values within each image of said first set; analyzing a second set of labeled images to generate a second model which identifies specific locations on one or more objects based on pixel values within each image of said second set; establishing a mapping between identified locations in said first model and identified location in said second model; B) for each set of images to be compared, conducting a model application stage which includes the steps of: matching a first unlabelled image to the first model to identify locations on objects in said first image; matching a second unlabelled image to the second model to identify locations on objects in said second image; and determining correspondence between the first and second unlabelled images based on the identified locations in each image and said mapping. 44. A method for indexing data into a multi-faceted model using a single-faceted global manifold model to which the data relates, comprising the steps of: A) conducting a training stage which includes the steps of: generating a single-faceted global manifold model from a plurality of examples of the data, wherein said global manifold model encompasses all examples of the data; generating a multi-faceted manifold model from divisions of the examples of data, wherein each facet encompasses a local set of examples of the data; B) for each new set of data, conducting a model indexing stage which includes the steps of: applying said global manifold model to the new set of data; deriving a coordinate vector from said application of the global manifold model to said set of data; and indexing said data into said multi-faceted model from said global manifold model in accordance with said coordinate vector. 45. The method of claim 44 wherein said multi-faceted model is a piecewise affine model. 46. The method of claim 44 wherein said global manifold model is an affine manifold model. 47. The method of claim 44 wherein said coordinate vector is a non-uniform quantization of coordinates of the global manifold model. 48. The method of claim 47 further including the step of merging similar model facets in neighboring quantization sections of said multifaceted model according to a fitness function. 49. The method of claim 48 wherein said multi-faceted model identifies coupling between observable data and hidden data, and said fitness function is based on resulting hidden data error. 50. The method of claim 48 further including the step of using a hashing function to map quantization coordinates into a table index, where the size of the table is smaller than the total number of quantization cells. 51. The method of claim 44 wherein said multi-faceted model is also a manifold model. 52. The method of claim 44 wherein said data comprises observable data in an image. 53. The method of claim 44 wherein said multi-faceted model identifies coupling between observable data and hidden data. 54. The method of claim 53 wherein said multi-faceted model is segmented into spaces which respectively relate to said facets, and wherein said segmentation is based upon coordinates for said single-faceted global model. 55. The method of claim 54 wherein said segmentation is defined by non-uniform quantization of the coordinates of the single-faceted global model. 56. The method of claim 55 wherein boundaries for said quantization are determined according to errors in the reconstruction of hidden data on the multi-faceted model. 57. A model for aligning observed data to a manifold model, comprising the steps of: i) selecting possible locations for the alignment of the data within an unaligned set of data; ii) for each possible location, determining a lower bound for the distance between the unaligned data set aligned at that location and an expected appearance of aligned data, in accordance with an average appearance defined by said model; iii) removing the possible locations whose lower bound exceeds a threshold value; iv) for each possible location, determining the coordinate value for a dimension of the model; v) for each possible location, determining a new lower bound by combining previously determined coordinate values with the distance between the data set aligned at that location and the appearance of the data set under said alignment in accordance with the previously determined coordinate values; and vi) repeating steps iii), iv) and v) for all of the dimensions of the model. 58. The method of claim 57 wherein said lower bounds are determined in accordance with expected variances along each of the dimensions of the model. 59. The method of claim 58 wherein said expected variances are progressively smaller on each successive repetition of said steps. 