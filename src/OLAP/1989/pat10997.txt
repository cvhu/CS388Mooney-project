A method and device for improving orientation and/or location accuracy of a programmable robot with respect to a target object. The method consists of calibrating the position of a terminal control frame associated with a robot end-effector which is coupled to a robot distal link. Separated reference positions external from the robot are identified, as to geometry and spatial data. This identification data is stored for later recall and comparison for use in determining a localized relative frame of reference. The robot end-effector is moved to a first reference position and a rigid body error correction is determined. This correction is stored in computer memory for application to later computer movement.
Claims We claim: 1. A method for calibrating the position of a terminal control frame of a robot end-effector such as a camera or gripping device which is coupled to a robot distal link having a robot distal frame and being subject to control of a computer data processing and storage means, said method comprising the steps of: (a) attaching pointing means having a pointing end to the robot distal link such that the pointing means is aligned parallel with a z-axis of the robot distal frame; (b) selecting a first reference point in a space removed from the robot but within an operating distance; (c) moving the robot to a first pose wherein the pointing end of the pointing means is located at the first reference point; (d) storing robot positioning data representing the first robot pose of step "c" in the computer means for later recall and comparison; (e) attaching the end-effector to the distal link; (f) identifying a reference point on the end-effector; (g) moving the robot to a second pose wherein the end-effector reference point is located at the first reference point; (h) storing robot positioning data representing the second robot pose of step "g" in the computer means for later recall and comparison; (i) comparing the stored positioning data of steps "d" and "h" for detection of differences; (j) processing detected differences within the computer means to define offset position of the terminal control frame with respect to the robot distal frame. 2. A method as defined in claim 1, comprising the more specific steps of: attaching to the distal link an elongate pointer having a distal contact end; identifying a first reference point on a fixed target object; and moving the robot to a first pose wherein the contacting end of the pointer is located at the first reference point on the target object. 3. A method as defined in claim 1, comprising the further steps of: (k) selecting an additional reference point in a space removed from the robot but within an operating distance; (l) moving the robot to a first pose wherein the pointing end of the pointing means is located at said additional reference point; (m) storing robot positioning data representing the first robot pose of step "l" in the computer means for later recall and comparison; (n) moving the robot to a second pose wherein the end-effector reference point is located at the first reference point; (o) storing robot positioning data representing the second robot pose of step "n" in the computer means for later recall and comparison; (p) comparing the stored positioning data of steps "m" and "o" for detection of differences; (q) processing the detected differences of step "p" within the computer means to define an offset position of the terminal control frame with respect to the robot distal frame. 4. A method as defined in claim 3, wherein the stated steps are repeated a sufficient number of times to develop a statistical base of difference values which may be processed to define a more accurate definition of the offset position of the terminal control frame. 5. A method as defined in claim 1 for calibrating relative orientation of the terminal control frame of a robot end effector with respect to the robot distal frame, comprising the steps of: (aa) selecting a second reference point in a space removed from the robot but within an operating distance; (bb) moving the robot to a first pose wherein the pointing end of the pointing means is located at the second reference point; (cc) storing robot positioning data representing the first robot pose of step "bb" in the computer means for later recall and comparison; (dd) processing the stored positioning data for the first and second reference points to identify an orientation vector for a line connecting the first and second reference points; (ee) storing vector orientation data relating to the terminal control frame in the computer means for later recall and processing; (ff) moving the robot to a third pose such that the orientation of the vector relative to terminal control frame can be defined; (gg) storing robot positioning data representing the third robot pose of step "ff" in the computer means for later recall and comparison; and (hh) processing the stored data to define the relative orientation of the terminal control frame with respect to the terminal distal frame. 6. A method as defined in claim 5, further comprising the additional steps of repeating movement, storing and processing steps as defined in claim 5 with respect to other robot poses to define additional statistical base for improvement for accuracy orientation definition. 7. A method for improving orientation and/or location accuracy of a programmable robot with respect to a target, said method comprising the steps of: (a) positioning the robot with respect to the target, said robot having a terminal operating end-effector, said robot being capable of movement between a variety of different positions with respect to the target; (b) identifying a plurality of separated reference positions external from the robot; (c) developing identification data defining geometries and spatial data of the separated reference positions relative to the target; (d) storing the identification data for each respective reference position within a data processing unit for recall and comparison by the robot upon later excursion to a location near such reference position; (e) moving the robot end-effector to a first location near one of the reference positions, referred to herein as the calibration position, wherein a sensor coupled to the robot detects the presence of the calibration position; (f) comparing the detected calibration position with the originally stored information data relating to that position; (g) developing a rigid body error correction based on position differences detected in the previous comparison step, said correction to be used with respect to later moves of the robot relative to the calibration position; (h) storing the rigid body error correction within the data processing unit; (i) moving the end-effector to a second reference position utilizing the originally stored identification data regarding the second reference position and applying the rigid body correction developed with respect to the calibration position to more accurately predict proper placement of the robot in approximate vicinity to the second reference position. 8. A method as defined in claim 7, comprising the additional steps of: (j) detecting the second reference position; (k) comparing the detected second reference position with respect to the predicted second position to which the robot has been moved in step "i" (l) detecting differences between the predicted position and actual position of the second reference position detected in step "j"; (m) processing the detected differences to define the amount of correction required to properly position the end-effector at subsequent reference positions; (n) storing the defined correction within the data processing unit. 9. A method as defined in claim 8, further comprising the additional steps of repeating movement, detection, storing and processing steps as set forth in claim 8 with respect to additional reference positions to define a statistical base for accurately quantifying and averaging position deviation between predicted and actual positions of subsequent reference positions. 10. A method as defined in claim 9, further comprising the initial step of quantifying and storing identification data within the data processing unit regarding geometric configuration and orientation of each reference feature on the target object, as well as their relative separation and orientation between features, for later recall and comparison upon actual detection of each reference feature as a reference position. 11. A method as defined in claim 8, further comprising the additional steps of repeating movement, detection, storing and processing steps as set forth in claim 8 with respect to additional reference positions to define parameters of an analytical model to enable accurate prediction of robot position with respect to subsequent reference positions. 12. A method as defined in claim 7, wherein step "b" comprises the more specific step of identifying a plurality of separated reference features external from the robot which, are positioned on a target object. 13. A method for mapping robot inaccuracy of a programmable robot, said method comprising the steps of: (a) preparing a target object having a plurality of identifiable features thereon which can serve as reference points for mapping; (b) developing a feature database defining geometries and spatial relationships of the features on the object in sufficient detail to enable individual recognition of each feature; (c) storing the feature database in a computer for later recall and comparison; (d) positioning the target object within operational reach of a distal link of the robot; (e) attaching sensing means at the distal link capable of detecting the stored features based on a comparison of sensory data with data in the feature database; (f) calibrating the sensing means with respect to the distal link to accurately define relative positioning of a distal frame with respect to a terminal control frame of the sensing means; (g) storing the calibrated terminal control frame position within the computer for later recall and comparison; (h) preparing a routine which correlates stored feature database information with the calibrated terminal control frame position and provides drive commands to the robot for moving the sensing means sequentially to predicted positions of the respective features; (i) activating the routine to move the sensing means to a calibrating feature comprising one of the stored features on the target object; (j) defining the relative pose error of the actual position of the sensing means with respect to the predicted position to provide rigid body correction data; (k) storing the rigid body correction data within the computer for later recall and comparison; (l) correlating the stored rigid body correction data with the prepared routine to define a new predicted position for a next feature to which the sensing means will be moved; (m) moving the sensing means to the new predicted location of next feature; (n) defining the relative pose error of the actual position of the sensing means with respect to the new predicted position; (o) storing the error data of step "n" within the computer for later recall and comparison; (p) repeating steps l through o with respect to each subsequent feature to develop a map of the target object based on error data measured; (q) processing the map error data to define an expression representing robot inaccuracy. 14. A method for improving orientation and/or location accuracy of a programmable robot with respect to an operation to be performed on a target object, said method comprising the steps of: (a) preparing a routine which provides drive commands to the robot for moving an attached sensing means to an approximate position of a desired feature on the target object; (b) calibrating a sensory reference frame which defines a relative position for the sensing means with respect to the robot; (c) activating the routine such that the robot sensing means detects the feature and produces sensory data regarding feature position; (d) develop a transformation matrix which relates position of the feature to the sensory reference frame; (e) determine a sensory frame pose for the robot based on the matrix of step "d", sensory reference frame position and geometry of the feature; (f) determine a set of joint coordinates for the robot corresponding to the sensor frame pose; (g) identifying control points along a path of operation representing regions of movement limitation for the robot; (h) modifying the routine and defined path of operation with control points to maintain path conformity for free movement of the robot; and (i) activating the modified routine to perform the operation. 15. A method for improving orientation and/or location accuracy of a programmable robot with respect to a target, said method comprising the steps of: (a) calibrating the position of a terminal control frame of a robot end-effector which is coupled to a robot distal link having a robot distal frame to define their relative position and orientation; (b) identifying a plurality of separated reference positions external from the robot; (c) developing identification data defining geometries and spatial data of the separated reference positions relative to the target; (d) storing the identification data for each respective reference position within a data processing unit for recall and comparison by the robot upon later excursion to a location near such reference position; (e) moving the robot end-effector to a first location near one of the reference positions, referred to herein as the calibration position, wherein a sensor coupled to the robot detects the presence of the calibration position; (f) comparing the detected calibration position with the originally stored information data relating to that position; (g) developing a rigid body error correction based on position differences detected in the previous comparison step, said correction to be used with respect to later moves of the robot relative to the calibration position; (h) storing the rigid body error correction within the data processing unit; (i) moving the end-effector to a second reference position utilizing the originally stored identification data regarding the second reference position and applying the rigid body correction developed with respect to the calibration position to more accurately predict proper placement of the robot in approximate vicinity to the second reference position. 