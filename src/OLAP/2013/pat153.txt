In a multi-participant modeled virtual reality environment, avatars are modeled beings that include moveable eyes creating the impression of an apparent gaze direction. Control of eye movement may be performed autonomously using software to select and prioritize targets in a visual field. Sequence and duration of apparent gaze may then be controlled using automatically determined priorities. Optionally, user preferences for object characteristics may be factored into determining priority of apparent gaze. Resulting modeled avatars are rendered on client displays to provide more lifelike and interesting avatar depictions with shifting gaze directions.
Claims What is claimed is: 1. A method for animating an avatar's gaze, the method comprising: providing a digital representation of an avatar including at least one modeled eye and a modeled scene in a computer memory; determining a field of view for the modeled eye of the avatar, wherein the field of view encompasses visual targets in the modeled scene; directing the modeled eye to gaze at different selected visual targets in the field of view in an automated sequence of changing gaze directions determined at least in part on respective attractiveness values for each of the visual targets; determining the respective attractiveness values based at least in part on predefined user preferences for specified characteristics of prospective visual targets; and outputting data configured to cause a client computer to display a rendered view of the modeled scene, avatar and modeled eye. 2. The method of claim 1, further comprising determining the respective attractiveness values based on a measure of movement of corresponding ones of the visual targets within the field of view. 3. The method of claim 1, further comprising determining the respective attractiveness values based on a measure of sound associated with the visual target. 4. The method of claim 1, further comprising determining the respective attractiveness values based on a geometrical relationship between each visual target and the modeled eye. 5. The method of claim 1, further comprising determining respective durations of gaze directed at each of the selected visual targets in the automated sequence, based on the respective attractiveness values. 6. The method of claim 1, further comprising including in the predefined user preferences values for any one or more of the specified characteristics selected from the group consisting of gender, sexual orientation, race, hair color, eye color, body type, and clothes. 7. The method of claim 1, further comprising fixing the respective attractiveness values for each visual target. 8. The method of claim 1, further comprising varying the respective attractiveness values for each visual target based on changing attributes of each visual target during modeling of the scene. 9. The method of claim 8, further comprising determining the attractiveness value based on a current location of the visual targets in relation to the avatar, wherein at least one of the visual targets and the avatar are in motion relative to one another. 10. The method of claim 1, further comprising determining the attractiveness value of the selected visual targets based at least in part on weighting features of the visual targets according to the predefined user preferences. 11. A non-transitory computer-readable storage medium encoded with instructions operative to cause a computer to perform the steps of: generating a digital representation of an avatar including at least one modeled eye and a modeled scene in a computer memory; determining a field of view for the modeled eye of the avatar, wherein the field of view encompasses visual targets in the modeled scene; directing the modeled eye to gaze at different selected visual targets in the field of view in an automated sequence of changing gaze directions determined at least in part on respective attractiveness values for each of the visual targets; determining the respective attractiveness values based at least in part on predefined user preferences for specified characteristics of prospective visual targets; and outputting data configured to cause a client computer to display a rendered view of the modeled scene, avatar and modeled eye. 12. The non-transitory computer-readable storage medium of claim 11, encoded with further instructions for determining the respective attractiveness values based on a measure of movement of corresponding ones of the visual targets within the field of view. 13. The non-transitory computer-readable storage medium of claim 11, encoded with further instructions for determining the respective attractiveness values based on a measure of sound associated with the visual target. 14. The non-transitory computer-readable storage medium of claim 11, encoded with further instructions for determining the respective attractiveness values based on a geometrical relationship between each visual target and the modeled eye. 15. The non-transitory computer-readable storage medium of claim 11, encoded with further instructions for determining respective durations of gaze directed at each of the selected visual targets in the automated sequence, based on the respective attractiveness values. 16. The non-transitory computer-readable storage medium of claim 11, encoded with further instructions for including in the predefined user preferences values for any one or more of the specified characteristics selected from the group consisting of gender, sexual orientation, race, hair color, eye color, body type, and clothes. 17. The non-transitory computer-readable storage medium of claim 11, encoded with further instructions for fixing the respective attractiveness values for each visual target. 18. The non-transitory computer-readable storage medium of claim 11, encoded with further instructions for varying the respective attractiveness values for each visual target based on changing attributes of each visual target during modeling of the scene. 19. The non-transitory computer-readable storage medium of claim 18, encoded with further instructions for determining the attractiveness value based on a current location of the visual targets in relation to the avatar, wherein at least one of the visual targets and the avatar are in motion relative to one another. 20. The non-transitory computer-readable storage medium of claim 11, encoded with further instructions for determining the attractiveness value of the selected visual targets based at least in part on weighting features of the visual targets according to the predefined user preferences. 