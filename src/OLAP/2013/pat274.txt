A robotic system includes a humanoid robot having a plurality of joints adapted for force control with respect to an object acted upon by the robot, a graphical user interface (GUI) for receiving an input signal from a user, and a controller. The GUI provides the user with intuitive programming access to the controller. The controller controls the joints using an impedance-based control framework, which provides object level, end-effector level, and/or joint space-level control of the robot in response to the input signal. A method for controlling the robotic system includes receiving the input signal via the GUI, e.g., a desired force, and then processing the input signal using a host machine to control the joints via an impedance-based control framework. The framework provides object level, end-effector level, and/or joint space-level control of the robot, and allows for functional-based GUI to simplify implementation of a myriad of operating modes.
Claims The invention claimed is: 1. A robotic system comprising: a humanoid robot having a plurality of robotic joints and end-effectors adapted for imparting a force to an object; a graphical user interface (GUI) adapted for receiving an input signal from a user describing at least a reference external force in the form of a desired input force to be imparted to the object, wherein the GUI includes a Cartesian space of inputs, a joint space of inputs, and a selectable qualitative impedance level; and a controller that is electrically connected to the GUI, wherein the GUI provides the user with programming access to the controller and allows the user to switch between position control and force control of the humanoid robot solely by selecting the reference external force, and between impedance control on the object, end-effector, and joint level solely by selecting a desired combination of the end-effectors. 2. The system of claim 1, wherein the GUI graphically displays each of the Cartesian space of inputs and the joint space of inputs for each of a left side node and a right side node of the humanoid robot. 3. The system of claim 1, wherein the controller is adapted to parameterize a predetermined set of internal forces of the humanoid robot in the object-level of control to thereby allow for multiple grasp types in real-time, the multiple grasp types including at least a rigid contact grasp type and a point contact grasp type. 4. The system of claim 1, wherein the GUI is a functional-based device that uses the Cartesian space of inputs, the joint space of inputs, and the qualitative impedance level as a set of intuitive inputs,. and a layer of interpretive logic that deciphers the input into the GUI by applying the correct control objectives and mode of operation, to command all joints in the humanoid robot with a set of impedance commands for at least one of the object, the end-effector, and the joint space level of control. 5. The system of claim 1, wherein the controller is adapted for executing hybrid force and position control in the Cartesian space by projecting a stiffness term of an impedance relationship into a null space orthogonally to the received reference force to automatically decouple force and position directions. 6. A controller for a robotic system, wherein the system includes a humanoid robot having a plurality of robotic joints adapted for force control with respect to an object being acted upon by the humanoid robot, and a graphical user interface (GUI) electrically connected to the controller that is adapted for receiving an input signal from a user, the controller comprising: a host machine having memory; and an algorithm executable from the memory by the host machine to thereby control the plurality of joints using an impedance-based control framework, wherein the impedance-based control framework includes a function of commanded inertia, damping, and stiffness matrices; wherein execution of the algorithm by the host machine provides at least one of an object level, end-effector level, and joint space-level of control of the humanoid robot in response to the input signal into the GUI, the input signal including at least a desired input force to be imparted to the object; and wherein the host machine is configured to switch between impedance control on the object, the end-effector, and the joint level when a user selects, via the input signal to the GUI, a desired combination of the end-effectors. 7. The controller of claim 6, wherein the algorithm is adapted for executing an intermediate layer of logic to decipher the input signal entered via the GUI. 8. The controller of claim 6, wherein the host machine automatically decouples a force direction and a position control direction of the humanoid robot using a null-space projection matrix when the user inputs the desired input force, and wherein the position control direction is automatically projected into a null space orthogonally to the input force by execution of the algorithm. 9. The controller of claim 6, wherein the algorithm is adapted to parameterize a predetermined set of internal forces of the humanoid robot in object-level control to thereby allow for multiple grasp types, the multiple grasp types including at least a rigid contact grasp type and a point contact grasp type. 10. The controller of claim 6, wherein the controller is adapted for applying a second-order position tracker to the position control directions while applying a second-order force tracker to the force control directions. 11. The controller of claim 6, wherein the user selects the desired end-effectors of the robot to activate, and wherein the controller generates a linear and a rotational Jacobian for each end-effector in response thereto. 12. The controller of claim 6, wherein the controller is adapted to switch between a position control mode and a force control mode when the user provides the desired input force as a reference external force via the GUI. 13. A method for controlling a robotic system including a humanoid robot having a plurality of joints and end-effectors adapted for imparting a force to an object, a controller, and a graphical user interface (GUI) electrically connected to the controller, wherein the controller is adapted for receiving an input signal from the GUI, the method comprising: receiving the input signal via the GUI; processing the input signal using the controller to thereby control the plurality of joints and end-effectors, wherein processing the input signal includes using an impedance-based control framework to provide object level, end-effector level, and joint space-level control of the humanoid robot; and automatically switching between a position control mode and a force control mode via the controller when the user provides a desired input force as the input signal via the GUI, and between impedance control at one of the object, end-effector, and joint levels when the user selects a desired combination of end-effectors of the humanoid robot as the input signal via the GUI. 14. The method of claim 13, wherein the input signal is a desired input force imparted to the object, and wherein processing the input signal includes: automatically decoupling a force control direction and a position control direction when the user inputs the desired input force via the GUI, and projecting the position control direction orthogonally into a null space. 15. The method of claim 13, further comprising: using the controller to apply a second-order position tracker to the position control direction and a second-order force tracker to the force control direction. 16. The method of claim 13, further comprising: parameterizing a predetermined set of internal forces of the humanoid robot in object-level control to thereby allow for multiple grasp types in real-time, including at least a rigid contact grasp type and a point contact grasp type. 