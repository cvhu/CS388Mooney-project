A graphical interface system and method of use allows robot programs to be graphically created and visualized in three dimensional space in a CAD environment. Using either on-line or off-line techniques, an operator enters robot positions and orientations in space into the interface to define robot configurations. Trajectories between configurations are entered or generated and are displayed along with the configurations. The state of the end effector is also entered and visually communicated. A special state can be designated. The special state has associated therewith programming code for controlling robot actions at a configuration and the robot environment at the configuration. When such a state is designated by the user, programming code written in a special language is entered and stored in association with a particular configuration. After all robot configurations, states and trajectories are entered, the system creates robot control data. In operation, when the robot reaches a configuration associated with the special state, the programming code is executed. Robot configurations and trajectories can be simultaneously displayed along with CAD created objects such as workpieces so that interactions therebetween are visible. The CAD environment is utilized for selecting configurations and creating of trajectories. Configurations can be also be designated by selecting points on CAD created objects and lines.
Claims I claim: 1. A method for inputting robot end-effector information into a graphical interface, visualizing the information in a three dimensional graphical environment associated with the interface, and generating robot control data therefrom, the method comprising the steps of: (a) storing graphical image data of the robot end-effector; (b) inputting one or more nodes into the graphical interface, each node including configuration dam defining the orientation and position of the robot end-effector in three dimensional space, wherein said configuration data is input by: (i) placing a robot end-effector associated with a six-axis robot at a preselected orientation and position in space; (ii) reading joint data associated with each of the six axes; and (iii) converting the joint data into orientation and position data corresponding to the coordinate system of the graphical interface; (c) generating a graphical image of the node in the three dimensional graphical environment from the input node information and stored graphical image data, the graphical image showing the robot end-effector in the robot end-effector's configuration; and (d) creating robot programming language and data files from the node information for controlling operation of the robot end-effector. 2. A method according to claim 1 wherein step (b) includes inputting a plurality of nodes, the method further comprising the step of: (e) inputting a trajectory between at least one pair of the nodes, wherein step (c) further includes showing the trajectory between the two nodes in the three dimensional graphical environment and step (d) further includes creating the robot programming language and data files from the trajectory. 3. A method according to claim 2 wherein the trajectory between two nodes is generated by a CAD point connecting function. 4. A method according to claim 2 wherein the trajectory between two nodes is generated by specifying a user defined trajectory. 5. A method according to claim 1 further comprising the steps of: (e) inputting CAD data defining a three dimensional model of a simulated object; and (f) generating a graphical image of the simulated object from the CAD data and displaying the graphical image of the simulated object in the three dimensional graphical environment, along with the one or more end-effector images. 6. A method according to claim 1 wherein the configuration data defining the robot end-effector position in step (b) is input by inputting x, y and z axis coordinates in space. 7. A method according to claim 1 wherein the configuration data defining the robot end-effector position in step (b) is input by: (i) inputting CAD data to define a line in three dimensional space; (ii) selecting a point along the line and/or at the end of the line; and (iii) associating the position with the specified point. 8. A method according to claim 1 wherein the configuration data defining the robot end-effector position in step (b) is input by: (i) inputting CAD data to define a solid model of a simulated object; (ii) generating a graphical image of the solid model from the CAD data and displaying the graphical image of the solid model in the three dimensional graphical environment; (iii) selecting a point on the solid model; and (iv) associating the position with the specified point. 9. A method according to claim 1 wherein the configuration data defining the robot end-effector orientation in step (b) is input by: (i) selecting one or more axes; and (ii) inputting an amount of rotation about the selected axis. 10. An apparatus for inputting robot end-effector information into a graphical interface, visualizing the information in a three dimensional graphical environment associated with the interface, and generating robot control data therefrom, the apparatus comprising: (a) means for storing graphical image data of the robot end-effector; (b) means for inputting one or more nodes into the graphical interface, each node including configuration data defining the orientation and position of the robot end-effector in three dimensional space, said means for inputting further including, (i) means for placing a robot end-effector associated with a six-axis robot at a preselected orientation and position in space; (ii) means for reading joint data associated with each of the six axes; and (iii) means for converting the joint data into orientation and position data corresponding to the coordinate system of the graphical interface, wherein the converted orientation and position data is the orientation and position of the robot end-effector in three dimensional space; (c) means for generating a graphical image of the node in the three dimensional graphical environment from the input node information and stored graphical image data, the graphical image showing the robot end-effector in the robot end-effector's configuration; and (d) means for creating robot programming language and data files from the node information for controlling operation of the robot end-effector. 11. An apparatus according to claim 10 wherein a plurality of nodes are input into the means for inputting, the apparatus further comprising: (e) means for inputting a trajectory between at least one pair of the nodes; and (f) means for generating the trajectory between the two nodes in the three dimensional graphical environment, the means for creating robot programming language and data files further including means for creating the robot programming language and data files from the trajectory. 12. An apparatus according to claim 11 wherein the means for generating the trajectory between two nodes is a CAD point connecting function. 13. An apparatus according to claim 11 wherein the means for generating the trajectory between two nodes employs a user defined trajectory. 14. An apparatus according to claim 10 further comprising: (e) means for inputting CAD data defining a three dimensional model of a simulated object; and (f) means for generating a graphical image of the simulated object from the CAD data and displaying the graphical image of the simulated object in the three dimensional graphical environment, along with the one or more end-effector images. 15. An apparatus according to claim 10 wherein the means for inputting includes means for inputting x, y and z axis coordinates in space, the coordinates being the position of the robot end-effector in three dimensional space. 16. An apparatus according to claim 10 wherein the means for inputting includes: (i) means for inputting CAD data to define a line in three dimensional space; and (ii) means for selecting a point along the line and/or at the end of the line, wherein the position of the selected point is the position of the robot end-effector in three dimensional space. 17. An apparatus according to claim 10 wherein the means for inputting includes: (i) means for inputting CAD data to define a solid model of a simulated object; (ii) means for generating a graphical image of the solid model from the CAD data and displaying the graphical image of the solid model in the three dimensional graphical environment; and (iii) means for selecting a point on the solid model, wherein the position of the selected point is the position of the robot end-effector in three dimensional space. 18. An apparatus according to claim 10 wherein the means for inputting includes means for selecting one or more axes and inputting an amount of rotation about the selected axis, wherein the amount of rotation about the selected axis is the orientation of the robot end-effector in three dimensional space. 19. A method for inputting robot end-effector information into a graphical interface, visualizing the information in a three dimensional graphical environment associated with the interface, and generating robot control data therefrom, the method comprising the steps of: (a) storing graphical image data of the robot end-effector; (b) inputting one or more nodes into the graphical interface, each node including configuration data defining the orientation and position of the robot end-effector in three dimensional space, each node further including end-effector state information at the node, wherein one of the states of the robot end-effector is Criptic; (c) generating a graphical image of the node in the three dimensional graphical environment from the input node information and stored graphical image data, the graphical image showing the robot end-effector in the robot end-effector's configuration, said graphical image further includes showing the state of the robot end-effector at the robot end-effector's node in the three dimensional graphical environment; (d) inputting a set of instructions associated with a robot at the respective node when the Criptic state is input; and (e) creating robot programming language and data files from the node and state information for controlling operation of the robot end-effector, and said set of instructions, thereby allowing the set of instructions to be executed when the robot reaches the respective node. 20. A method according to claim 19 wherein the set of instructions in step (d) is input through a text editor. 21. A method for inputting robot end-effector information into a graphical interface, visualizing the information in a three dimensional graphical environment associated with the interface, and generating robot control data therefrom, the method comprising the steps of: (a) storing graphical image data of the robot end-effector; (b) inputting one or more nodes into the graphical interface, each node including configuration data defining the orientation and position of the robot end-effector in three dimensional space, each node further including end-effector state information at the node, said state information comprising the state of being open, closed or Criptic; (c) generating a graphical image of the node in the three dimensional graphical environment from the input node information and stored graphical image data, the graphical image showing the robot end-effector in the robot end-effector's configuration, said graphical image further includes showing the state of the robot end effector at the robot end-effector's node in the three dimensional graphical environment; and (d) creating robot programming language and data files from the node and state information for controlling operation of the robot end-effector. 22. A method for inputting robot end-effector information into a graphical interface, visualizing the information in a three dimensional graphical environment associated with the interface, and generating robot control data therefrom, the apparatus comprising: (a) means for storing graphical image data of the robot end-effector; (b) means for inputting one or more nodes into the graphical interface, each node including configuration data defining the orientation and position of the robot end-effector in three dimensional space, each node further including end-effector state information at the node, wherein one of the states of the robot end-effector is Criptic; (c) means for generating a graphical image of the node in the three dimensional graphical environment from the input node information and stored graphical image data, the graphical image showing the robot end-effector in the robot end-effector's configuration, said means for generating a graphical image further including a means for showing the state of the robot end-effector at the robot end-effector's node in the three dimensional graphical environment; (d) means for inputting a set of instructions associated with a robot at the respective node when the Criptic state is input; and (e) means for creating robot programming language and data files from the node and state information for controlling operation of the robot end-effector, and said set of instructions, thereby allowing the set of instructions to be executed when the robot reaches the respective node. 23. An apparatus according to claim 22 wherein the means for inputting a set of instructions is a text editor. 24. An apparatus for inputting robot end-effector information into a graphical interface, visualizing the information in a three dimensional graphical environment associated with the interface, and generating robot control data therefrom, the apparatus comprising: (a) means for storing graphical image data of the robot end-effector; (b) means for inputting one or more nodes into the graphical interface, each node including configuration data defining the orientation and position of the robot end-effector in three dimensional space, each node further including end-effector state information at the node, said state information comprising the state of being open, closed or Criptic; (c) means for generating a graphical image of the node in the three dimensional graphical environment from the input node information and stored graphical image data, the graphical image showing the robot end-effector in the robot end-effector's configuration, said means for generating a graphical image further including means for showing the state of the robot end-effector at the robot end-effector's node in the three dimensional graphical environment; and (d) means for creating robot programming language and data files from the node and state information for controlling operation of the robot end-effector. 