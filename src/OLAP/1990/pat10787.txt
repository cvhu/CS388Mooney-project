A telerobotic system adapted for tracking and handling a moving object comprises a robot manipulator, a video monitor, an image processor, hand controls and a computer. The robot manipulator comprises a movable robotic arm having an effector for handling an object, a drive system for moving the arm in response to arm input signals, sensors for sensing the position of the arm and for generating arm output signals which characterize the dynamic motion behavior of the arm, and a vid=eo camera carried by the arm. The camera responds to motion of the moving object within the field of view of the camera. The video monitor receives an input video signal from the video camera, for displaying an image of the object to a human operator. The image processor is responsive to the output signal of the camera, and is capable of acquiring and pre-processing an image of the object on a frame by frame basis. The hand control is capable of generating a hand control output signal in response to input from a human operator. The computer generates arm input signals and is disposed between the hand control means, the robot manipulator, and image processor. The computer receives (i) output signals from the image processor and (ii) the arm output signals and (iii) the hand control output signal and generates arm input signals in response to the received signals whereby the arm tracks the motion of the object.
Claims We claim: 1. A telerobotic system adapted for handling a moving objects, said object having at least three points of known position, comprising: (a) a robot manipulator comprising (i) a movable robotic arm having an effector for handling an object, (ii) means for moving said arm in response to arm input signals, (iii) means for sensing the position of said arm and for generating arm output signals, which arm output signals characterize the dynamic motion behaviour of said arm, and (iv) a video camera carried by said arm, said camera being adapted to respond in real time to real time motion of said moving object within the field of view of said camera; (b) a video monitor for receiving an input video signal from said video camera and for displaying an image of the object to a human operator; (c) image processing means, responsive to the output signal of said camera, for acquiring and pre-processing an image of the object on a frame by frame basis; (d) hand control means for generating a hand control output signal in response to input from a human operator; (e) computer means for generating arm input signals disposed between said hand control means, said robot manipulator, and said image processing means, said computer means receiving (i) output signals from said image processing means and (ii) said arm output signals and (iii) said hand control output signal and generating arm input signals in response to said received signals whereby said arm tracks the real time motion of the object. 2. A telerobotic system as claimed in claim 1 wherein said computer means comprising means for solving the following tracking control algorithm ##EQU26## wherein I is a unit matrix, F is a positive-definite matrix; and P.sub.CT, the desired target position relative to the camera, is obtained by integrating the commanded rate P.sub.CT ; and wherein the signal v.sub.w is computed as follows: where K is a positive-definite matrix and (n.sub.CT., q.sub.CT, n.sub.CT, q.sub.CT) are Euler parameters generated by integrating the following equations: ##EQU27## wherein a superscript "T" denotes matrix or vector transport and I is a unit matrix; and wherein: the letter p is used generally to denote a position vector; and the letter B denotes the orientation matrix of one frame of reference expressed in terms of another frame of reference; and the letters w and p represent the angular and linear velocity, respectively, of one frame of reference in terms of another frame of references, wherein: ph, B.sub.Oh denote position and orientation of the robot's hand with respect to its base; P.sub.h, w.sub.h denote linear and angular velocities of the robot's hand with respect to its base; p.sub.T, B.sub.Ot denote estimated position and orientation of a target with respect to the base of the robot; p.sub.T, w.sub.T denote estimated linear and angular velocities of a target with respect to the base of the robot; p.sub.C, B.sub.OC denote position and orientation of said camera with respect to the base of the robot; p.sub.C w.sub.C denote linear and angular velocities of said camera with respect to base of the robot; p.sub.Ch, B.sub.Ch denote position and orientation of said camera on the robot's hand (assumed to be fixed); p.sub.CT, B.sub.CT denote estimated position and orientation of a target with respect to said camera; P.sub.CT, w.sub.CT denote estimated linear and angular velocities of a target with respect to said camera; ##EQU28## denote commanded (from hand controller) velocities of target relative to said camera, ##EQU29## denote commanded outputs to the resolved-rate controller of said robot; and for any vector v with components define the matrix ##EQU30## 3. A telerobotic system as claimed in claim 1 wherein said computer means comprises means for solving the following photogrammetry algorithm comprising the steps of: (a) constructing matrix P from the control point coordinates p.sub.i, determining matrices E and P.sub.1, using Gaussian elimination, and computing the psuedoinverse and kernel of P.sub.1 ; (b) calculating matrices R.sub.x.sbsb.i, R.sub.y.sbsb.i, R.sub.z.sbsb.i (i=1,2); (c) finding the kernel of R.sub.2 ; (d) constructing matrices V.sub.i, (i=1, . . . 3); (e) selecting an initial estimate of vector x.sub.k (k=0); (f) evaluating function f at the current iterative point x.sub.k and determining the norm of f; (g) comparing the norm of f with a predefined threshold of zero; (h) if the norm of f is within a predefined threshold of zero, computing vectors .alpha. and .beta., assembling B.sub.CT and recovering p.sub.CT ; (i) if the norm of f is outside a predefined threshold of zero, computing the Jacobian .gradient.f and updating x.sub.k, and returning to step (f) above; (j) if .gradient.f cannot be computed because of a singularity, returning to step (f) with an arbitrarily perturbed iterative point x.sub.k+1. 4. A telerobotic system as claimed in claim 3 wherein said computer means comprising means for solving the following tracking control algorithm ##EQU31## where I is a unit matrix, F is a positive-definite matrix; and ##EQU32## the desired target position relative to the camera, is obtained by integrating the commanded rate ##EQU33## and wherein the signal v.sub.w is computed as follows: where K is a positive-definite matrix and (n.sub.CT, q.sub.CT, n.sub.Ct, q.sub.CT) are Euler parameters generated by integrating the following equations: ##EQU34## where a superscript "T" denotes matrix or vector transpose and I is a unit matrix; and wherein: the letter p is used generally to denote a position vector; and the letter B denotes the orientation matrix of one frame of reference expressed in terms of another frame of reference; and the letters w and p represent the angular and linear velocity, respectively, of one frame of reference in terms of another frame of references, wherein: ph, B.sub.Oh denote position and orientation of the robot's hand with respect to its base; p.sub.h, w.sub.h denote linear and angular velocities of the robot's hand with respect to its base; p.sub.T, B.sub.OT denote estimated position and orientation of a target with respect to the base of the robot; P.sub.T, w.sub.T denote estimated linear and angular velocities of a target with respect to the base of the robot; p.sub.C, B.sub.OC denote position and orientation of said camera with respect to the base of the robot; p.sub.C, w.sub.C denote linear and angular velocities of said camera with respect to base of the robot; p.sub.Ch, B.sub.Ch denote position and orientation of said camera on the robot's hand (assumed to be fixed); p.sub.CT, B.sub.CT denote estimated position and orientation of a target with respect to said camera; p.sub.CT, w.sub.CT denote estimated linear and angular velocities of a target with respect to said camera; ##EQU35## denote commanded (from hand controller) velocities of target relative to said camera, ##EQU36## denote commanded outputs to the resolved-rate controller of said robot; and for any vector v with components, define the matrix ##EQU37## 5. The telerobotic system of claim 1 wherein said computer means comprises; (a) computer kinematic transformation means for generating an output signal indicative of the position and orientation of said camera relative to said robot manipulator in response to said arm output signals; (b) computer photogrammetry means responsive to the output signal from said image processing means for generating an output signal indicative of the motion characteristics of said moving object relative to said camera, the moving object being within the field of view of said camera; (c) target motion estimation means for receiving the output signal from said kinematic transformation means and said computer photogrammetry means and for producing an estimate of the motion characteristics of said moving object relative to said robot manipulator; (d) control algorithm means which receive the output signals from said computer photogrammetry means, said target motion estimator means and said hand control means and for producing arm input signals for said means for moving said arm in response to such signals. 6. A telerobotic tracking system for tracking the movement of a moving object, said object having at least three points of known position, comprising: (a) a robot manipulator comprising (i) a movable robotic arm, (ii) means for moving said arm in response to arm input signals, (iii) means for sensing the position of said arm and for generating arm output signals, which arm output signals characterize the dynamic motion behaviour of said arm, and (iv) a video camera carried by said arm, said camera being adapted to respond in real time to real time motion of said moving object within the field of view of said camera; (b) a video monitor which receives an input video signal from said video camera, for displaying an image to a human operator; (c) image processing means, responsive to the output signal of said camera, capable of acquiring and pre-processing an image on a frame by frame basis; (d) computer means for receiving (i) the output signal from said image processing means and (ii) said arm output signals and generating arm input signals in response to said input signals to said computer means. 7. A telerobotic system as claimed in claim 6 wherein said computer means comprising means for solving the following tracking control algorithm ##EQU38## where I is a unit matrix, F is a positive-definite matrix; and ##EQU39## the desired target position relative to the camera, is obtained by integrating the commanded rate ##EQU40## and wherein the signal v.sub.w is computed as follows: where K is a positive-definite matrix and (n.sub.CT, q.sub.CT, n.sub.Ct, Q.sub.CT) are Euler parameters generated by integrating the following equations. ##EQU41## where a superscript "T" denotes matrix or vector transport and I is a unit matrix; and wherein: the letter p is used generally to denote a position vector; and the letter B denotes the orientation matrix of one frame of reference expressed in terms of another frame of reference; and the letters w and p represent the angular and linear velocity, respectively, of one frame of reference in terms of another frame of references, wherein: ph, B.sub.Oh denote position and orientation of the robot's hand with respect to its base; p.sub.h, w.sub.h denote linear and angular velocities of the robot's hand with respect to its base; p.sub.T, B.sub.OT denote estimated position and orientation of a target with respect to the base of the robot; p.sub.T, w.sub.T denote estimated linear and angular velocities of a target with respect to the base of the robot; p.sub.C, B.sub.OC denote position and orientation of said camera with respect to the base of the robot; p.sub.C, w.sub.C denote linear and angular velocities of said camera with respect to base of the robot; p.sub.Ch, B.sub.Ch denote position and orientation of said camera on the robot's hand (assumed to be fixed); p.sub.CT, B.sub.CT denote estimated position and orientation of a target with respect to said camera; p.sub.CT, w.sub.CT denote estimated linear and angular velocities of a target with respect to said camera; ##EQU42## denote commanded (from hand controller) velocities of target relative to said camera, ##EQU43## denote commanded outputs to be resolved-rate controller of said robot; and for any vector v with components, define the matrix ##EQU44## 8. A telerobotic system as claimed in claim 6 wherein said computer means comprises means for solving the following photogrammetry algorithm comprising the steps of: (a) constructing matrix P from the control point coordinates p.sub.i, determining matrices E and P.sub.1, using Gaussian elimination, and computing the psuedoinverse and kernel of P.sub.1 ; (b) calculating matrices R.sub.x.sbsb.i, R.sub.y.sbsb.i, R.sub.z.sbsb.i (i=1,2); (c) finding the kernel of R.sub.2 ; (d) constructing matrices V.sub.i, (i=1,2); (e) selecting an initial estimate of vector x.sub.k (k=0); (f) evaluating function f at the current iterative point x.sub.k and determining the norm of f; (g) comparing the norm of f with a predefined threshold of zero; (h) if the norm of f is within a predefined threshold of zero, computing vectors .alpha. and .beta., assembling B.sub.CT and recovering p.sub.CT ; (i) if the norm of f is outside a predefined threshold of zero, computing the Jacobian .gradient.f and updating x.sub.k, and returning to step (f) above; (j) if .gradient.f cannot be computed because of a singularity, returning to step (f) with an arbitrarily perturbed iterative point x.sub.k+1. 9. A telerobotic system as claimed in claim 8 wherein said computer means comprising means for solving the following tracking control algorithm ##EQU45## where I is a unit matrix, F is a positive-definite matrix; and ##EQU46## the desired target position relative to the camera, is obtained by integrating the commanded rate ##EQU47## and wherein the signal v.sub.w is computed as follows: where K is a positive-definite matrix and (n.sub.CT, q.sub.CT, n.sub.Ct, q.sub.CT) are Euler parameters generated by integrating the following equations: ##EQU48## where a superscript "T" denotes matrix or vector transpose and I is a unit matrix; and wherein: the letter p is used generally to denote a position vector; and the letter B denotes the orientation matrix of one frame of reference expressed in terms of another frame of reference; and the letters w and p represent the angular and linear velocity, respectively, of one frame of reference in terms of another frame of references, wherein: ph, B.sub.Oh denote position and orientation of the robot's hand with respect to its base; p.sub.h, w.sub.h denote linear and annular velocities of the robot's hand with respect to its base; p.sub.T, B.sub.OT denote estimated position and orientation of a target with respect to the base of the robot; p.sub.T, w.sub.T denote estimated linear and angular velocities of a target with respect to the base of the robot; p.sub.C, B.sub.OC denote position and orientation of said camera with respect to the base of the robot; p.sub.C, w.sub.C denote linear and angular velocities of said camera with respect to base of the robot; p.sub.Ch, B.sub.Ch denote position and orientation of said camera on the robot's hand (assumed to be fixed); p.sub.CT, B.sub.Ct denote estimated position and orientation of a target with respect to said camera; p.sub.CT, w.sub.CT denote estimated linear and angular velocities of a target with respect to said camera; ##EQU49## denote commanded (from hand controller) velocities of target relative to said camera, ##EQU50## denote commanded outputs to the resolved-rate controller of said robot; and for any vector v with components, define the matrix ##EQU51## 10. The telerobotic system of claim 6 wherein said computer means comprises: (a) responsive to said arm output signal from computer kinematic transformations means for generating an output signal indicative of the position and orientation of said camera relative to said robot manipulator; (b) computer photogrammetry means responsive to the output signal from said image processing means for generating an output signal indicative of the motion characteristics of said moving object relative to said camera, the moving object being within the field of view of said camera; (c) target motion estimation means for receiving the output signal from said kinematic transformation means and said computer photogrammetry means and for producing an estimate of the motion characteristics of said moving object relative to said robot manipulator; (d) control algorithm means which receive the output signals from said computer photogrammetry means, said target motion estimator means and for producing arm input signals for said means for moving said arm in response to such signals. 