An object, such as a robot, is located at an initial state in a finite state space area and moves under the control of the unsupervised neural network model of the invention. The network instructs the object to move in one of several directions from the initial state. Upon reaching another state, the model again instructs the object to move in one of several directions. These instructions continue until either: a) the object has completed a cycle by ending up back at a state it has been to previously during this cycle, or b) the object has completed a cycle by reaching the goal state. Upon reaching a state, the neural network model calculates a level of satisfaction with its progress towards reaching the goal state. If the level of satisfaction is low, the neural network model is more likely to override what has been learned thus far and deviate from a path known to lead to the goal state to experiment with new and possibly better paths. If the level of satisfaction is high, the neural network model is much less likely to experiment with new paths. The object is guaranteed to eventually find the best path to the goal state from any starting location, assuming that the level of satisfaction does not exceed a threshold point where learning ceases.
Claims What is claimed is: 1. A neural network model used to control the movement of an object amongst a plurality of states from a first state to a goal state, said model comprising: first learning means for learning a first path from said first state to said goal state; means for detecting an obstacle in said first path; and second learning means for learning an alternate path from said first state to said goal state. 2. The neural network of claim 1, further comprising: means for indicating a first level of satisfaction corresponding to said first path; and means for indicating a second level of satisfaction corresponding to said alternate path, wherein said second level of satisfaction is lower than said first level of satisfaction since said second path contains more states than said first path. 3. The neural network of claim 2, further comprising: means for detecting that said obstacle in said first path has been removed; and means for overriding what was learned in said second learning means and relearning said first path. 4. A method for controlling the movement of an object amongst a plurality of states from a first state to a goal state, said method being performed through the aid of a neural network, said method comprising the steps of: learning a first path from said first state to said goal state; detecting an obstacle in said first path; and learning an alternate path from said first state to said goal state. 5. The method of claim 4, further comprising the steps of: indicating a first level of satisfaction corresponding to said first path; and indicating, a second level of satisfaction corresponding to said alternate path, wherein said second level of satisfaction is lower than said first level of satisfaction since said second path contains more states than said first path. 6. The method of claim 5, further comprising the steps of: detecting that said obstacle in said first path has been removed; and overriding what was learned in said second learning means and relearning said first path. 