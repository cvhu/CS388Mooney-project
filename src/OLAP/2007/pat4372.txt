A fusion estimator is determined as the location of the most significant mode of a density function, which takes into account the uncertainty of the estimates to be fused. A mode detection method relies on mode tracking across scales. The fusion estimator is consistent and conservative, while handling naturally outliers in the data and multiple source models. The new estimator is applied for multiple motion estimation. Numerous experiments validate the theory and provide very competitive results. Other applications include generic distributed fusion, robot localization, motion tracking, registration of medical data, fusion for automotive tasks.
Claims What is claimed is: 1. An information fusion method comprising: determining a plurality of initial estimates of motion of an object comprising mean and covariance information; and determining a density based fusion estimate as a most significant mode of a density function determined from the plurality of initial estimates of motion of an object, wherein the most significant mode corresponds to a determined motion estimate of the object, wherein the most significant mode is determined by mode tracking across scales, the mode tracking beginning with a unique mode defined at a relatively large scale and tracking that mode toward a relatively smaller scale. 2. The method of claim 1, wherein the density function is determined according to a variable-bandwidth kernel density estimate. 3. The method of claim 1, further comprising determining a covariance of the fusion estimate, wherein the covariance is a convex combination of covariances of the plurality of initial estimates, each initial estimate having a weight, wherein the weights of the initial estimates are determined according to the most significant mode of the data. 4. The method of claim 1, wherein determining the plurality of initial estimates comprises determining a window bounding the data for motion estimation. 5. The method of claim 4, further comprising: determining a matrix of spatial gradients in the data; determining a vector of temporal image gradients in the data; and determining the covariance information as a matrix proportional to a variance of noise in the data based on the matrix of spatial gradients and the vector of temporal image gradients. 6. A computer readable medium embodying instructions executable by a processor to perform a method for nonparametric information fusion for motion estimation comprising: determining a plurality of initial estimates of motion from a sequence of images; tracking a mode of a density function across scales given multiple source models, wherein each source model corresponds to a set of initial estimates of motion; and determining a location of a most significant mode of the density function from a fusion of the initial estimates, wherein the most significant mode is output as a motion estimate from a sequence of images, wherein the most significant mode is determined by mode tracking across scales starting from a unique mode defined at a large scale and tracking that mode toward smaller scales. 7. The method of claim 6, further comprising determining a covariance of the fusion of the initial estimates, wherein the covariance is a convex combination of covariances of the plurality of initial estimates, each initial estimate having a weight, wherein the weights of the initial estimates are determined according to the most significant mode of the data. 8. The method of claim 6, wherein the density function is determined as a sum value of a plurality of Gaussian kernels located at data points in a predetermined neighborhood of data. 9. The method of claim 8, wherein each Gaussian kernel comprises spread information and orientation information. 10. A program storage device readable by machine, tangibly embodying a program of instructions executable by the machine to perform method steps for information fusion, the method steps comprising: determining a plurality of initial estimates of motion of an object comprising mean and covariance information, the plurality of initial estimates; and determining a density based fusion estimate as a most significant mode of a density function determined from the plurality of initial estimates of motion of an object, wherein the most significant mode corresponds to a determined motion estimate of the object, wherein the most significant mode is determined by mode tracking across scales, the mode tracking beginning with a unique mode defined at a relatively large scale and tracking that mode toward a relatively smaller scale. 11. The method of claim 10, wherein the density function is determined according to a variable-bandwidth kernel density estimate. 12. The method of claim 10, further comprising determining a covariance of the fusion estimate, wherein the covariance is a convex combination of covariances of the plurality of initial estimates, each initial estimate having a weight, wherein the weights of the initial estimates are determined according to the most significant mode of the data. 13. The method of claim 10, wherein determining the plurality of initial estimates comprises determining a window bounding the data for motion estimation. 14. The method of claim 13, further comprising: determining a matrix of spatial gradients in the data; determining a vector of temporal image gradients in the data; and determining the covariance information as a matrix proportional to a variance of noise in the data based on the matrix of spatial gradients and the vector of temporal image gradients. 