The present invention is a method and apparatus that provides detection, characterization, and intuitive dissemination of targets. This disclosure combines improvements to ultra-wideband (UWB) sensing and machine target characterization with a means to convey data in a format that is quickly and readily understood by practitioners of the technology. The invention is well suited for Situational Awareness (SA) support in areas that are occluded by rain, fog, dust, darkness, distance, foliage, building walls, and any material that can be penetrated by ultra-wideband RF signals. Sense Through The Wall (STTW) performance parameters including target range, stand-off distance, and probability of detection are improved herein by combining a dynamically positioned sliding windowing function with orthogonal feature vectors that include but are not limited to time amplitude decay, spectral composition, and propagation time position in the return signal data. This invention is particularly useful for STTW and SA applications including urban combat, law enforcement, fire protection, transportation security, and homeland security. The invention can also be used to detect objects that are concealed by clothing, debris, and other non-metallic materials.
Claims What is claimed is: 1. A method that uses ultra-wideband RF energy to detect objects of interest that comprises in combination; (a) transmitting repetitive bursts of ultra-wideband RF impulses in the direction of a target area to search for objects of interest, (b) receiving and amplifying signals that are reflected from objects of interest and background clutter in the target area, (c) converting the said received and amplified signals into digital form, (d) performing signal processing functions on said converted signals to reduce noise in the digitized data, (e) incrementally analyzing each said signal processed radar return with a windowing function wherein said window function is moved and performed across the entirety of each processed radar return, (f) calculating any plurality of domain parameters from each said windowing function and using calculated values to extract target specific feature information that distinguishes objects of interest from background clutter, (g) outputting said target feature information into an automatic target recognition method that distinguishes objects of interest from background clutter in the feature information, (h) reporting object class output from said automatic target recognition method to a display device. 2. A method of claim 1 that transmits repetitive bursts of low-noise RF impulse energy wherein the rise time is less than 500 picoseconds and the fall time is less than 10 nanoseconds. 3. A method of claim 1 that performs averaging signal processing functions on the time-domain reflected signal to improve the signal to noise ratio. 4. A method of claim 1 that performs averaging signal processing functions on the Fourier transform of the reflected signal to improve the signal to noise ratio. 5. A method of claim 1 that incrementally signal processes each reflected radar return with an overlapping sliding windowing function. 6. A method of claim 1 that incrementally signal processes each reflected radar return with a non-overlapping sliding windowing function. 7. A method of claim 1 that dynamically positions each said windowing function over time-domain amplitude peaks in each said incremental analysis of the reflected radar return. 8. A method of claim 1 wherein any plurality of windowing functions are used to analyze any plurality of time domain slices in the signal processed radar return signal. 9. A method of claim 1 wherein the size of any windowing function is adjusted to improve signal discrimination and target characterization results. 10. A method of claim 1 wherein the size of any time domain slice is adjusted to improve signal discrimination and target characterization results. 11. A method of claim 1 that calculates a Fourier transform on each said windowing function and uses the calculated Fourier transform to select target specific feature information that distinguishes objects of interest from background clutter. 12. A method of claim 1 that calculates time amplitude decay data statistics on each said windowing function and uses the calculated data statistics to select target specific feature information that distinguishes objects of interest from background clutter. 13. A method of claim 1 that calculates the propagation time position of each said windowing function and uses said propagation time position to select target specific feature information that distinguishes objects of interest from background clutter. 14. A method of claim 1 that calculates any combination of the Fourier transform, time amplitude decay, and the propagation time position of each said windowing function and uses said calculated data to select target specific feature information that distinguishes objects of interest from background clutter. 15. A method of claim 1 wherein the said windowing function is a Hamming window. 16. A method of claim 1 wherein the said windowing function is a Hamming window. 17. A method of claim 1 wherein the said windowing function is a Gaussian window. 18. A method of claim 1 wherein the said windowing function is an asymptotic window. 19. A method of claim 1 that reports object class output from said automatic target recognition method by selecting an image of any type that intuitively represents the object class that was reported with the highest probability of detection. 20. A method of claim 19 that comprises a visual representation of the presence and type of target that is characterized in the reflected radar signal data. 21. A method of claim 19 that comprises an audible representation or indication of the presence and type of target that is characterized in the reflected radar signal data. 22. A method of claim 19 that comprises in combination any plurality of visual, audible, or physical representation or indication of the presence and type of target that is characterized in the reflected radar signal data. 23. The method of claim 1 wherein the feature information is time-amplitude or frequency based. 24. The method of claim 1 wherein the feature information is used to distinguish any plurality of target classes. 25. The method of claim 23 wherein the feature information is one-dimensional, two-dimensional, or multi-dimensional. 26. The method of claim 1 wherein automatic target recognition comprises neural network classifiers. 27. The method of claim 1 wherein automatic target recognition comprises cluster classifiers. 28. The method of claim 1 wherein automatic target recognition comprises statistical classifiers. 29. The method of claim 1 wherein automatic target recognition comprises rule based classifiers. 30. The method of claim 1 wherein automatic target recognition comprises fuzzy based classifiers. 31. The method of claim 1 wherein automatic target recognition comprises hybrid classifiers. 32. An automatic target recognition method of claim 1 that further comprises; (a) calculating data statistics from feature information input, (b) using a selector to use calculated data statistic output values to select target feature information to distinguish specific target classes from background clutter wherein each target class uniquely describes a target for recognition purposes, (c) using a classifier to use target specific feature information to distinguish objects of interest from background clutter and to output target class data. 33. The method of claim 32 wherein the parallel hardware comprises cluster classifier architectures. 34. The method of claim 32 wherein the parallel hardware comprises statistical classifier architectures. 35. The method of claim 32 wherein the parallel hardware comprises rule-based classifier architectures. 36. The method of claim 32 wherein the parallel hardware comprises fuzzy-based classifier architectures. 37. The method of claim 32 wherein the parallel hardware comprises hybrid classifier architectures. 38. A method of claim 32 for distinguishing targets from all types of system noise and background clutter comprising the steps of; (a) inputting data having targets, system noise, and background clutter, (b) applying neural network learning procedures to the input data to construct a set of operators, (c) applying the constructed set of operators to construct a set of features, (d) choosing optimal features from the constructed set of features to distinguish targets from clutter, (e) using the selected optimal features to distinguish targets from background clutter. 39. The method of claim 38 wherein parallel hardware is employed to distinguish targets from background clutter. 40. An apparatus that uses ultra-wideband RF energy to detect objects of interest that comprises in combination; (a) an electronic means to generate repetitive ultra-wideband pulses at a high pulse repetition frequency wherein said transmitter electronics are coupled to any plurality of antennae that are configured and positioned to direct energy in the direction of the target area, (c) radar receiver amplification electronics coupled to any plurality of antennae that are configured to detect signals that are reflected from the target area, (d) sampling electronics with sufficient dynamic range and sampling bandwidth to accurately digitize reflected signals from the target area that are amplified by said radar receiver, (e) a signal processor to perform noise reduction functions on said digitized reflected signals, (f) electronic firmware that is properly configured to incrementally analyze each said digitized reflected radar signal return with a windowing function wherein said windowing function is moved and performed across the entirety of each signal processed radar return, (g) electronic firmware that is properly configured to calculate transfer functions of data from each said windowing function and to use calculated values to extract target specific feature information that distinguishes objects of interest from background clutter, (h) electronic firmware that is properly configured to report feature vectors to an automatic target recognition method that distinguishes objects of interest from background clutter in the feature information, (i) electronic firmware that is properly configured to implement automatic target recognition, (j) electronic firmware that is properly configured to select and report display images based on automatic target recognition output, (k) an electronic apparatus to display target image information. 41. An apparatus of claim 40 wherein the antenna is coupled to the transmitter and is the same antenna that is coupled to the receiver. 42. An apparatus of claim 40 that comprises in combination any plurality of antennae that are operated in mono-static mode. 43. An apparatus of claim 40 that comprises in combination any plurality of antennae that are operated in bi-static mode. 44. An apparatus of claim 40 that comprises in combination any plurality of antennae that form a physical array. 45. An apparatus of claim 40 that comprises in combination any plurality of antennae that form a synthetic array. 46. An apparatus of claim 40 that comprises in combination any plurality of antennae that are operated in mono-static mode, antennae that are operated in bi-static mode, antennae that form physical array, or antennae that form a synthetic array. 47. An apparatus of claim 40 that comprises electronic hardware that forms a triggered time-domain impulse generator that produces an output pulse with a rise time of 500 picoseconds or less and a fall-time of 10 nanoseconds or less. 48. An apparatus of claim 40 that comprises an electronic oscillating signal generator with an effective frequency range of 50 Hz to 100 kHz to trigger the time-domain impulse generator of claim 38. 49. An apparatus of claim 40 wherein parallel hardware is used to calculate data transfer functions on each windowing function. 50. An apparatus of claim 40 wherein parallel hardware is used to extract target specific feature information from said calculated data transfer function values that distinguish objects of interest from background clutter. 51. An apparatus of claim 40 wherein the automatic target recognition electronics comprises parallel hardware to implement neural network architectures. 52. An apparatus of claim 40 wherein the automatic target recognition electronics comprises parallel hardware to implement statistical target classification architectures. 53. An apparatus of claim 40 that comprises in combination electronics that calculate a Fourier transform on each said windowing function. 54. An apparatus of claim 40 that employs parallel hardware to calculate a Fourier transform on each said windowing function. 55. An apparatus of claim 40 that comprises in combination electronics that calculate time amplitude decay data statistics on each said windowing function. 56. An apparatus of claim 40 that employs parallel hardware to calculate time amplitude decay data statistics on each said windowing function. 57. An apparatus of claim 40 that comprises in combination electronics that calculate the propagation time position of each said windowing function. 58. An apparatus of claim 40 that employs parallel hardware to calculate the propagation time position of each said windowing function. 59. An apparatus of claim 40 that comprises a display to provide a visual representation of the presence and type of object of interest that is characterized in the reflected radar signal data. 60. An apparatus of claim 40 that comprises a display to provide audible representation of the presence and type of object of interest that is characterized in the reflected radar signal data. 61. An apparatus of claim 40 that comprises a display to provide vibratory, thermal, or other physical representation of the presence and type of object of interest that is characterized in the reflected radar signal data. 