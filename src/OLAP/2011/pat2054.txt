An hierarchical temporal memory network having at least one node configured to receive at least two variables of different properties. The at least two variables have different data types, different data sizes, or represent different physical or logical properties in the hierarchical temporal memory network. By using the node receiving variables of different properties, the hierarchical temporal memory network can be configured more flexibly and efficiently because a separate node is not needed to receive, process, and output variables of different properties.
Claims What is claimed is: 1. An hierarchical temporal memory (HTM) network comprising: a first node for receiving a first input data representing an object or a status of an object and generating first variables and second variables, the first variables representing information about patterns and sequences in the first input data corresponding to learned patterns and sequences, the second variables comprising category variables representing a correct cause of the first input data; and a second node associated with the first node for receiving the second variables, the second node generating third variables representing information about causes of the first input data. 2. The HTM network of claim 1, wherein the first variables comprises a probability distribution representing probabilities that the patterns and sequences in the first input data correspond to the learned patterns and sequences. 3. The HTM network of claim 1, further comprising a third node at a same hierarchy as the first node in the HTM network and associated with the second node, the third node receiving a second input data representing the object or the status of the object and generating fourth variables provided to the second node, the second input data partly overlapping with the first input data. 4. The HTM network of claim 1, wherein the second variables are provided to the second node and at least one node other than the second node. 5. The HTM network of claim 1, wherein the second node generates and provides fourth variables to the first node. 6. The HTM network of claim 5, wherein the fourth variables represent a prediction made at the second node. 7. An hierarchical temporal memory (HTM) network comprising: a first child node for receiving a first input data representing an object or a status of an object and generating first variables, the first variables representing information about patterns and sequences in the first input data corresponding to learned patterns and sequences stored in the first child node; a second child node for receiving a second input data representing the object or the status of the object and generating second variables, the second input data partly overlapping with the first input data, the second variables representing information about patterns and sequences in the second input data corresponding to learned patterns and sequences stored in the second child node; and a parent node associated with the first child node and the second child node to receive the first variables and the second variables, the second node generating third variables representing information about causes of the first and second input data; wherein the first child node or the second child node is configured to send category information representing a correct cause of the first and second input data to the parent node. 8. A computer-implemented method of determining an object or a status of object causing an input data, the method comprising: a first node generating first variables responsive to receiving a first input data representing the object or the status of the object, the first variables representing information about patterns and sequences in the first input data corresponding to learned patterns and sequences; the first node generating second variables comprising category variables representing a correct cause of the first input data; and a second node generating third variables representing information about causes of the first input data responsive to receiving the second variables. 9. The method of claim 8, wherein the first variables comprise a probability distribution representing probabilities that the patterns and sequences in the first input data correspond to the learned patterns and sequences. 10. The method of claim 8, further comprising a third node generating fourth variables and providing the fourth variables to the second node responsive to receiving a second input data representing the object or the status of the object, the second input data partly overlapping with the first input data. 11. The method of claim 8, further comprising sending the second variables to the second node and at least one node other than the second node. 12. The method of claim 8, further comprising the second node providing fourth variables to the first node after generating the fourth variables based on at least the first variables or the second variables. 13. The method of claim 12, wherein the fourth variables represent a prediction made at the second node. 