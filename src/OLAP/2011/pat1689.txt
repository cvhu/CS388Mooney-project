A machine classification learning method titled Generalized Reduced Error Logistic Regression (RELR) is presented. The method overcomes significant limitations in prior art logistic regression and other machine classification learning methods. The method is applicable to all current applications of logistic regression, but has significantly greater accuracy using smaller sample sizes and larger numbers of input variables than other machine classification learning methods including prior art logistic regression.
Claims The invention claimed is: 1. A system for machine learning comprising: a computer including a computer-readable medium having software stored thereon that, when executed by said computer, performs a method comprising the steps of being trained to learn a logistic regression match to a target class variable so to exhibit classification learning by which: an estimated error in each variable's moment in the logistic regression be modeled and reduced through constraints that require that the expected extreme error be inversely related to a t-value for that variable; an estimated error in each variable's moment in the logistic regression be modeled and reduced through constraints that require that the probability of positive and negative estimated errors be substantially equal across all variable moments; where there is substantially no bias in the probability of positive or negative estimated errors across even versus odd polynomial moments; and, an estimated error in each variable's moment in the logistic regression is constrained by a scaling that is not the sum of t-values across all variables but instead is substantially twice that sum so to reflect both positive and negative expected errors whereby when this substantially twice sum value is divided by the t-value for any variable, it yields a large expected error for small t-values and a small expected error for large t-values. 2. The system of claim 1 wherein said method initially employs one or a plurality of standardized input variables. 3. The system of claim 2 wherein said method further employs standardized variables resulting from interactions between the input variables. 4. The system of claim 3 wherein said method further employs standardized variables that are nonlinear effects based upon the input variables or their interactions. 5. The system of claim 4 wherein said method computes a probability of a category and a category classification decision based upon a threshold. 6. The system of claim 5 wherein said method computes t-values using serial or parallel batch processing so to achieve a relatively fast processing speed. 7. The system of claim 6 wherein said method employs approximations of t-values that are computed so any expected error and accuracy is approximately the same as would result from using the t-values for which they are substituted. 8. The system of claim 7 further including dummy coded missing status variables and imputation of missing values through mean value imputation after the t-values, or any substitute approximations of t-values, have been computed. 9. The system of claim 8 wherein said method employs prior weightings of regression beta coefficients used to determine prior and posterior class probabilities. 10. The system of claim 9 wherein said method includes: the dimensionality being initially reduced to a manageable size by selecting that subset of potential variables as inputs to the logistic regression which have the largest magnitude t-values or approximate substitutes to t-values, whereby odd and even polynomial variables are screened separately, if they exist, so that the inputs contain the group of odd polynomial variables with the largest magnitude t-values and the group of even polynomial variables with the largest magnitude t-values. 11. The system of claim 10 wherein said method includes: performing successive iterations of the variable selection, performing of the method beginning with the initial manageable set of variables which are further gradually reduced by deleting variables with the lowest magnitude t-values or approximate substitutes to t-values; which, if nonlinear variables are included, treats linear and odd polynomial variables and even polynomial variables as two separate groups in which variables are simultaneously dropped, if they exist, so to reach a best model which is defined as having the largest log likelihood across training observations. 12. The system of claim 4 wherein said method is used in predictive modeling, and substantially eliminates problems of multicollinearity such as related to overfitting which are inherent in machine learning involving a plurality of input variables, interactions between input variables, and nonlinear variables. 13. The system of claim 1 wherein said method employs binary, nominal, ordinal, or interval category target class variables. 