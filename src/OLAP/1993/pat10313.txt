Locating and recognizing characters on a machine produced label, for example, is accomplished faster and more accurately by searching for first and second identifiable objects within first and second search windows, respectively. The first and second search windows are typically much smaller than the label or image being searched. The first object is the top portion of the label and the second object is the bottom portion of the label. Having located each object, a reference point is determined on each. From these two reference points, precise character or bar code locations can be predicted for reading the characters or bar codes printed on the label at predetermined locations. A character search window superimposed over each character at its estimated location is searched to read the character located thereat. If the first or second object could not be located, due to a torn label for example, an alternate object may be searched and a reference point located thereon.
Claims What is claimed is: 1. A method for efficiently locating an optically recognizable character encoded on a label, comprising machine-executed steps of: locating the label; searching in a first predetermined window for identifying a first predetermined object; determining a first reference mark position on the first predetermined object; searching in a second predetermined window for identifying a second predetermined object; determining a second reference mark position on the second predetermined object; calculating a first character window location relative to the first and second reference mark positions; reading a first character located within the first character window; and if the reading step failed: searching the first predetermined window for identifying a third predetermined object; determining a third reference mark position on the third predetermined object; searching the second predetermined window for identifying a fourth predetermined object; determining a fourth reference mark position on the fourth predetermined object; calculating the location of the first character window, the location being relative to the third and fourth reference mark positions; and reading the first character located within the first character window. 2. A method of efficiently locating an optically recognizable character encoded on a label, comprising machine-executed steps of: locating the label; searching in a first predetermined window for identifying a first predetermined object; determining a first reference mark position on the first predetermined object; searching in a second predetermined window for identifying a second predetermined object; determining a second reference mark position on the second predetermined object; calculating a first character window location relative to the first and second reference mark positions; reading a first character located within the first character window; and if either searching step failed: searching the first predetermined window for identifying a third predetermined object; determining a third reference mark position on the third predetermined object; searching the second predetermined window for identifying a fourth predetermined object; determining a fourth reference mark position on the fourth predetermined object; calculating the location of the first character window, the location being relative to the third and fourth reference mark positions; and reading the first character located within the first character window. 3. The method according to claim 2 further comprising the machine executed step of reporting a label as missing if no predetermined objects are identified. 4. A vision system for reading coded data on a label, wherein the time required to reach each one of the coded data is reduced by accurately predicting the location of each one of the coded data by first locating first and second references positioned on the label, said vision system comprising: a processor; a memory coupled to said processor; a camera coupled to said processor; wherein said processor comprises means for searching a first image window for identifying a first object, the first object being a first portion of the label; means for searching a second image window for identifying a second object, the second object being a second portion of the label; means for determining the first reference position on the first object and the second reference position on the second object; means for predicting a first coded data window location, the location being relative to the first and second reference positions; means for instructing said processor to read the coded data; means for searching a third image window for identifying a third object if said camera failed to find the first or second object, the third object being a third portion of the label; means for searching a fourth image window for identifying a fourth object, the fourth object being a fourth portion of the label; means for determining a third reference position on the third object and a fourth reference position on the fourth object; and means for predicting the first coded data window location, the location being relative to the third and fourth reference positions. 5. The vision system according to claim 4 wherein said processor further comprises means for indicating that the label is missing if the processor fails to locate any of the objects. 6. The vision system according to claim 5 wherein the first coded data is an alpha-numeric character. 7. The vision system according to claim 5 wherein the first coded data is a bar code. 8. The vision system according to claim 5 wherein the label is a predetermined size and each of the coded data is located at a predetermined location. 9. A robotic vision system for reading coded data on a label, the label being attached to an article for identifying said article, wherein the time required to reach each one of the coded data on the label is reduced by accurately predicting the location of each one of the coded data on the label thereby reducing a size of each coded data search window, said robotic vision system comprising: a processor; a memory coupled to said processor; a camera coupled to said processor; wherein said processor comprises: means for searching a first image window for identifying a first object, the first object being a top portion of the label; means for searching a second image window for identifying a second object, the second object being a bottom portion of the label; means for determining a first reference position on the first object and a second reference position on the second object; means for predicting a first coded data window location for placing a first coded data window, the location being relative to the first and second reference positions; means for reading a first coded data; and means for searching the first and second image windows for third and fourth objects, respectively, if the processor failed to identify the first or second objects, or if the processor failed to read the first coded data. 10. The robotic vision system according to claim 9 wherein the third and fourth objects are top and bottom corners, respectively, of the label. 11. The robotic vision system according to claim 10 wherein said processor further comprises means for indicating that the label is missing if the processor fails to locate the third and fourth objects. 12. The robotic vision system according to claim 9 wherein the first coded data is an alpha-numeric character. 13. The robotic vision system according to claim 9 wherein the first coded data is a bar code. 14. The robotic vision system according to claim 9 wherein the label is a predetermined size and each of the coded data is located at a predetermined location. 15. A subsystem for controlling a robotic vision system for reading coded data on a label, wherein the time required to read each one of the coded data on the label is reduced by accurately predicting the location of each one of the coded data on the label thereby reducing a size of each coded data search window, said subsystem comprising: storage means; a processor comprising: means for searching a first image window for identifying a first object, the first object being another portion of the label; means for searching a second image window for identifying a second object, the second object being another portion of the label; means for determining a first reference position on the first object and a second reference position on the second object; means for predicting a first coded data window location for placing a first coded data window, the location being relative to the first and second reference positions; means for reading the coded data within the first coded data window; and means for searching the first end second image windows for third and fourth objects, respectively, if the processor failed to identify the first or second objects, or if the processor failed to read the coded data. 16. The program product according to claim 15 wherein the third and fourth objects are top and bottom corners, respectively, of the label. 17. The program product according to claim 16 wherein said processor further comprises means for indicating that the label is missing if the processor fails to locate the third or fourth objects. 18. The program product according to claim 17 wherein the label is a predetermined size and each of the coded data is located at a predetermined location. 