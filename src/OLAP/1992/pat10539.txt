A method and apparatus for calibrating a vision-guided robot of the type having a slit light unit for illuminating a workpiece with a target image, a camera for detecting the target image, a tool for working upon the workpiece and a controller for positioning the tool in response to image signals from the camera so that the camera signals correspond to stored image signals. The method includes the steps of displacing the robot from a home position to a calibration position wherein the camera is oriented toward a target, determining a camera correction value between a desired camera position and the actual camera position by comparing a perceived target image with a stored target image and incorporating the camera correction value for robot positioning during a subsequent operational movement. The method also includes a slit light calibration sequence in which the robot is displaced to a second calibration position where the slit light unit directs a light beam on a second target, the camera perceives a second target image and a light correction value between a desired slit light image and an actual slit light image is determined and incorporated for robot positioning during the subsequent operational movement. The calibration unit comprises topmost, intermediate and lower plates arranged in stairstep fashion, the topmost plate having a first pattern perceivable by the camera to enable the controller to determine spatial orientation of the plate and the intermediate and lower plates include a second pattern perceivable by the camera which enables the controller to determine the position of the slit light unit.
Claims I claim: 1. A method of calibrating a vision-guided robot of type having a slit light unit for illuminating a workpiece with a target image, a camera for detecting said target image, a tool for working upon said workpiece, and control means for positioning said tool in response to image signals from said camera such that said camera signals correspond to stored image signals, in order to compensate for out-of-alignment conditions of said light unit and said camera relative to said tool, comprising the steps of: (a) displacing said robot to a first calibration position (A) wherein said camera is positioned at a predetermined orientation toward a first target and perceives a first target image; (b) determining a camera correction value (M) between a desired camera spatial position relative to said tool and an actual camera spatial position relative to said tool by comparing said perceived first target image with a stored first target image; and (c) incorporating said camera correction value (M) in a stored sequence for robot tool positioning during a subsequent operational movement, thereby compensating for an out-of-alignment condition of said camera relative to said tool without actual adjustment of said camera. 2. The method of claim 1 further comprising the step of: displacing said robot to a position (A+M), then proceeding with step (b) to determine a second camera correction value (M'); and comparing (M) and (M') to determine whether said camera correction value (M) is acceptable. 3. The method of claim 1 further comprising the steps of: (d) displacing said robot to a second calibration position (B+M) wherein said slit light unit is positioned at a predetermined orientation to direct a light beam on a second target and said camera perceives a second target image; (e) determining a light correction value (N) between a desired slit light spatial position relative to said tool and an actual slit light spatial position relative to said tool by comparing said perceived second target image with a stored second target image; and (f) incorporating said light correction value (N) in said operational sequence for robot tool positioning during a subsequent operational movement, thereby compensating for an out-of-alignment condition of said slit light unit relative to said tool without actual adjustment of said slit light unit. 4. The method of claim 3 further comprising the step of: displacing said robot to a position (B+M+N) then proceeding with step (d) to determine a second light correction value (N); and comparing (N') and (N') to determine whether said light correction value (N) is acceptable. 5. The method of claim 2 further comprising the step of calibrating said robot with respect to said slit light unit if said (M') value is less in magnitude than said (M) value. 6. The method of claim 4 wherein said (N) comparing step includes the step of proceeding to a next operational step if said (N) value is greater than said (N') value. 7. The method claim 3 wherein said displacing step includes directing said slit light unit to illuminate a calibration plate having a stepped surface simulating a surface of said workpiece. 8. A calibration unit for use with a vision-guided robot of a type having a slit light unit for illuminating a workpiece with a target image, a camera for detecting said target image, a tool for working upon said workpiece, and control means for receiving image signals from said camera and positioning said tool in response to said image signals such that said image signals correspond to stored signals, the calibration unit comprising: a topmost plate having a first pattern on an upper surface thereof perceivable by said camera, said pattern being shaped to enable said control means to determine spatial orientation of said plate relative to said camera; intermediate and lower plates arranged in overlapping relation to each other and having reflective upper surfaces for receiving and reflecting said target image, each having a second pattern thereon perceivable by said camera and positioned to enable said control means to determine whether said slit light unit is centered on a predetermined point. 9. The unit of claim 8 further comprising base means for supporting said topmost, intermediate and lower plates. 10. The unit of claim 9 wherein said base means supports said plates in an overlapping, stepped relation. 11. The unit of claim 8 wherein said first pattern comprises three rows of three dots each on a lighter, contrasting background. 12. The unit of claim 8 wherrin said second pattern comprises a mark at an edge of said intermediate plate superposed to said lower plate. 13. The unit of claim 12 wherein said plates are oriented relative to each other such that said target image impinges on both of said intermediate and lower plates. 