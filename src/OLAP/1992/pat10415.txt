Apparatus and methods based on signal processing techniques are disclosed for determining the distance of an object from a camera, rapid autofocusing of a camera, and obtaining focused pictures from blurred pictures produced by a camera. The apparatus of the present invention includes a camera characterized by a set of four camera parameters: position of the image detector or film inside the camera, focal length of the optical system in the camera, the size of the aperture of the camera, and the characteristics of the light filter in the camera. In the method of the present invention, at least two images of the object are recorded with different values for the set of camera parameters. The two images are converted to a standard format to obtain two normalized images. The values of the camera parameters and the normalized images are substituted into an equation obtained by equating two expressions for the focused image of the object. The two expressions for the focused image are based on a new deconvolution formula which requires computing only the derivatives of the normalized images and a set of weight parameters dependent on the camera parameters and the point spread function of the camera. In particular, the deconvolution formula does not involve any Fourier transforms and therefore the present invention has significant advantages over prior art. The equation which results from equating two expressions for the focused image of the object is solved to obtain a set of solutions for the distance of the object. A third image of the object is then recorded with new values for the set of camera parameters. The solution for distance which is consistent with the third image and the new values for the camera parameters is determined to obtain the distance of the object. Based on the distance of the object, a set of values is determined for the camera parameters for focusing the object. The camera parameters are then set equal to these values to accomplish autofocusing. After determining the distance of the object, the focused image of the object is obtained using the deconvolution formula. A generalized version of the method of determining the distance of an object can be used to determine one or more unknown camera parameters. This generalized version is also applicable to any linear shift-invariant system for system parameter estimation and signal restoration.
Claims I claim: 1. A method of determining the distance of an object from a camera system wherein no Fourier transforms are computed, said camera system having an aperture through which light enters, an image detector, an image forming optical system having a first and a second principal plane and a focal length, said second principal plane being arranged closer to said image detector than said first principal plane, a light filter, a camera controller, and an image processor being operatively connected to said image detector and to said camera controller, said method comprising: a) setting said camera system to a first set of camera parameters including at least one of: i) distance(s) between said second principal plane and said image detector, ii) diameter (D) of said camera aperture, iii) focal length (f) of said camera system, and iv) spectral light transmission characteristic (.lambda.) of said light filter; b) forming a first image of said object with said image forming optical system; c) recording said first image in said image detector as a first digital image; d) setting said camera system to a second set of camera parameters including at least one of: i) distance(s) between said second principal plane and said image detector, ii) diameter (D) of said camera aperture, iii) focal length (f) of said camera system, and iv) spectral light transmission characteristic (.lambda.) of said light filter; e) forming a second image of said object with said image forming optical system; f) recording said second image in said image detector as a second digital image; g) supplying said first digital image to an image normalization means, said image normalization means preprocessing said first digital image to provide a first normalized image, said first normalized image being related to a first point spread function of said camera system by a convolution operation; h) supplying said second digital image to said image normalization means, said image normalization means preprocessing said second digital image to provide a second normalized image, said second normalized image being related to a second point spread function of said camera system by a convolution operation; i) providing said first normalized image to a set of differentiators, said set of differentiators providing as output a first set of image derivative values; j) providing said second normalized image to said set of differentiators, said set of differentiators providing as output a second set of image derivative values; k) transmitting said first set of camera parameters, said second set of camera parameters, said first set of image derivative values and said second set of image derivative values to an equation solving means, said equation solving means being capable of solving a first mathematical relationship to obtain a first set of solutions, said first mathematical relationship including a first expression for a focused image in terms of said first set of camera parameters and said first set of image derivative values, said first mathematical relationship including a second expression for a focused image in terms of said second set of camera parameters and said second set of image derivatives, said first set of solutions for said first mathematical relationship representing the distance of said object from said camera system; l) setting said camera system to a third set of camera parameters including at least one of: i) distance (s) between said second principal plane and said image detector, ii) diameter (D) of said camera aperture, iii) focal length (.function.) of said camera system, and iv) spectral light transmission characteristic (.lambda.) of said light filter; m) forming a third image of said object with said image forming optical system; n) recording said third image in said image detector as a third digital image; o) supplying said third digital image to said image normalization means, said image normalization means preprocessing said third digital image to provide a third normalized image, said third normalized image being related to a third point spread function of said camera system by a convolution operation; p) providing said third normalized image to said set of differentiators, said set of differentiators providing as output a third set of image derivative values; q) transmitting said second set of camera parameters, said third set of camera parameters, said second set of image derivative values and said third set of image derivative values to said equation solving means, said equation solving means being capable of solving a second mathematical relationship to obtain a second set of solutions, said second mathematical relationship including said second expression for a focused image in terms of said second set of camera parameters and said second set of image derivatives, said second mathematical relationship including a third expression for a focused image in terms of said third set of camera parameters and said third set of image derivatives, said second set of solutions for said mathematical relationship representing the distance of said object from said camera system; r) providing said first set of solutions and said second set of solutions to a set intersection means, said set intersection means being capable of comparing said first set of solutions and said second set of solutions to determine a common value representing said distance of said object from said camera system. 2. The method of claim 1 wherein the preprocessing operation performed by said image normalization means includes at least one of: (a) correcting for a sensor response characteristic of said image detector; (b) correcting for a non-uniform light transmission of said optical system; (c) magnification normalization of said first image and said second image; (d) brightness normalization of said first image and said second image; and (e) noise filtering to reduce the effects of noise. 3. The method of claim 1 wherein said first and second expression for a focused image is the result of multiplying each member of said first and second set of image derivatives by a weight parameter to obtain a first and second set of weighted image derivatives and summing corresponding members of said first and second set of weighted image derivatives. 4. The method of claim 3 wherein each said weight parameter depends on a first and a second set of moment parameters which correspondingly characterize said first and said second point spread function. 5. The method of claim 4 wherein said first point spread function is symmetric and therefore odd moment parameters in said first set of moment parameters are all zero. 6. The method of claim 1 wherein said first point spread function has a non-zero constant value inside a region having the same shape as that of said aperture except for a magnification factor and has a zero value outside of said region. 7. The method of claim 1 wherein said aperture has a circular shape and therefore said first point spread function has a non-zero constant value inside a circular region and has a zero value outside of said circular region. 8. A method of autofocusing a camera system to an object wherein no Fourier transforms are computed, said camera system having an aperture through which light enters, an image detector, an image forming optical system having a first and second principal plane and a focal length, said second principal plane being arranged closer to said image detector than said first principal plane, a light filter, a camera controller, and an image processor being operatively connected to said image detector and to said camera controller, said method comprising: a) setting said camera system to a first set of camera parameters including at least one of: i) distance(s) between said second principal plane and said image detector, ii) diameter (D) of said camera aperture, iii) focal length (.function.) of said camera system, and iv) spectral light transmission characteristic (.lambda.) of said light filter; b) forming a first image of said object with said image forming optical system; c) recording said first image in said image detector as a first digital image; d) setting said camera system to a second set of camera parameters including at least one of: i) distance (s) between said second principal plane and said image detector, ii) diameter (D) of said camera aperture, iii) focal length (.function.) of said camera system, and iv) spectral light transmission characteristic (.lambda.) of said light filter; e) forming a second image of said object with said image forming optical system; f) recording said second image in said image detector as a second digital image; g) supplying said first digital image to an image normalization means, said image normalization means preprocessing said first digital image to provide a first normalized image, said first normalized image being related to a first point spread function of said camera system by a convolution operation; h) supplying said second digital image to said image normalization means, said image normalization means preprocessing said second digital image to provide a second normalized image, said second normalized image being related to a second point spread function of said camera system by a convolution operation; i) providing said first normalized image to a set of differentiators, said set of differentiators providing as output a first set of image derivative values; j) providing said second normalized image to said set of differentiators, said set of differentiators providing as output a second set of image derivative values; k) transmitting said first set of camera parameters, said second set of camera parameters, said first set of image derivative values and said second set of image derivative values to an equation solving means, said equation solving means being capable of solving a first mathematical relationship to obtain a first set of solutions, said first mathematical relationship including a first expression for a focused image in terms of said first set of camera parameters and said first set of image derivative values, said first mathematical relationship including a second expression for a focused image in terms of said second set of camera parameters and said second set of image derivatives, said first set of solutions for said first mathematical relationship representing the distance of said object from said camera system; l) setting said camera system to a third set of camera parameters including at least one of: i) distance (s) between said second principal plane and said image detector, ii) diameter (D) of said camera aperture, iii) focal length (.function.) of said camera system, and iv) spectral light transmission characteristic (.lambda.) of said light filter; m) forming a third image of said object with said image forming optical system; n) recording said third image in said image detector as a third digital image; o) supplying said third digital image to said image normalization means, said image normalization means preprocessing said third digital image to provide a third normalized image, said third normalized image being related to a third point spread function of said camera system by a convolution operation; p) providing said third normalized image to said set of differentiators, said set of differentiators providing as output a third set of image derivative values; q) transmitting said second set of camera parameters, said third set of camera parameters, said second set of image derivative values and said third set of image derivative values to said equation solving means, said equation solving means being capable of solving a second mathematical relationship to obtain a second set of solutions, said second mathematical relationship including said second expression for a focused image in terms of said second set of camera parameters and said second set of image derivatives, said second mathematical relationship including a third expression for a focused image in terms of said third set of camera parameters and said third set of image derivatives, said second set of solutions for said mathematical relationship representing the distance of said object from said camera system; r) providing said first set of solutions and said second set of solutions to a set intersection means, said set intersection means being capable of comparing said first set of solutions and said second set of solutions to determine a common value representing said distance of said object from said camera system. s) computing a new set of camera parameter values for focusing said object based on the distance of said object from said camera system and setting said camera system to said new set of camera parameter values whereby said camera system is autofocused to said object. 9. The method of claim 8 wherein the preprocessing operation performed by said image normalization means includes at least one of: (a) correcting for a sensor response characteristic of said image detector; (b) correcting for a non-uniform light transmission of said optical system; (c) magnification normalization of said first image and said second image; (d) brightness normalization of said first image and said second image; and (e) noise filtering to reduce the effects of noise. 10. The method of claim 8 wherein said first expression for a focused image is obtained by multiplying each member of said first set of image derivatives by a weight parameter to obtain a first set of weighted image derivatives and wherein all members of said first set of weighted image derivatives are added. 11. The method of claim 8 wherein said second expression for a focus image is obtained by multiplying each member of said second set of image derivatives by a weight parameter to obtain a second set of weighted image derivatives and wherein all members of said second set of weighted image derivatives are added. 12. The method of claim 10 wherein each said weight parameter depends on a first set of moment parameters which correspondingly characterize said first point spread function. 13. The method of claim 11 wherein each said weight parameter depends on a second set of moment parameters which correspondingly characterize said second point spread function. 14. The method of claim 12 wherein said first point spread function is symmetric and odd moment parameters in said first set of moment parameters are all zero. 15. The method of claim 8 wherein said first point spread function has a non-zero constant value inside a region having the same shape as that of said aperture except for a magnification factor and has a zero value outside of said region. 16. The method of claim 8 wherein said aperture has a circular shape and therefore said first point spread function has a non-zero constant value inside a circular region and has a zero value outside of said circular region. 17. A method of obtaining a focused image of an object from a blurred image of said object, wherein no Fourier transforms are computed, said blurred image formed in a camera system, said camera system having an aperture through which light enters, an image detector, an image forming optical system having a first and a second principal plane and a focal length, said second principal plane being arranged closer to said image detector than said first principal plane, a light filter, a camera controller, and an image processor being operatively connected to said image detector and to said camera controller, said method comprising: a) setting said camera system to a first set of camera parameters including at least one of: i) distance(s) between said second principal plane and said image detector, ii) diameter (D) of said camera aperture, iii) focal length (.function.) of said camera system, and iv) spectral light transmission characteristic (.lambda.) of said light filter; b) forming a first image of said object with said image forming optical system; c) recording said first image in said image detector as a first digital image; d) setting said camera system to a second set of camera parameters including at least one of: i) distance (s) between said second principal plane and said image detector, ii) diameter (D) of said camera aperture, iii) focal length (.function.) of said camera system, and iv) spectral light transmission characteristic (.lambda.) of said light filter; e) forming a second image of said object with said image forming optical system; f) recording said second image in said image detector as a second digital image; g) supplying said first digital image to an image normalization means, said image normalization means preprocessing said first digital image to provide a first normalized image, said first normalized image being related to a first point spread function of said camera system by a convolution operation; h) supplying said second digital image to said image normalization means, said image normalization means preprocessing said second digital image to provide a second normalized image, said second normalized image being related to a second point spread function of said camera system by a convolution operation; i) providing said first normalized image to a set of differentiators, said set of differentiators providing as output a first set of image derivative values; j) providing said second normalized image to said set of differentiators, said set of differentiators providing as output a second set of image derivative values; k) transmitting said first set of camera parameters, said second set of camera parameters, said first set of image derivative values and said second set of image derivative values to an equation solving means, said equation solving means being capable of solving a first mathematical relationship to obtain a first set of solutions, said first mathematical relationship including a first expression for said focused image in terms of said first set of camera parameters and said first set of image derivative values, said first mathematical relationship including a second expression for said focused image in terms of said second set of camera parameters and said second set of image derivatives, said first set of solutions for said first mathematical relationship representing the distance of said object from said camera system; l) setting said camera system to a third set of camera parameters including at least one of: i) distance (s) between said second principal plane and said image detector, ii) diameter (D) of said camera aperture, iii) focal length (.function.) of said camera system, and iv) spectral light transmission characteristic (.lambda.) of said light filter; m) forming a third image of said object with said image forming optical system; n) recording said third image in said image detector as a third digital image; o) supplying said third digital image to said image normalization means, said image normalization means preprocessing said third digital image to provide a third normalized image, said third normalized image being related to a third point spread function of said camera system by a convolution operation; p) providing said third normalized image to said set of differentiators, said set of differentiators providing as output a third set of image derivative values; q) transmitting said second set of camera parameters, said third set of camera parameters, said second set of image derivative values and said third set of image derivative values to said equation solving means, said equation solving means being capable of solving a second mathematical relationship to obtain a second set of solutions, said second mathematical relationship including said second expression for a focused image in terms of said second set of camera parameters and said second set of image derivatives, said second mathematical relationship including a third expression for a focused image in terms of said third set of camera parameters and said third set of image derivatives, said second set of solutions for said mathematical relationship representing the distance of said object from said camera system; r) providing said first set of solutions and said second set of solutions to a set intersection means, said set intersection means being capable of comparing said first set of solutions and said second set of solutions to determine a common value representing said distance of said object from said camera system; s) substituting the values of said first set of camera parameter values, said first set of image derivatives, and the distance of said object from said camera system into said first expression to obtain said focused image of said object. 18. Apparatus for determining the distance of an object from a camera system, said apparatus comprising a camera system characterized by a set of camera parameters, a camera controller for setting said set of camera parameters to desired values, an image forming optical system for forming images of said object, an image detector for recording images of said object, an image normalization means for normalizing images of said object, a derivative computation means for computing derivatives of normalized images, an equation solving means capable of solving a plurality of mathematical relationships having values of different derivatives of normalized images and camera parameter values, and a set intersection means for comparing at least two sets of solutions provided by said equation solving means and determining a common value representing the distance of said object from said camera system. 19. The apparatus of claim 18 which further includes a focus parameter determination means for determining a value for said set of camera parameters based on the distance of said object from said camera so that said object is focused by setting said set of camera parameters to the value determined by said focus parameter determination means. 20. The apparatus of claim 18 which further includes a focused image determination means which takes as input a set of derivatives of a blurred image of said object, values of said set of camera parameters, distance of said object from said camera and uses a deconvolution formula to give as output the focused image of said object without computing any Fourier transforms. 