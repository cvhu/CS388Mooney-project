The invention provides methods of protecting selected regions of an image from subsequent modification during the operation of a graphics application. The methods allow a user to select a region of an image to protect, and to assign a level of protection to the selected region. Subsequent brush strokes in the region are then attenuated according to the assigned level of protection and blended into the image without artifacts caused by overlapping strokes. The invention also provides a method of blending individual strokes into a texture without segmentation artifacts.
Claims What is claimed is: 1. A method of protecting a selected region of an image from subsequent editing, the method comprising the steps of: (a) creating a first texture comprising a plurality of pixels each with an assigned scalar value indicating a level of protection for a corresponding pixel of a protected image; (b) following a first user signal, directing graphical input representing a plurality of brush strokes performed by the user into a second texture, wherein the protected image is at least initially unedited by the graphical input and wherein the plurality of brush strokes comprises at least one overlapping portion; (c) modifying a value of at least one pixel of the second texture using the first texture; (d) only following completion of step (b) and following a second user signal subsequent to the first user signal, blending at least one pixel of the second texture into the protected image; and (e) displaying an image based on the result of step (d). 2. The method of claim 1, wherein the at least one overlapping portion corresponds to an area overlapped by a plurality of brush strokes. 3. The method of claim 1, wherein the plurality of brush strokes comprises at least one member selected from the group consisting of a paint stroke, an erase stroke, a pencil stroke, a pen stroke, a line application, a character application, a text application, a batch deletion, a batch paste, and a flood fill. 4. The method of claim 3, further comprising the step of generating the graphical input of step (b), wherein the graphical input corresponds to a movement of a user. 5. The method of claim 4, wherein the step of generating the graphical input comprises assigning scalar values to pixels of a scratch texture that correspond to a transition region at one or more edges of a brush stroke. 6. The method of claim 4, wherein the graphical input comprises a scratch texture representing a brush stroke and step (b) comprises blending the scratch texture into the second texture substantially upon completion of the brush stroke. 7. The method of claim 6, wherein the step of blending the scratch texture into the second texture comprises performing a compositing operation. 8. The method of claim 7, wherein the compositing operation is an overlay operation performed with pixels of A and B, where A comprises pixels having a paint color attenuated by the scratch texture and B comprises the second texture. 9. The method of claim 4, wherein the step of generating the graphical input comprises the step of, for each of at least a plurality of pixels of a scratch texture: (i) comparing a candidate scalar value from received data to an existing scalar value at a corresponding pixel of the scratch texture; and (ii) assigning the candidate scalar value to the corresponding pixel of the scratch texture only if the candidate scalar value exceeds the existing scalar value. 10. The method of claim 1, wherein the graphical input represents at least one brush stroke performed by a user, and wherein the at least one brush stroke comprises at least one overlapping portion corresponding to an area of a single brush stroke that overlaps itself. 11. The method of claim 1, further comprising the steps of: (i) copying at least one pixel of the protected image into a display image; and (ii) blending at least one pixel of the second texture into the display image. 12. The method of claim 11, wherein step (i) and step (ii) are each performed prior to step (d). 13. The method of claim 11, wherein at least one of step (c) and step (ii) proceeds pixel-by-pixel as the second texture accumulates graphical input. 14. The method of claim 11, wherein step (i) and step (ii) are each performed prior to step (d), and wherein at least one of step (c) and step (ii) proceeds pixel-by-pixel as the second stencil texture accumulates graphical input. 15. The method of claim 1, wherein the graphical input represents at least one erase stroke performed by a user. 16. The method of claim 15, further comprising the step of: (i) modifying a value of at least one pixel in the protected image using the first texture. 17. The method of claim 16, wherein step (i) comprises attenuating a value of a pixel in the protected image subject to a minimum RGB.alpha. alpha value, where the minimum alpha value is determined using the first texture. 18. The method of claim 1, wherein the graphical input represents at least one paint stroke and at least one erase stroke performed by a user. 19. The method of claim 1, wherein step (c) comprises attenuating values of pixels of the second texture using values of corresponding pixels in the first texture. 20. The method of claim 1, wherein step (d) comprises performing a compositing operation. 21. The method of claim 20, wherein the compositing operation is an overlay operation performed with pixels of A and B, where A comprises the second texture and B comprises the protected image. 22. The method of claim 21, wherein A comprises the second texture as modified in step (c). 23. The method of claim 1, wherein step (c) and step (d) are performed substantially simultaneously. 24. The method of claim 1, wherein the assigned scalar value of a pixel in the first texture indicates a level of protection from 0% to 100%. 25. The method of claim 24, wherein the level of protection corresponds to a nonzero opacity less than 100%, thereby preventing opacity of the selected region of the protected image from decreasing below the specified nonzero opacity. 26. The method of claim 24, wherein the level of protection relates to an opacity. 27. The method of claim 1, wherein the protected image is unedited by the graphical input of step (b) until the blending in step (d). 28. The method of claim 1, wherein the graphical input in step (b) represents a plurality of paint strokes performed by the user between the first user signal and the second user signal. 29. The method of claim 1, wherein the first user signal is a button click. 30. The method of claim 1, wherein the first texture represents at least one user-selected region of the image. 31. A method of protecting a selected region of an image from subsequent editing, the method comprising the steps of: (a) creating a first texture comprising a plurality of pixels each with an assigned scalar value indicating a level of protection for a corresponding pixel of a protected image; (b) directing graphical input comprising at least one erase stroke into a second texture, wherein the protected image is at least initially unedited by the graphical input; (c) modifying a value of at least one pixel of the second texture using the first texture; (d) attenuating a value of a pixel in the protected image subject to a minimum RGB.alpha. alpha value determined from the first texture; (e) blending at least one pixel of the second texture into the protected image; and (f) displaying an image based on the result of step (e). 32. The method of claim 31, wherein the graphical input further comprises at least one member selected from the group consisting of a paint stroke, a pencil stroke, a pen stroke, a line application, a character application, a text application, a batch deletion, a batch paste, and a flood fill. 33. The method of claim 31, wherein the graphical input comprises a plurality of erase strokes comprising at least one overlapping portion. 34. The method of claim 31, wherein the assigned scalar value of a pixel in the first texture indicates a level of protection from 0% to 100%. 35. The method of claim 34, wherein the level of protection is a nonzero value less than 100%. 36. The method of claim 34, wherein the level of protection relates to an opacity. 37. An apparatus for protecting a selected region of an image from subsequent editing, the apparatus comprising: (a) a graphical user interface device; and (b) a processor configured to run software that: (i) creates a first texture comprising a plurality of pixels each with an assigned scalar value indicating a level of protection for a corresponding pixel of a protected image; (ii) following a first user signal, directs graphical input from the graphical user interface device into a second texture, wherein the graphical input represents a plurality of brush strokes performed by the user, wherein the protected image is at least initially unedited by the graphical input, and wherein the plurality of brush strokes comprises at least one overlapping portion; (iii) modifies a value of at least one pixel of the second texture using the first texture; (iv) only after completion of (ii) and following a second user signal subsequent to the first user signal, blends at least one pixel of the second texture into the protected image; and (v) displays an image based on the result of (iv). 38. The apparatus of claim 37, wherein the plurality of brush strokes comprises at least one member selected from the group consisting of a paint stroke, an erase stroke, a pencil stroke, a pen stroke, a line application, a character application, a text application, a batch deletion, a batch paste, and a flood fill. 39. The apparatus of claim 37, wherein the assigned scalar value of a pixel in the first texture indicates a level of protection from 0% to 100%. 40. The apparatus of claim 39, wherein the level of protection corresponds to a nonzero value less than 100%, thereby preventing opacity of the selected region of the protected image from decreasing below the specified nonzero opacity. 41. The apparatus of claim 39, wherein the level of protection relates to an opacity. 42. The apparatus of claim 37, wherein the protected image is unedited by the graphical input of (ii) until the blending in (iv). 