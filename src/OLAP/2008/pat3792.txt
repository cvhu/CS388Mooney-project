A wireless substrate-like sensor is provided to facilitate alignment and calibration of semiconductor processing systems. The wireless substrate-like sensor includes an optical image acquisition system that acquires one or more images of targets placed within the semiconductor processing system. Analysis of images of the targets obtained by the wireless substrate-like sensor provides position and/or orientation information in at least three degrees of freedom. An additional target is affixed to a known location within the semiconductor processing system such that imaging the reference position with the wireless substrate-like sensor allows the measurement and compensation for pick-up errors.
Claims What is claimed is: 1. A method for determining position and orientation of a flat target in three dimensions, the method comprising: providing at least four reference target indicia on a reference target and fixing the reference target's position; removably coupling an image acquisition system to a robot such that the image acquisition system is movable by the robot; digitizing an image of the reference target with the image acquisition system; identifying the at least four reference target indicia in the image of the reference target; providing at least four station target indicia on a station target; digitizing an image of the station target with the image acquisition system; identifying the at least four station target indicia in the image of the station target; calculating the relative position and orientation between the station target and the robot based upon identification of the at least four reference target indicia and the at least four station target indicia. 2. The method of claim 1, wherein the station target indicia are shaped circularly. 3. The method of claim 1, wherein the robot is a material handling robot. 4. The method of claim 1, wherein the image acquisition system is embodied within a substrate-like sensor. 5. The method of claim 1, wherein the station target is fixedly attached relative to a processing tool. 6. The method of claim 1 wherein digitizing the image of the reference target with the image acquisition system comprises moving the image acquisition system with the robot to a position proximate the reference target, and wherein digitizing the image of the station target with the image acquisition system comprises moving the image acquisition system with the robot to a position proximate the station target. 7. The method of claim 1, wherein the station target is fixedly attached relative to a station component. 8. The method of claim 1, and further comprising decoupling the image acquisition system from the robot. 9. The method of claim 1, wherein the image acquisition system includes an area array device. 10. The method of claim 1, wherein the at least four station target indicia have high contrast with respect to a background of the station target. 11. The method of claim 9, wherein the area array device is a Charge Coupled Device (CCD). 12. The method of claim 9, wherein the area array device is a Complementary Metal Oxide Semiconductor (CMOS) image device. 13. The method of claim 10, wherein the at least four station target indicia are dark, and the background of the station target is light. 14. The method of claim 10, wherein the at least four station target indicia are raised above a surface of the station target. 15. A method for determining position and orientation of a flat target in three dimensions, the method comprising: providing at least four reference target indicia on a reference target and fixing the reference target's position; removably coupling acquisition system to a robot such that the image acquisition system is movable by the robot; digitizing an image of the reference target with the image acquisition system; identifying the at least four reference target indicia in the image of the reference target; providing at least four station target indicia on a station target; digitizing an image of the station target with the image acquisition a system; identifying the at least four station tar et indicia in the image of the station target; calculating the relative position and orientation between the station target and the robot based upon identification of the at least four station target indicia in the image of the station target; and calculating the relative position and orientation between the image acquisition system and the robot based upon identification of the at least four reference target indicia in the image of the reference target. 16. The method of claim 15, wherein calculating the relative position and orientation between the station target and the robot comprises: calculating the relative position and orientation between the station target and the robot as a function of the calculated relative position between the image acquisition system and the robot. 17. A method for determining position and orientation of a station component in three dimensions, the method comprising: providing a reference target and fixing the reference target's position with respect to a robot; providing a station target having at least four indicia on a station component; removably coupling an image acquisition system to the robot such that the image acquisition system is movable by the robot; digitizing an image of the reference target with the image acquisition system; calculating the relative position and orientation between the image acquisition system and the robot based on the digitized image of the reference target; digitizing an image of the station target with the image acquisition system; identifying the at least four indicia in the image of the station target; and calculating the relative position and orientation between the station component and the robot as a function of the identification of the at least four indicia in the image of the station target and as a function of the calculated relative position between the image acquisition system and the robot. 18. The method of claim 17, wherein the image acquisition system is embedded within a substrate-like sensor. 19. The method of claim 17, and further comprising decoupling the image acquisition system from the robot. 20. The method of claim 17, wherein calculating the relative position and orientation between the image acquisition system and the robot comprises: identifying at least four reference indicia in the image of the reference target; and calculating the relative position and orientation between the image acquisition system and the robot based upon identification of the at least four reference target indicia in the image of the reference target. 