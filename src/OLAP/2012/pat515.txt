The present invention creates and stores target representations in several coordinate representations based on biologically inspired models of the human vision system. By using biologically inspired target representations a computer can be programmed for robot control without using kinematics to relate a target position in camera eyes to a target position in body or head coordinates. The robot sensors and appendages are open loop controlled to focus on the target. In addition, the invention herein teaches a scenario and method to learn the mappings between coordinate representations using existing machine learning techniques such as Locally Weighted Projection Regression.
Claims What is claimed is: 1. A method of learning a mapping between an eye centered coordinate representation and a head centered coordinate representation given an initial estimate of the mapping and a set of targets each with a known eye centered coordinate representation comprising: initializing the method by estimating the head centered coordinate representation for each target using the initial estimate of the mapping and the eye centered coordinate representation for each target; executing the following steps; a) selecting a target in a field of view of a first eye camera and a second eye camera; b) retrieving the eye centered coordinate representation for the target; c) commanding the first eye camera and the second eye camera to foveate on the target by moving the first eye camera and the second eye camera; d) computing the true head centered coordinate representation of the target; e) updating the mapping from eye centered coordinate representation to head centered coordinate representation using the true head centered coordinate representation for the target and the estimated head centered coordinate representations for all previously viewed targets; f) updating the estimated head centered coordinate representations for all targets previously foveated; g) computing the change in mapping; repeating steps a-g if the change in mapping is greater than a user defined threshold otherwise ending the method. 2. The method of claim 1 wherein updating the mapping is done using a locally weighted projection regression method. 3. A method of learning a mapping between a head centered coordinate representation and a body centered coordinate representation given an initial estimate of the mapping and a set of targets each with a known eye centered coordinate representation comprising: a) selecting a target from the set of targets in a field of view of a first eye camera and a second eye camera wherein the first eye camera and the second eye camera are pivotally mounted on a head and the head is pivotally mounted on a body; b) while the head is not looking directly at the target, generate a set of training points as follows; i) move the head by a user defined increment; ii) foveate on the target with the first eye camera and the second eye camera; iii) compute a training point as an estimated body centered coordinate representation, an estimated head centered coordinate representation, the head pan angle and the head tilt angle; d) repeat steps i-iii above until the head is pointed directly at the target; e) computing the true body centered coordinate representation for the target; f) updating the mapping using the true body centered coordinate representation of the target and the set of training points generated for the target; h) computing the change in mapping; repeating steps a-h if the change in mapping is greater than a user defined threshold otherwise end the method. 4. The method of claim 3 where the set of targets is substantially uniformly distributed in the field of view of a first eye camera and a second eye camera. 5. The method of claim 3 wherein updating the mapping is done using a locally weighted projection regression method. 6. A computer program product for representing targets, the computer program product comprising means, stored on a non-transitory computer readable medium, for: representing at least one target by a plurality of coordinate representations, sensor values and angle commands collectively; mapping between at least two coordinate representations; implementing at least one training scenario that implements a learning method for learning the mapping between at least two of the coordinate representations wherein the plurality of coordinate representations comprises; at least one eye centered coordinate representation of the at least one target; at least one head centered coordinate representation of the at least one target; and at least one body centered coordinate representation of the at least one target; a first current pan and a first current tilt angles of a first eye camera; a first current pan and a first current tilt angles of a second eye camera; first current pan and a first current tilt angles of a head. 