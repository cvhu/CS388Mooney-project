A method for controlling a surgical device is provided. The method includes manipulating the surgical device to perform a procedure on a patient; determining whether a relationship between an anatomy of the patient and a position, an orientation, a velocity, and/or an acceleration of a surgical tool of the surgical device corresponds to a desired relationship between the anatomy and the position, the orientation, the velocity, and/or the acceleration of the surgical tool; and imposing a constraint on the surgical device if the relationship does not correspond to the desired relationship and/or a detection device is unable to detect a position of the anatomy and/or the position of the surgical tool.
Claims What is claimed is: 1. A method for controlling a surgical device, comprising the steps of: manipulating the surgical device to perform a procedure on a patient; determining whether a relationship between an anatomy of the patient and at least one of a position, an orientation, a velocity, and an acceleration of a surgical tool of the surgical device corresponds to a desired relationship between the anatomy and the at least one of the position, the orientation, the velocity, and the acceleration of the surgical tool; imposing a constraint on the surgical device if a detection device is unable to detect at least one of a position of the anatomy and the position of the surgical tool; determining whether the surgical tool is interacting with a virtual boundary associated with the anatomy; and deactivating the virtual boundary if the surgical tool is not interacting with the virtual boundary. 2. The method of claim 1, wherein the desired relationship is defined by at least one parameter generated by a haptic rendering algorithm. 3. The method of claim 1, wherein the step of determining whether the relationship corresponds to the desired relationship includes determining whether the surgical device has violated at least one parameter generated by a haptic rendering algorithm. 4. The method of claim 1, wherein the step of determining whether the relationship corresponds to the desired relationship includes determining whether a penetration depth of the surgical tool into a virtual boundary associated with the anatomy exceeds a predetermined threshold. 5. The method of claim 1, wherein the step of determining whether the relationship corresponds to the desired relationship includes determining whether a velocity of at least one of the anatomy, a tracked object, and a tracking element disposed on a tracked object exceeds a predetermined threshold. 6. The method of claim 1, wherein the step of determining whether the relationship corresponds to the desired relationship includes determining whether a position of at least one of the anatomy, a tracked object, and a tracking element disposed on a tracked object is outside a predetermined boundary. 7. The method of claim 1, wherein the step of determining whether the relationship corresponds to the desired relationship includes determining whether an output force of the surgical device exceeds a predetermined threshold. 8. The method of claim 1, further comprising the step of implementing control parameters for controlling the surgical device to provide at least one of haptic guidance to the user and a limit on user manipulation of the surgical device, based on the relationship between the anatomy and the at least one of the position, the orientation, the velocity, and the acceleration of the surgical tool. 9. The method of claim 1, wherein the step of imposing the constraint includes at least one of limiting movement of at least a portion of the surgical device and limiting operation of the surgical device. 10. The method of claim 1, wherein the constraint includes at least one parameter generated by a haptic rendering algorithm. 11. The method of claim 1, further comprising the step of: removing the imposed constraint after a predetermined time interval from the time of imposing the constraint. 12. The method of claim 1, further comprising the steps of: detecting with the detection device a first object comprising at least one of the anatomy and a tracking element associated with the anatomy; detecting with the detection device a second object comprising at least one of the surgical device and a tracking element associated with the surgical device; and providing an indication to a user if the detection device is unable to detect at least one of the first object and the second object. 13. The method of claim 12, further comprising the step of enabling the surgical device only if the detection device detects the first object and the second object. 14. A system for controlling a surgical device, comprising: a surgical tool coupled to the surgical device, the surgical device configured to be manipulated by a user to perform a procedure on a patient; and a computing system programmed to: determine whether a relationship between an anatomy of the patient and at least one of a position, an orientation, a velocity, and an acceleration of the surgical tool corresponds to a desired relationship between the anatomy and the at least one of the position, the orientation, the velocity, and the acceleration of the surgical tool, impose a constraint on the surgical device if a detection device is unable to detect at least one of a position of the anatomy and the position of the surgical tool; determine whether the surgical tool is interacting with a virtual boundary associated with the anatomy, and deactivate the virtual boundary if the surgical tool is not interacting with the virtual boundary. 15. The system of claim 14, wherein the desired relationship is defined by at least one parameter generated by a haptic rendering algorithm. 16. The system of claim 14, wherein the computing system is programmed to: determine whether the surgical device has violated at least one parameter generated by a haptic rendering algorithm. 17. The system of claim 14, wherein the computing system is programmed to: determine whether a penetration depth of the surgical tool into a virtual boundary associated with the anatomy exceeds a predetermined threshold. 18. The system of claim 14, wherein the computing system is programmed to: determine whether a velocity of at least one of the anatomy, a tracked object, and a tracking element disposed on a tracked object exceeds a predetermined threshold. 19. The system of claim 14, wherein the computing system is programmed to: determine whether a position of at least one of the anatomy, a tracked object, and a tracking element disposed on a tracked object is outside a predetermined boundary. 20. The system of claim 14, wherein the computing system is programmed to: determine whether an output force of the surgical device exceeds a predetermined threshold. 21. The system of claim 14, wherein the computing system is programmed to: implement control parameters for controlling the surgical device to provide at least one of haptic guidance to the user and a limit on user manipulation of the surgical device based on the relationship between the anatomy and the at least one of the position, the orientation, the velocity, and the acceleration of the surgical tool. 22. The system of claim 14, wherein the computing system is programmed to: impose the constraint by limiting at least one of operation of the surgical device and movement of at least a portion of the surgical device. 23. The system of claim 14, wherein the constraint includes at least one parameter generated by a haptic rendering algorithm. 24. The system of claim 14, wherein the computing system is programmed to: remove the imposed constraint after a predetermined time interval from the time of imposing the constraint. 25. The system of claim 14, wherein the computing system is programmed to: detect with the detection device a first object comprising at least one of the anatomy and a tracking element associated with the anatomy; detect with the detection device a second object comprising at least one of the surgical device and a tracking element associated with the surgical device; and provide an indication to the user if the detection device is unable to detect at least one of the first object and the second object. 26. The system of claim 25, wherein the computing system is programmed to: enable the surgical device only if the detection device detects the first object and the second object. 27. A method for controlling a surgical device, comprising the steps of: manipulating the surgical device to perform a procedure on a patient; determining whether a relationship between an anatomy of the patient and at least one of a position, an orientation, a velocity, and an acceleration of a surgical tool of the surgical device corresponds to a desired relationship between the anatomy and the at least one of the position, the orientation, the velocity, and the acceleration of the surgical tool; imposing a constraint on the surgical device if a detection device is unable to detect at least one of a position of the anatomy and the position of the surgical tool; and removing the imposed constraint after a predetermined time interval from the time of imposing the constraint. 28. A system for controlling a surgical device, comprising: a surgical tool coupled to the surgical device, the surgical device configured to be manipulated by a user to perform a procedure on a patient; and a computing system programmed to: determine whether a relationship between an anatomy of the patient and at least one of a position, an orientation, a velocity, and an acceleration of the surgical tool corresponds to a desired relationship between the anatomy and the at least one of the position, the orientation, the velocity, and the acceleration of the surgical tool; impose a constraint on the surgical device if a detection device is unable to detect at least one of a position of the anatomy and the position of the surgical tool; and remove the imposed constraint after a predetermined time interval from the time of imposing the constraint. 