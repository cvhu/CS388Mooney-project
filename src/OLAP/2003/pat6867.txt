A surgical navigation system has a computer with a memory and display connected to a surgical instrument or pointer and position tracking system, so that the location and orientation of the pointer are tracked in real time and conveyed to the computer. The computer memory is loaded with data from an MRI, CT, or other volumetric scan of a patient, and this data is utilized to dynamically display 3-dimensional perspective images in real time of the patient's anatomy from the viewpoint of the pointer. The images are segmented and displayed in color to highlight selected anatomical features and to allow the viewer to see beyond obscuring surfaces and structures. The displayed image tracks the movement of the instrument during surgical procedures. The instrument may include an imaging device such as an endoscope or ultrasound transducer, and the system displays also the image for this device from the same viewpoint, and enables the two images to be fused so that a combined image is displayed. The system is adapted for easy and convenient operating room use during surgical procedures.
Claims What is claimed is: 1. A method of image-enhanced endoscopy at a patient site, comprising: (a) acquiring volumetric scan data of the patient site; (b) manipulating in a region of the patient site, an endoscope having a lens with a known conical field of view; (c) displaying in real time, a perspective image of patient surface features generated by the endoscope; (d) registering the scan data with the position of the patient; (e) determining the position and orientation of the endoscope with respect to the position of the patient, thereby determining the position of the endoscope with respect to the scan data; (f) constructing from the volumetric scan data, a perspective image of the patient site, as seen from the position, orientation, and conical field of view of the endoscope, where image surface structures can be represented by surface renderings or volume renderings and where image subsurface structures can be represented by surface renderings or volume renderings, different structures being represented by different opacities; and (g) displaying at a selected opacity setting, the constructed perspective image of the patient site, allowing the user to view the constructed perspective endoscopic-view image of surface or subsurface structures of the patient overlaid on obstructing surfaces and objects from the position, orientation, and conical field of view of the endoscope. 