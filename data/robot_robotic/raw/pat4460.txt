An optical 3D digitizer with an enlarged non-ambiguity zone, comprising a structured light projector for projecting a fringe pattern over a target area, the fringe pattern having a shiftable position over the target area is disclosed. First and second cameras having overlapping measurement fields are directed toward the target area and positioned with respect to the projector to define distinct triangulation planes therewith. The second camera has a larger non-ambiguity depth than the first camera. A computer evaluates a same set of camera-projector related functions from images captured by the cameras including the projected pattern at shifted positions, builds low depth resolution and degenerated 3D models from the camera-projector related functions evaluated with respect to the second and first cameras respectively, determines chromatic texture from the images, and builds a complete textured 3D model from data corresponding between the low depth resolution and degenerated 3D models within a tolerance range.
Claims The invention claimed is: 1. An optical 3D digitizer with an enlarged non-ambiguity zone, comprising: at least one structured light projector for projecting a fringe pattern over a target area, the fringe pattern having a shiftable position over the target area; a first camera directed toward the target area and positioned with respect to said at least one structured light projector to define a first triangulation plane therewith; a second camera directed toward the target area and positioned with respect to said at least one structured light projector to define a second triangulation plane therewith, the second triangulation plane being distinct from the first triangulation plane, the first and second cameras having at least partially overlapping measurement fields, the second camera having a larger non-ambiguity depth than the first camera; and a computer means connected to the cameras, for performing an image processing of images captured by the cameras, the image processing including evaluating a same set of camera-projector related functions from images including the pattern projected by said at least one structured light projector at shifted positions as captured by the cameras, building a low depth resolution 3D model from the camera-projector related functions evaluated with respect to the second camera, building a degenerated 3D model from the camera-projector related functions evaluated with respect to the first camera, determining chromatic texture from the images captured by the cameras, and building a complete textured 3D model from data corresponding between the low depth resolution and degenerated 3D models within a tolerance range. 2. The optical 3D digitizer according to claim 1, wherein the fringe pattern has a periodic sinusoidal section profile. 3. The optical 3D digitizer according to claim 1, wherein the set of camera-projector related functions comprises relations determined from phase shifting algorithms used in phase shifting interferometry. 4. The optical 3D digitizer according to claim 1, wherein the set of camera-projector related functions comprises relations determined from spatial phase shifting algorithms relying on a single fringe image in temporal phase shifting interferometry. 5. The optical 3D digitizer according to claim 1, wherein the images captured by the cameras including the pattern projected by said at least one structured light projector are written as: I.sub.n(i,j)=I.sub.Ave(i,j)+I.sub.Mod(i,j)[1+cos(.phi.(i,j)+m(i,j)2.pi.+(- n=1).alpha.)] where I represents one of the images, n represents a shift position of the pattern, i,j represent pixel coordinates in said one of the images, I.sub.Ave (i,j) represents a local intensity diffused or reflected back to the camera which captured said one of the images, including surrounding ambient light and local temporal average intensity of the pattern, I.sub.Mod (i,j) represents a local amplitude modulation of the pattern, .phi.(i,j) represents a local phase function wrapped over 2.pi. range, m(i,j) represents a local order of the phase function, and .alpha. a represents a 90.degree. phase shift. 6. The optical 3D digitizer according to claim 1, wherein the camera-projector related functions comprise a phase function, a phase-shift function, an amplitude modulation function and an average function. 7. The optical 3D digitizer according to claim 6, wherein the computer means evaluates the chromatic texture from the amplitude modulation function and the average function using separate color channels. 8. The optical 3D digitizer according to claim 6, wherein the computer means evaluates the set of camera-projector related functions using: .phi..function..times..times..function..function..function..function..fun- ction..function..function..function..function..function..function..functio- n..function..function..function..alpha..function..times..times..function..- times..function..function..function..function..function..function..functio- n..function. ##EQU00002## where I represents one of the images, n represents a shift position of the pattern, i,j represent pixel coordinates in said one of the images, I.sub.Ave (i,j) represents a local intensity diffused or reflected back to the camera which captured said one of the images, including surrounding ambient light and local temporal average intensity of the pattern, I.sub.Mod (i,j) represents a local amplitude modulation of the pattern, .phi.(i,j) represents a local phase function wrapped over 2.pi. range, and .alpha. represents a phase shift; and wherein a local order of the phase function m(i,j) is evaluated directly. 9. The optical 3D digitizer according to claim 8, wherein the computer means builds the low depth resolution and degenerated 3D models using look-up tables. 10. The optical 3D digitizer according to claim 1, wherein the image processing includes comparing the camera-projector related functions of the cameras and pixel coordinates in the images captured by the cameras, determining rejection of pixels without correspondences if a field of view of the second camera is entirely covered by the first camera, attaching pixels showing acceptable functions to surrounding pixels by local phase unwrapping, and extracting 3D coordinates forming the complete textured 3D model using table data for building the low depth resolution 3D model applied to corrected order values and current phase values. 11. A computer apparatus for performing an image processing of images captured by first and second cameras, the second camera having a larger non-ambiguity depth than the first camera, comprising: means for evaluating a same set of camera-projector related functions from images captured by the cameras, at least some of the images including a pattern projected at shifted positions; means for building a low depth resolution 3D model from the camera-projector related functions evaluated with respect to the second camera; means for building a degenerated 3D model from the camera-projector related functions evaluated with respect to the first camera; means for determining chromatic texture from the images captured by the cameras; and means for building a complete textured 3D model from data corresponding between the low depth resolution and degenerated 3D models within a tolerance range. 12. A computer readable medium having recorded thereon statements and instructions for execution by a computer to perform an image processing of images captured by first and second cameras directed toward a target area, the second camera having a larger non-ambiguity depth than the first camera, the image processing including evaluating a same set of camera-projector related functions from the images captured by the cameras, at least some of the images including a pattern projected at shifted positions, building a low depth resolution 3D model from the camera-projector related functions evaluated with respect to the second camera, building a degenerated 3D model from the camera-projector related functions evaluated with respect to the first camera, determining chromatic texture from the images captured by the cameras, and building a complete textured 3D model from data corresponding between the low depth resolution and degenerated 3D models within a tolerance range. 13. A computer program product, comprising a memory having computer readable code embodied therein, for execution by a CPU, for performing an image processing of images captured by first and second cameras directed toward a target area, the second camera having a larger non-ambiguity depth than the first camera, said code comprising: code means for evaluating a same set of camera-projector related functions from the images captured by the cameras, at least some of the images including a pattern projected at shifted positions; code means for building a low depth resolution 3D model from the camera-projector related functions evaluated with respect to the second camera; code means for building a degenerated 3D model from the camera-projector related functions evaluated with respect to the first camera; code means for determining chromatic texture from the images captured by the cameras; and code means for building a complete textured 3D model from data corresponding between the low depth resolution and degenerated 3D models within a tolerance range. 14. An optical 3D digitizer with an enlarged non-ambiguity zone, comprising: at least one structured light projector projecting a fringe pattern over a target area, the fringe pattern having a shiftable position over the target area; a first camera directed toward the target area and positioned with respect to said at least one structured light projector to define a first triangulation plane therewith; a second camera directed toward the target area and positioned with respect to said at least one structured light projector to define a second triangulation plane therewith, the second triangulation plane being distinct from the first triangulation plane, the first and second cameras having at least partially overlapping measurement fields, the second camera having a larger non-ambiguity depth than the first camera; and a computing device, connected to the cameras, being programmatically configured to i) evaluate a same set of camera-projector related functions from images including the pattern projected by said at least one structured light projector at shifted positions as captured by the cameras, ii) build a low depth resolution 3D model from the camera-projector related functions evaluated with respect to the second camera, iii) build a degenerated 3D model from the camera-projector related functions evaluated with respect to the first camera, iv) determine chromatic texture from the images captured by the cameras, and v) build a complete textured 3D model from data corresponding between the low depth resolution and degenerated 3D models within a tolerance range. 15. A computing device for performing image processing of images captured by first and second cameras, the second camera having a larger non-ambiguity depth than the first camera, wherein the computing device includes a software program which when executed in the computing device i) evaluates a same set of camera-projector related functions from images captured by the cameras, at least some of the images including a pattern projected at shifted positions, ii) builds a low depth resolution 3D model from the camera-projector related functions evaluated with respect to the second camera, iii) builds a degenerated 3D model from the camera-projector related functions evaluated with respect to the first camera, iv) determines chromatic texture from the images captured by the cameras, and v) builds a complete textured 3D model from data corresponding between the low depth resolution and degenerated 3D models within a tolerance range. 