A video-conferencing system is described that provides physical cues regarding remote participants. Each remote participant is physically represented at a video conference by a robotic unit that includes a monitor, camera, microphone and speaker. In this way, a physical presence of the remote participant is conveyed at the conference, so that other participants are more likely to involve the remote participant. Moreover, the remote participant has access to a gesture determination system, which inputs gesture information about the remote participant that expresses a state of mind of the participant. Such gesture information may include leaning forward to show interest, or leaning back to show disinterest. The gesture information is transmitted to the robotic unit, which is actuated so as to reflect the gesture information, and thereby express the state of mind of the remote participant in a physical, intuitive way.
Claims What is claimed is: 1. A system comprising: an audio-visual input system at a first location that is operable to receive audio-visual information associated with a user; a gesture determination system at the first location that is operable to determine gesture information associated with a state of mind of the user based on the received audio-visual information associated with the user; and a tele-embodiment unit at a second location that is operable to receive the gesture information and automatically engage in movement corresponding to the gesture information, whereby the movement of the tele-embodiment unit expresses the state of mind of the user. 2. The system of claim 1 wherein the second location is a site of a conference, and the tele-embodiment unit conveys a physical presence of the user. 3. The system of claim 1 comprising an audio-visual output system at the second location that is operable to output the audio-visual information associated with the user. 4. The system of claim 1 wherein the tele-embodiment unit includes a robotic arm associated with a monitor and camera. 5. The system of claim 4 wherein the tele-embodiment unit is operable to move the monitor and camera in alignment with one another. 6. The system of claim 1 wherein the gesture determination system includes a gesture control device by which the user inputs the gesture information. 7. The system of claim 6 wherein the gesture information includes selectable emotional states and the movement of the tele-embodiment unit is pre-programmed to correspond to a selected emotional state. 8. The system of claim 1 wherein the gesture determination system includes a gesture control device that is operable to track physical movements of the user. 9. The system of claim 8 wherein the gesture determination system includes a gesture interpreter for associating the physical movements with the state of mind of the user. 10. A method comprising: receiving audio-visual input from a conference participant; determining expression information associated with a non-verbal communication of the conference participant based on the received audio-visual input from the conference participant; transmitting the audio-visual input and the expression information to a conference location; rendering the audio-visual input at an audio-visual output associated with a tele-embodiment unit at the conference location; and moving the tele-embodiment unit automatically, based on the expression information, to reflect the non-verbal communication of the conference participant. 11. The method of claim 10 wherein determining expression information comprises receiving a selection of expression information from among a pre-selected list available to the conference participant. 12. The method of claim 10 wherein determining expression information comprises: tracking physical movements of the conference participant; and running a software analysis process to determine the non-verbal communication, based on the physical movements. 13. The method of claim 10 wherein moving the tele-embodiment unit comprises moving a video screen that is attached to a robot arm so as to be pivotable and movable in three dimensions. 14. The method of claim 10 wherein the tele-embodiment unit has a one-to-one correspondence with the conference participant, such that a physical presence of the conference participant is conveyed at the conference location. 15. A video-conferencing system comprising: a plurality of participant input systems corresponding to a plurality of participants, each input system operable to receive audio-visual input from its corresponding participant; and a plurality of physical conference units located at a conference location that is remote from a location of each of the participant input systems, each of the physical conference units corresponding to one of the plurality of participants and including audio-visual output capabilities, wherein the physical conference units convey a physical presence of their corresponding participants at the conference location based on the received audio-visual inputs from their corresponding participants. 16. The video-conferencing system of claim 15 wherein each participant input system comprises: a gesture determination system operable to receive gesture information associated with a state of mind of its corresponding participant based on the received audio-visual input from its corresponding participant; and a remote communication handler operable to forward the gesture information and the audio-visual input to its corresponding physical conference unit. 17. The video-conferencing system of claim 16 wherein the gesture determination system comprises: a gesture control device operable to track physical movements of its corresponding participant; and a gesture interpreter operable to associate the physical movements with the state of mind. 18. The video-conferencing system of claim 16 wherein each physical conference unit comprises a robotic unit operable to automatically move in coordination with the gesture information, such that the physical conference unit physically expresses the state of mind of its corresponding participant. 19. The video-conferencing system of claim 18 wherein the robotic unit comprises a video screen aligned with a camera and attached to a robot arm that is operable to move the video screen and camera in conjunction with the gesture information and the audio-visual input. 20. The video-conferencing system of claim 19 wherein the robot arm is operable to move the video screen and camera in three dimensions. 21. The system of claim 6 wherein the gesture information includes selectable states of mind and the movement of the tele-embodiment unit is pre-programmed to correspond to a selected state of mind. 