A method and system for mutually immersive telepresencing are provided. A user is viewed at a user's location to provide a user's image. The size of the user's head is determined in the user's image. A surrogate having a surrogate's face display about the size of the user's head is provided. The user's image is processed based on the size of the surrogate's face display to provide an about life-size image of the user's head. The about life-size image is displayed on the surrogate's face display.
Claims The invention claimed is: 1. A method for mutually-immersive telepresencing comprising: viewing a user at a user's location to provide a user's image; determining the size of the user's head in the user's image; providing a surrogate having a surrogate's face display about the size of the user's head; processing the user's image based on the size of the surrogate's face display to provide an about life-size image of the user's head; and displaying the about life-size image on the surrogate's face display wherein displaying the about life-size image includes exponential time weighted averaging of a plurality of the user's images to display the about life-size image. 2. The method as claimed in claim 1 wherein: determining the size of the user's head includes determining the location of the user's head at the user's location. 3. The method as claimed in claim 1 wherein: determining the size of the user's head in the user's image includes determining a scale of the user's head; and displaying the about life-size image in a classic portrait style. 4. The method as claimed in claim 1 wherein: processing the user's image includes cropping to provide a close-up image of the face of the user. 5. A system for mutually-immersive telepresencing comprising: a camera set for viewing a user at a user's location to provide a user's image; a computer for determining the size of the user's head in the user's image; a surrogate having a surrogate's face display about the size of the user's head; and a processor for processing the user's image based on the size of the surrogate's face display to provide an about life-size image of the user's head and for displaying the about life-size image on the surrogate's face display wherein the processor includes means for exponential time weighted averaging of a plurality of the user's images to display the about life-size image. 6. The system as claimed in claim 5 wherein: the computer has components for determining the location of the user's head at the user's location. 7. The system as claimed in claim 5 wherein: the computer includes means for determining a scale of the user's head; and the surrogate's face display displays the about life-size image in a classic portrait style. 8. The system as claimed in claim 5 wherein: the processor includes means for cropping to provide a close-up image of the face of the user. 9. A system for mutually-immersive telepresencing comprising: a camera set for viewing a user at a user's location to provide a user's image; a computer for determining the size of the user's head in the user's image using a distance of the user's head in the image from where the user is viewed and a width of the user's head in the image; a surrogate having a surrogate's face display about the size of the user's head; and a processor for processing the user's image based on the size of the surrogate's face display to provide an about life-size image of the user's head and for displaying the about life-size image on the surrogate's face display. 10. The system as claimed in claim 9 wherein: the computer has components for determining the location and orientation of the user's head at the user's location. 11. The system as claimed in claim 9 wherein: the computer includes means for determining a scale of the user's head; and the processor includes means for displaying the about life-size image in a classic portrait style with a clearance between a top of the surrogate's face display and the about life-size image. 12. The system as claimed in claim 9 wherein: the computer has components for determining the location and orientation of the user's head at the user's location; and the processor includes means for cropping to provide a close-up image of the face of the user selected from a group consisting of: both sides cropped of the about life-size image of the user's head when the camera set views the user from within 45 degrees on either side of the face of the user, the backside cropped of the about life-size image of the user's head when the camera set views a profile of the user, both sides cropped of the about life-size image of the user's head when the camera set views the back of the user's head, and both top and bottom cropped of the about life-size image of the user's head when the camera set views the user's head providing a life-size image of the user's head which is taller than will fit in the surrogate's face display. 13. The system as claimed in claim 9 wherein: the processor includes means for exponential time weighted averaging of head position and scale computed from a plurality of the user's images before displaying the about life-size image. 