A method and apparatus is disclosed for tracking an arbitrarily moving object in a sequence of images where the background may be changing. The tracking is based on visual features, such as color or texture, where regions of images (such as those which represent the object being tracked or the background) can be characterized by statistical distributions of feature values. The method improves on the prior art by incorporating a means whereby characterizations of the background can be rapidly re-learned for each successive image frame. This makes the method robust against the scene changes that occur when the image capturing device moves. It also provides robustness in difficult tracking situations, such as when the tracked object passes in front of backgrounds with which it shares similar colors or other features. Furthermore, a method is disclosed for automatically detecting and correcting certain kinds of errors which may occur when employing this or other tracking methods.
Claims The embodiments of the invention in which we claim an exclusive property or privilege are defined as follows: 1. A method for tracking the image position of a tracked object that appears in a plurality of successive frames of an image sequence, said method comprising the following steps: a) initializing the method by identifying a target region in one frame of said image sequence, wherein said target region contains pixels which represent an object which a user of this method wishes to track, b) developing a characterization of the tracked object by developing a characterization of those pixels which lie inside said target region, c) defining a search window, said search window comprising a designated region of the image which is to be searched for the tracked object, said search window to have an area r times greater than the area estimated for the target region identified in step a), said parameter r being a number that said user of the method must choose according to the kind of object being tracked, d) centering said search window on the centroid of the target region identified in step a), e) positioning the search window at an initial location in a successive frame of the image sequence, f) developing a characterization of said search window's pixels at said search windows present location in the present image in the sequence, g) computing, for each pixel in the search window, the probability that the said pixel represents the tracked object, said computation making use of numerical image data associated with said pixel, said characterization of said tracked object pixels developed in step b), said characterization of said search window pixels developed in step f), and Bayes law, said pixel probabilities thereby forming a two dimensional distribution of the tracked object's location in the image, h) estimating the new object location as the centroid of said two dimensional distribution calculated in step g), i) repositioning said search window to be centered on said new object location as determined in step h), j) iteratively repeating steps f), g), h), i) until the position of said search window converges, said convergence meaning that the difference between the positions, calculated for said search window in step i) of two consecutive said iterations, falls below a threshold value, k) repeating the steps e), f), g), h), i) for each successive frame of said image sequence. 2. The method of claim 1, modified to improve computational speed such that step f) occurs only once for each successive frame, in an image sequence, and not once in each of a plurality of iterations of the method for each image frame so that step j)consists of iteratively repeating steps g),h),i) only. 3. The method of claim 1, further including an additional step, said step providing a means whereby the size of the target region is re-estimated, either once for each successive frame in an image sequence, or once within each of a plurality of iterations of steps f), g), h) and i) of the method for each frame of an image sequence. 4. The method of claim 3, further including an additional step, whereby the search window is resized as a function of the estimated size of the target region, said search window resizing to occur either once for each frame in an image sequence, or once within each of a plurality of iterations of steps [f)], [g)], [h)] and [i)] of the method. 5. The method of claim 1, further comprising an additional step including means whereby potential errors can be detected by comparing a continuously relearned background characterization or search window characterization against the characterization known for the tracked object, a potential error being deemed likely if the compared characterizations are deemed similar according to a statistical criterion for evaluating the similarity of two such characterizations. 6. The method of claim 4, further including an additional step, whereby erroneous excessive shrinking of said search window is automatically detected and corrected by comparing a continuously relearned background characterization or search window characterization against the characterization known for the tracked object, a potential error being deemed likely if the compared characterizations are found overly similar according to a statistical criterion for evaluating the similarity of two such characterizations, said error being corrected by re-sizing said search window. 7. The method of claim 1, wherein the method is initialized by designating a target region, said target region being composed of pixels, which represent said tracked object, wherein said initialization comprises a method chosen from: a) a human user manually designating a region of said first image to represent the target region, b) a human user using a computer point device to specify a single point with the image region, with image processing methods being then used to interpret pixels in a region surrounding said user specified single point and automatically identifying those pixels which represent the tracked object, thus identifying the target region c) a human user viewing video footage of the scene in which tracking is to be undertaken being displayed on a screen or other viewing device; a region of the viewed scene being defined or otherwise highlighted; when an object of interest enters said defined region, a human user indicating object presence to a computer; said computer then carrying out the method of claim 1, using the highlighted region as the target region d) automatically detecting objects of interest in successive frames of a video sequence using tracking methods known in the art; then said tracking method determining the appropriate region in an initial frame of a further sequence of images, which can be used as the target region e) a model of the object to be tracked being learned offline using a series of images or photographs that represent said object, t) searching for a region in the first frame to be tracked such that said region is similar to a model of the tracked object previously learned offline. 8. The method of claim 1, wherein steps b) and f) comprise forming characterizations of image features, wherein said features comprise assignations of numerical values to image pixels. 9. The method of claim 8, wherein the feature is selected from the group of color or texture features. 10. The method of claim 8, wherein said characterizations are expressed as a histogram. 11. The method of claim 8, wherein said characterizations are expressed as a parametric or non-parametric probability distribution. 12. The method of claim 1, including a means whereby the characterization of the tracked object is continually updated or relearned in successive frames of an image sequence. 13. The method of claim 1, where said method is used as part of a system whereby a camera is mounted on a motorized or actuated system, whereby the motion of said camera is controlled such that a tracked object is kept within the field of view of said camera. 14. The method of claim 1, with the additional modification that multiple instances of said method are used to simultaneously track multiple objects which all appear within the field of view of a single camera. 15. The method of claim 1, where the method is used as part of a system whereby a camera is mounted on a motorized or actuated system, whereby the motion of said camera is controlled such that a plurality of simultaneously tracked objects are kept within the field of view of said camera. 16. The method of claim 1, wherein said step c) comprises positioning said search window at an initial location, said initial location being either the same as the final location of the search window in the previous image, or at a predicted location for the tracked object, said predicted location being estimated by extrapolating the recent trajectory of the tracked object or using a Kalman filter or other predictive filtering techniques. 17. An apparatus for tracking an object, said apparatus comprising: a) an image capturing device, said device capturing a sequence of images featuring said object b) an image processor responsive to successive frames of said sequence of images c) a characterization processor for developing characterizations of said object d) a characterization processor for developing new characterizations of a search window region for each of said successive frames e) an object location distribution processor for using information from said object and search window characterizations to convert said images into 2D distributions of location of said object by applying Bayes law to each pixel of the search window, to calculate the probability that said pixel represents said tracked object f) a mean shift processor for iteratively calculating the mean location of said 2D distributions g) a controller for causing said processors to process and combining information derived from said processors to achieve tracking of said object. 18. The apparatus of claim 17 wherein said image capturing device is mounted on a motorized or actuated system, whereby the motion of said image capturing device is controlled such that a tracked object is kept within the field of view of said image capturing device. 19. The apparatus of claim 17 further comprising an error detection processor, said error detection processor comprising a means whereby potential errors can be detected by comparing a continuously relearned background characterization or search window characterization against a characterization known for a tracked object. 