A robot is proposed which has a speech recognition unit to detect information supplied simultaneously with or just before or after detection of a touch by a touch sensor, an associative memory/recall memory to store action made correspondingly to the touch and input information (speech signal) detected by the speech recognition unit in association with each other, and an action generator to control the robot to make action recalled by the associative memory/recall memory based on a newly acquired input information (speech signal). The robot has also a sensor data processor to allow the robot to act correspondingly to the touch detection by the touch sensor. Thus, the robot can learn action in association with an input signal such as speech signal.
Claims What is claimed is: 1. A robot apparatus comprising: means for detecting a touch; means for detecting information supplied simultaneously with, just before or after the touch detection by the touch detecting means; means for storing action made correspondingly to the touch detection in association with input information detected by the input information detecting means; and means for recalling action from information in the storing means based on newly acquired information to control the robot apparatus to do the action. 2. The robot apparatus according to claim 1 wherein, the action made correspondingly to the touch detection by the touch detecting means is a result of a displacement of a moving part due to an external loading by the touch; and the touch detecting means detects a touch from a change of a control signal to the moving part due to the external loading. 3. The robot apparatus according to claim 1 further comprising means for allowing the robot apparatus to act correspondingly to the touch detection by the touch detecting means; the storing means stores the action made correspondingly to the touch detection by the touch detecting means and input information detected by the input information detecting means in association with each other. 4. The robot apparatus according to claim 1, wherein the input information detecting means detects at least either image information or speech information. 5. A method for controlling an action of a robot apparatus, the method comprising the steps of: detecting a touch made to the robot apparatus; detecting information supplied simultaneously with or just before or after the touch detection in the touch detecting step; storing action made in response to the touch detection in the touch detecting step and input information detected in the input information detecting step in association with each other into a storing device; and recalling action from the information in the storing device based on newly acquired input information to control the robot to do the action. 6. A robot apparatus comprising: means for detecting input information; means for storing the input information detected by the input information detecting means and action result information indicative of a result of action made correspondingly to the input information detected by the input information detecting means; and means for identifying action result information in the storing means based on a newly supplied input information to control the robot apparatus to do action based on the action result information. 7. A robot apparatus comprising: means for detecting input information; means for storing the input information detected by the input information detecting means and action result information indicative of a result of action made correspondingly to the input information detected by the input information detecting means; and means for identifying action result information in the storing means based on a newly supplied input information to control the robot apparatus to do action based on the action result information wherein, an emotion is changed correspondingly to an external factor and/or internal factor and action is made based on the state of the emotion; the storing means stores the emotion state resulted from the action made based on the input information as the action result information and the input information in association with each other; and the action controlling means recalls a corresponding emotion state from the storing means based on the input information to control the robot apparatus to act based on the emotion state. 8. The robot apparatus according to claim 6, wherein the input information detecting means detects at least either image information or speech information. 9. A method for controlling an action of a robot apparatus, the method comprising the steps of: storing action result information indicative of a result of action made correspondingly to input information detected by an input information detecting means and the input information in association with each other into a storing device; and identifying action result information in the storing device means based on newly supplied input information to control the robot apparatus to make action based on the action result information. 10. A robot apparatus comprising: means for detecting input information; means for detecting a feature of the input information detected by the input information detecting means; means for classifying the input information based on the detected feature; means for controlling the robot apparatus to do action based on the input information; and means for changing the classification of the input information having caused the robot apparatus to do the action based on action result information indicative of a result of the action made by the robot apparatus under the control of the action controlling means. 11. The robot apparatus according to claim 10, wherein the input information is image information or speech information. 12. The robot apparatus according to claim 10, wherein the classification changing means changes the classification of input information when the action result information indicates that the action result is unpleasant. 13. A method for controlling an action of a robot apparatus, the method comprising the steps of: detecting a feature of input information detected by an input information detecting device; classifying the input information based on the feature detected in the feature detecting step; controlling the robot apparatus to act based on the classification of the input information, made in the information classifying step; and changing the classification of the input information having caused the robot apparatus to do the action based on action result information indicative of a result of the action made by the robot apparatus controlled in the action controlling step. 14. A robot apparatus comprising: means for identifying a target object; means for storing information on the target object identified by the target object identifying means; and means for controlling the robot apparatus to act based on information on a newly detected object and information on the target object, stored in the storing means. 15. The robot apparatus according to claim 14, wherein the target object identifying means segments input image information to detect a time change of the segmented area and identify an object corresponding to an area whose time change has reached a predetermined value. 16. The robot apparatus according to claim 14, wherein the target object identifying means identifies a target object based in input speech information. 17. The robot apparatus according to claim 16, wherein the target object identifying means identifies a target object from at least either sound volume or direction information of input speech information. 18. A robot apparatus comprising: means for identifying a target object; means for storing information on the target object identified by the target object identifying means; and means for controlling the robot apparatus to act based on information on a newly detected object and information on the target object, stored in the storing means, wherein the target object identifying means detects a sightline of a trainer teaching the target object to identify the target object from the sightline. 19. A method for controlling an action of a robot apparatus, the method comprising the steps of: identifying a target object; storing information on the target object identified in the target object identifying step into a storing device; and controlling the robot apparatus to act based on information on a newly detected object and information on the target object, stored in the storing device. 20. A robot apparatus comprising: moving members, joints to move the moving members, detecting means for detecting the state of the joint to which an external force is applied via the moving member; and means for learning the joint state detected by the detecting means and external force in association with each other. 21. The robot apparatus according to claim 20 wherein, the detecting means detects an external force acting on the joint via the moving member as a state of the joint; and the learning means learns the external force detected by the detecting means and external force to the moving member in correlation with each other. 22. A robot apparatus comprising: moving members, joints to move the moving members, detecting means for detecting the state of the joint to which an external force is applied via the moving member; and means for learning the joint state detected by the detecting means and external force in association with each other wherein, the detecting means detects a difference between a target value and measured value of the joint state; and the learning means learns the difference between the target and measured values, detected by the detecting means, and the external force in correlation with each other. 23. The robot apparatus according to claim 22 wherein the detecting means detects a change of a control signal to the joint due to the external force; and the learning means learns the changed control signal detected by the detecting means and the external force. 24. The robot apparatus according to claim 20, further comprising action controlling means for allowing the robot apparatus to act based on a result of the learning by the learning means and the joint state after the learning. 25. A robot apparatus comprising: moving members, joints to move the moving members, detecting means for detecting the state of the joint to which an external force is applied via the moving member; and means for learning the joint state detected by the detecting means and external force in association with each other, wherein the learning means learns by a neural network including an input layer, hidden layer and an output layer. 26. An external force detector comprising: means for detecting a state of a joint which moves a moving member; and means for detecting an external force acting on the moving member based on the joint state detected by the joint state detecting means. 27. A external force detector comprising: means for detecting a state of a joint which moves a moving member; and means for detecting an external force acting on the moving member based on the joint state detected by the joint state detecting means wherein, the detecting means detects a difference between a target value and measured value of the joint state; and the external force detecting means detects the external force based on the difference between the target and measured values, detected by the detecting means. 28. The detector according to claim 27 wherein, the detecting means detects a change of a control signal to the joint due to the external force applied via the moving member; and the external force detecting means detects the external force based on the changed control signal detected by the detecting means. 29. A method for detecting an external force, comprising the steps of: detecting a state of a joint which moves a moving member; detecting an external force acting on the moving member based on the detected joint state; detecting the external force acting on the moving member based on the state of the joint which moves the moving member. 