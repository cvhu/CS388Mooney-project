One aspect of this disclosure relates to a method for recovering the three-dimensional (3D) point geometry of an object from images acquired with a single camera. The present subject matter uses single-camera images, models generalized camera lines-of-sight outside the camera, and uses linkage distances between markers on an object and the modeled lines-of-sight to recover the 3D positions of markers on the object. The linkage distances are used to recover information about the third dimension that would otherwise be lost in single-camera two-dimensional images. Benefits include low-cost, simplicity, and ease of calibration and implementation, and further include the ability to estimate 3D distances and positions as accurately as with a commercially available multi-camera 3D system. Other aspects and embodiments are provided herein.
Claims What is claimed is: 1. A method of using a single camera to determine three dimensional (3D) position information for a designated point on an object, the method comprising: determining a linkage distance between the designated point and a seeding point on the object; defining a 3D viewfield coordinate system having orthogonal axes in the viewfield of the camera and designating the coordinate axis most nearly parallel to the optical axis of the camera as the depth axis; mapping locations in the image plane to unique lines of sight in the viewfield of the camera, wherein a coordinate along the depth axis determines a unique position along a particular line of sight mapped from a particular location in the image plane; determining the position of the seeding point in the viewfield coordinate system; determining the location of the image of the designated point in the image plane; and computing the position of the designated point along the depth axis as a function of the position of the seeding point along the depth axis, the linkage distance between the designated point and the seeding point, and the location of the image of the designated point in the image plane. 2. The method of claim 1, further comprising aligning the depth axis of the viewfield coordinate system to be approximately collinear with the camera's optical axis. 3. The method of claim 2, wherein mapping locations in the image plane comprises: orienting a calibration grid having a number of co-planar markers to be orthogonal to the depth axis of the viewfield coordinate system such that each marker produces an image on the image plane, each marker having a known position relative to at least one other marker in the grid; acquiring images of the calibration grid at a number of positions along the depth axis; and for each image that is acquired, determining the coordinate position of the calibration grid along the depth axis. 4. The method of claim 1, wherein computing the position of the designated point comprises solving a single equation having a single unknown. 5. The method of claim 4, wherein solving a single equation having a single unknown comprises selecting from among two solutions. 6. The method of claim 5, wherein selecting from among two solutions comprises selecting a real solution from among a real and an imaginary solution. 7. The method of claim 1, wherein determining the position of the seeding point in the viewfield coordinate system comprises: providing one or more triplets of designated points on the object, each triplet including a triangle of designated points between which the linkage distances are known, wherein the linkage distance from the seeding point to at least one of the designated points in the one or more triplets is known; solving a system of three equations, each equation providing one coordinate of each triplet point; and for each triplet that is provided, determining one spatial coordinate of the seeding point. 8. The method of claim 7 wherein the seeding point is one of the designated points in the one or more triplets. 9. The method of claim 1, wherein determining the position of the seeding point in the viewfield coordinate system comprises: determining the position of the seeding point along the depth axis; determining the location of the image of the seeding point in the image plane; and computing the 3D position of the seeding point as a function of the depth coordinate of the seeding point and the location of the image of the seeding point in the image plane. 10. The method of claim 1, further comprising computing the 3D position of the designated point as a function of the depth coordinate of the designated point and the location of the image of the designated point in the image plane. 11. The method of claim 1, wherein the object is an inventory item. 12. The method of claim 1, wherein the object includes teeth. 13. The method of claim 1, wherein the object is an animal. 14. The method of claim 1, wherein the object is a person. 15. A three dimension (3D) video imaging system comprising: a camera; and a computational system comprising a processor and a readable medium having executable program instructions stored thereon that when executed by the processor cause the processor to: determine a linkage distance between a designated point on an object and a seeding point on the object; define a 3D viewfield coordinate system having orthogonal axes in the viewfield of the camera and designate the coordinate axis most nearly parallel to the optical axis of the camera as the depth axis; map locations in the image plane to unique lines of sight in the viewfield of the camera, wherein a coordinate on the depth axis determines a unique position along a particular line of sight mapped from a particular location in the image plane; determine the position of the seeding point in the viewfield coordinate system; determine the location of the image of the designated point in the image plane; and compute the position of the designated point along the depth axis as a function of the position of the seeding point along the depth axis, the linkage distance between the designated point and the seeding point, and the location of the image of the designated point in the image plane. 16. The method of claim 15, wherein the depth axis is aligned to be approximately collinear with the camera's optical axis. 17. The system of claim 16, wherein the image plane lies between a focal point of the camera and the object whose image is being received in the image plane. 18. The system of claim 15, further comprising a calibration grid to determine a mapping from locations in the image plane to unique lines of sight in the viewfield of the camera such that a coordinate on the depth axis determines a unique position along a particular line of sight mapped from a particular location in the image plane, wherein the calibration grid includes a number of co-planar markers, each marker being linked by a known distance to at least one other marker in the grid, wherein the grid may be oriented to be orthogonal to the depth axis of the viewfield coordinate system such that a number of the markers in the calibration grid produce images on the image plane. 19. A method of recording three dimensional (3D) movement of an object using a single camera, the method comprising: mapping locations in an image plane of the camera to unique lines of sight in the viewfield of the camera, wherein a coordinate on a depth axis determines a unique position along a particular line of sight mapped from a particular location in the image plane, wherein the depth axis is an axis of an orthogonal coordinate system defined in the viewfield of the camera, the depth axis being the axis of the coordinate system most nearly parallel to the optical axis of the camera; determining the 3D positions of a plurality of designated points on the object at a second position relative to the positions of the designated points at a first position, each of the plurality of designated points having a known linkage distance to at least one other point in the plurality of points; and modeling the object based on the relative positions of the designated points in the first and the second positions. 20. The method of claim 19, wherein the object is a product that is being manufactured. 21. The method of claim 19, wherein the object is an inventory item. 22. The method of claim 19, wherein a robot uses the determined 3D position of the object to determine the orientation and size of the object. 23. The method of claim 19, wherein the object is a robot, and the robot uses the computed 3D positions of the designated points to determine the 3D position of the robot's movable elements. 24. The method of claim 19, wherein the object includes teeth. 25. The method of claim 19, wherein the object is an animal. 26. The method of claim 25, wherein the plurality of designated points are identified and positioned so as to record the animal's gait. 27. The method of claim 25, wherein the plurality of designated points are identified and positioned so as to identify the animal. 28. The method of claim 19, wherein the object is a person. 29. The method of claim 28, wherein the plurality of designated points are identified and positioned so as to record the person's gait. 30. The method of claim 28, wherein the plurality of designated points are identified and positioned so as to identify the person. 