Methods and systems for estimating a location of a robot are disclosed. In one embodiment, the method comprises a robot capturing range images indicating distances from the robot to a plurality of objects in an environment. The method further comprises transmitting to a server a query based on the range images, receiving from the server a mapping of the environment and, based on the distances and the mapping, estimating a location of the robot. In another embodiment, the method comprises receiving from a robot range images of an environment and, based on the range images, determining an inventory of objects in the environment. The method further comprises, based on the inventory, identifying the environment and transmitting to the robot a mapping of the environment.
Claims What is claimed is: 1. A robot comprising: a range detector configured to capture range images indicating distances from the robot to a plurality of objects in an environment, wherein the range images comprise at least one of point-map images and point-cloud images; and at least one processor configured to (i) initiate the transmission of a query to a server, wherein the query is based at least in part on the range images, (ii) receive a mapping of the environment from the server, wherein the mapping of the environment comprises an indication of a location of at least some of the objects in the plurality of objects in the environment and (iii) estimate a location of the robot based at least in part on the distances and the mapping. 2. The robot of claim 1, wherein the range detector comprises one of a stereo camera, a structured light scanner, a time-of-flight camera, and a laser rangefinder camera. 3. The robot of claim 1, further comprising a server interface configured to transmit the query to the server and receive the mapping from the server. 4. The robot of claim 3, wherein the server interface comprises a wireless interface. 5. The robot of claim 3, wherein the server interface comprises a web-based interface. 6. The robot of claim 1, wherein estimating the location of the robot comprises using triangulation to estimate the location of the robot. 7. The robot of claim 1, wherein estimating the location of the robot comprises using trilateration to estimate the location of the robot. 8. A method comprising: a robot capturing range images indicating distances from the robot to a plurality of objects in an environment, wherein the range images comprise at least one of point-map images and point-cloud images; transmitting to a server a query based at least in part on the range images; receiving from the server a mapping of the environment, wherein the mapping of the environment comprises an indication of a location of at least some of the objects in the plurality of objects in the environment; and based on the distances and the mapping, estimating a location of the robot. 9. The method of claim 8, wherein the range images comprise at least one of point-map images and point-cloud images. 10. The method of claim 8, wherein the query is further based on a recent location of the robot. 11. The method of claim 8, wherein the mapping comprises an indication of a location of at least some of the objects in the plurality of objects. 12. The method of claim 8, wherein estimating the location of the robot comprises using at least one of triangulation and trilateration to estimate the location of the robot. 13. A method comprising: receiving range images of an environment from a robot, wherein the range images comprise at least one of point-map images and point-cloud images; based on the range images, determining an inventory of objects in the environment; based on the inventory, identifying the environment; and transmitting a mapping of the environment and the inventory of objects in the environment to the robot. 14. The method of claim 13, wherein the range images comprise at least one of point-map images and point-cloud images. 15. The method of claim 13, further comprising: based at least in part on the range images, identifying objects in the environment; and based at least in part on the identified objects, determining the inventory. 16. The method of claim 13, wherein the inventory of the objects in the environment includes instructions for use of the objects. 17. The method of claim 13, further comprising receiving from the robot a recent location of the robot. 18. The method of claim 17, wherein identifying the environment comprises: based at least in part on the inventory, determining a type of environment; and based at least in part on the inventory and the type of environment, identifying the environment. 19. The method of claim 13, wherein the mapping comprises an indication of a location of at least some of the objects in the plurality of objects. 20. A computer-readable medium having stored therein instructions that, when executed by a computing device, cause the computing device to perform functions comprising: receiving range images of an environment from a robot, wherein the range images comprise at least one of point-map images and point-cloud images; based on the range images, determining an inventory of objects in the environment; based on the inventory, identifying the environment; and transmitting a mapping of the environment and the inventory of objects in the environment to the robot. 21. The computer-readable medium of claim 20, wherein the functions further comprise: based at least in part on the range images, identifying objects in the environment; and based at least in part on the identified objects, determining the inventory. 