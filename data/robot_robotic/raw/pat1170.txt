A method for visual recognition of an object in an electronic image includes extracting unique points of an object to be learned and/or a target object. The unique points are obtained by cross-correlating the image with a structure. Generally, the structure and/or the size of the structure may vary to detect extremum information associated with the learned object and/or target object. An icon corresponding to each of the unique points is extracted. The size of the icon corresponds to the scale of the unique point. After extraction of the various icons, an object becomes a collection of icons. Each of these icons is un-rotated and normalized or resized to a constant size so it can be compared with other icons. One of the unique properties of these icons is their stability over scale and angle. Thus, this invention allows the recognition of an image(s) or object(s) from large number of trained images or objects very quickly.
Claims What is claimed is: 1. A method for visual recognition of at least one object in an image, the method comprising: providing an image in an electronic format, wherein the image includes at least one object to be learned; generating extremum information associated with the image by cross-correlating at least one structure across at least a portion of the image, wherein the extremum information includes at least one coordinate point associated with cross-correlating the at least one structure across the image; extracting at least one icon from the image, wherein the icon includes the coordinate point associated with the extremum information; determining an angle associated with the at least one icon; normalizing the icon to a fixed size; and storing icon information in a computer readable form, wherein the icon information includes image values associated with at least a portion of the icon; the at least one coordinate point associated with the extremum information; and the angle associated with the at least one icon. 2. The method of claim 1, wherein the extremum information includes a set of coordinate points for each extremum information. 3. The method of claim 2, wherein the extremum information further includes a radius for each extremum information. 4. The method of claim 1, wherein the structure used to generate the extremum information is a cone-like structure. 5. The method of claim 4, wherein the at least one structure has a predetermined number of sizes and extremum information associated with the image is generated for each structure size. 6. The method of claim 5, wherein extremum information associated with a structure size is normalized by a common scaling factor. 7. The method of claim 5, wherein extremum information associated with two or more structure sizes is normalized using different scaling factors for each structure size. 8. The method of claim 1, wherein the icon information is stored in a database, wherein at least one entry of the database includes a description of the object. 9. The method of claim 1, wherein the icon information is stored in a descriptor vector. 10. The method of claim 1, wherein the extremum information is generated by extracting peak values from the step of cross-correlating. 11. A method for matching a learned object with a target object, the method comprising: providing at least one learned object and at least one target object, wherein the learned object and the target object; extracting unique points from the target object, wherein the unique points are generated from extremum information obtained from the target image by cross-correlating at least one structure across the target image; extracting an icon of the target image corresponding to each of the unique points; determining an angle associated with the at least one icon; normalizing the extracted icon; and determining if the extracted icon from the target images matches a learned object. 12. The method of claim 11, wherein the step of determining a match includes searching a database of learned objects to determine a match. 13. The method of claim 12 further including ranking objects detected in the target image based on a match score. 14. The method of claim 13 further including localizing the objects detected in the target image to determine the location of the objects in the target image. 15. The method of claim 14 further including finding one or more corresponding icons in the detected icons from one or more learned icons associated with at least one learned object. 16. The method of claim 15 further including computing a perspective transform for all of the unique points. 17. The method of claim 16 further including transforming object contour points with the perspective transform. 18. The method of claim 17 further including verifying the transformed contour points by superimposing the transformed contour points onto the image. 19. The method of claim 17 further including generating a redundancy measure. 20. The method of claim 14 further including selecting a predetermined number of unique points and computing a perspective transform for the predetermined number of unique points. 21. The method of claim 20 further including transforming object contour points with the perspective transform for the predetermined number of unique points. 22. The method of claim 21 further including verifying the transformed contour points by superimposing the transformed contour points onto the image. 23. The method of claim 15 further including computing a perspective transform for every set of 4 unique points. 24. A non-transitory computer readable medium storing a program, the program being suitable for use in matching a learned object with a target object, wherein when the program is loaded in memory of an associated computer and executed, causes extracting unique points from the target object, wherein the unique points are generated from extremum information obtained from the target image by cross-correlating at least one structure across the target image; extracting an icon of the target image corresponding to each of the unique points; determining an angle associated with the at least one icon; normalizing the extracted icon; and determining if the extracted icon from the target images matches the learned object. 