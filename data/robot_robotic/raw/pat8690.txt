A system and method is provided for navigating a manifold in a high-dimensional space and to interface sound to movement. According to the system of the invention, an input movement sensor operates to capture movement of an object in relation to the manifold. The captured movement is then communicated to generate a control signal in a higher dimensional phase space. A window space translates information from the phase space to render a representation of the relation between the location of the object and the manifold. Sound quality changes are related to movement. Sound output is via a sound synthesizer which generates sound relating to input movement. In a preferred embodiment, movement of an object in relation to a manifold is captured in a three-dimensional virtual reality environment. In a preferred embodiment the manifold is sound generated. The captured movement is then communicated in order to generate a higher dimensional phase space. A window space is also generated for mapping information from the phase space to render a representation of the relationship between the location of the object and the manifold. The representation can then be displayed.
Claims We claim: 1. A system for interfacing sound synthesis to physical movement, comprising: an interactive sound interface, the interface coupled to receive input reflecting movement; means for generating a phase space, the phase space representing at least one dimension greater than input dimensionality of the interactive sound interface and defining changes in perceived qualities of sound in relation to input movement being received from the interactive sound interface; means for generating a window space having a dimensionality of the interactive sound interface, the window space for mapping information from the phase space to render a representation of the relation between the input movement and sound, the representation being capable of being displayed; and a sound synthesizer, the sound synthesizer coupled to the interactive sound composition interface to generate sound in relation to input movement. 2. The system defined in claim 1, further comprising a three-dimensional virtual reality environment, the three-dimensional virtual reality environment operative for capturing the movement and coupled to communicate the movement to the interactive sound interface. 3. A method for interfacing sound synthesis to physical movement, comprising the steps of: receiving input reflecting movement; generating a phase space representing at least one dimension of sound greater than dimensionality of said input reflecting movement and defining a relation between perceived qualities of sound and input movement; mapping information from the phase space to render a representation of the relation between the location of the input and sound; displaying the representation; and synthesizing sound in response to the location of the input. 4. The method defined in claim 3, further comprising the step of generating a window space for displaying the representation. 5. The method defined in claim 3, further comprising the step of providing an interactive sound interface, the interactive sound interface coupled to receive the input reflecting movement. 6. The method defined in claim 3, further comprising the step of providing a three-dimensional virtual reality environment operative for capturing the movement. 7. The method defined in claim 6, further comprising the step of communicating the captured movement to the interactive sound interface. 8. A system for navigating a manifold in a high-dimensional space, comprising: a three-dimensional virtual reality environment operative to capture movement of an object relative to the manifold and coupled to communicate the captured movement; means for generating a phase space representing at least four dimensions of the manifold in relation to location of the object, the location being received from the three-dimensional virtual reality environment; and means for generating a window space, the window space for mapping information from the phase space to render an image of the relation between the location of the object and the manifold, the image capable of being displayed. 9. The system defined in claim 8, wherein the manifold is sound generated. 10. The system defined in claim 8, wherein the object comprises a robot. 11. The system defined in claim 8, wherein the object comprises an animated figure. 12. A method for navigating a manifold in a high-dimensional space, comprising the steps of: capturing movement of an object in relation to the manifold in a three-dimensional virtual reality environment; communicating the captured movement; generating a phase space representing at least four dimensions of the manifold in relation to location of the object, the location being received from the three-dimensional virtual reality environment; and generating a window space for translating information from the phase space to render an image of the relation between the location of the object and the manifold, the image capable of being displayed. 13. The method defined in claim 12, further comprising the step of storing and retrieving said captured movement to reproduce a sequence. 14. The method defined in claim 12, further comprising the step of performing transformations upon captured movements for further exploration and differentiation of said phase space. 