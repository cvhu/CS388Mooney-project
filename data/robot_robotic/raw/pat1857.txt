A method for exchanging information in a shared interactive environment, comprising selecting a first physical device in a first live video image wherein the first physical device has information associated with it, causing the information to be transferred to a second physical device in a second live video image wherein the transfer is brought about by manipulating a visual representation of the information, wherein the manipulation includes interacting with the first live video image and the second live video image, wherein the first physical device and the second physical device are part of the shared interactive environment, and wherein the first physical device and the second physical device are not the same.
Claims What is claimed is: 1. A method for exchanging information in a shared interactive environment, comprising: selecting a first object wherein the first object is one of 1) a first physical device at a remote location shown in a live video image, and 2) an icon on a computing device, wherein the live video image shows a view of the remote location which includes a plurality of physical devices including the first physical device; causing information associated with the first object to be transferred to a second object wherein the second object is the other of 1) the first physical device at the remote location shown in the live video image, and 2) the icon on the computing device; annotating the view of the remote location shown in the live video image with an annotation; automatically transferring the annotation to the first physical device if the annotation is at least partially drawn over the first physical device as it appears in the live video image; displaying the annotation on the first physical device such that the annotation can be viewed at the remote location; wherein the first physical device has a dynamically defined hotpot in the live video image; wherein the transfer is brought about by manipulating a visual representation of the information in the live video image; wherein manipulating includes interacting with the first object in the live video image and the second object; and wherein the first physical device is part of the shared interactive environment. 2. The method of claim 1 wherein: the manipulation is accomplished by dragging the representation from the first object and dropping the representation on the second object. 3. The method of claim 1 wherein: changes to the first physical device are visible to all participants in the shared interactive environment. 4. The method of claim 3 wherein: each of the at least one participants can interact with the shared interactive environment through different computing devices. 5. The method of claim 1 wherein: the first physical device can include a display, a projector, a printer, a facsimile machine, a personal digital assistant, a computer, and a portable computer. 6. The method of claim 1 wherein: the information can include a digital file, a sound, and an audio/video presentation. 7. The method of claim 1 wherein: the first physical device has associated with it a pop-up control panel through which a user can configure and control it. 8. The method of claim 1 wherein: the live video image is one of: a panoramic view and a zoomed view. 9. A method for exchanging information in a shared interactive environment, comprising: selecting a first remote physical device in a first live video image that shows a first view of the shared interactive environment, wherein information is associated with the first remote physical device; causing the information to be transferred to a second remote physical device shown in a second live video image that shows a second view of the shared interactive environment, wherein the transfer is brought about by manipulating a visual representation of the information shown in the first live image by interacting with the first live video image and the second live video image, querying the second remote physical device to determine if it can receive the information from the first remote physical device, and transferring the information from the first remote physical device to the second remote physical device; wherein at least one of the first remote physical device and the second remote physical device has a statically or dynamically defined hotspot in the first live video image or the second live video image; wherein the first remote physical device and the second remote physical device are part of the shared interactive environment; and wherein the first remote physical device and the second remote physical device are different remote physical devices. 10. The method of claim 9 wherein: the manipulation is accomplished by dragging the representation from the first physical device and dropping the representation on the second physical device. 11. The method of claim 9 wherein: changes to the physical devices are visible to all participants in the shared interactive environment. 12. The method of claim 9 wherein: a physical device can include a display, a projector, a printer, a facsimile machine, a personal digital assistant, a computer, and a portable computer. 13. The method of claim 9, further comprising: annotating at least one of the first live video image and the second live video image. 14. The method of claim 13, further comprising: automatically transferring the annotation to a physical device if the annotation is at least partially drawn over the physical device as it appears in a live video image. 15. The method of claim 9 wherein: the first live video image and the second live video image are the same. 16. The method of claim 9 wherein: the information can include a digital file, an annotation, a sound, and an audio/video presentation. 17. The method of claim 9 wherein: at least one of the first physical device and the second physical device has associated with it a pop-up control panel through which a user can configure and control it. 18. A shared interactive environment, comprising: a camera system to provide a first live view of a location and a second live view of the location, wherein the second live view can be configured to zoom in on a portion of the first live view, and wherein each live view shows a different view of a plurality of physical devices at the location; a first graphical user interface (GUI) coupled to the camera system which presents the first live view and the second live view, wherein each view shows one or more of the plurality of physical devices at the location, wherein information is associated with at least one physical device in the first live view; a device controller to dynamically control the physical device in response to interaction of a first user with the GUI wherein the interaction can include annotating at least one of: 1) the first live view of the location; and 2) the second live view of the location; wherein annotations are automatically transferred to the physical device in the live views if the annotation is at least partially drawn over the physical device as it appears in the live video image, and wherein the annotation is displayed on the physical device such that the annotation can be viewed at the location; wherein interaction can include causing the information to be transferred from the at least one physical device to a second physical device in the second live view, wherein the transfer is brought about by manipulating a visual representation of the information by interacting with the first live view and the second live view; a device tracker coupled to the camera system and to dynamically recognize new physical devices; and wherein the camera system can be mounted on a mobile, robotic platform. 19. The shared interactive environment of claim 18, wherein: the first GUI allows the first user to interact the physical device; and wherein the interaction of the first user is apparent to a second user via a second GUI. 20. The shared interactive environment of claim 18, wherein: the device controller can control the physical device through at least one of: 1) an infrared communication channel; and 2) one or more networks. 21. The shared interactive environment of claim 18, wherein: the device tracker can recognize new physical devices by at least one of: 1) image pattern recognition; 2) radio frequency transmission; and 3) acoustic signal. 22. The shared interactive environment of claim 18, wherein: the physical device can be a display; and wherein the display can include an image stack. 23. The shared interactive environment of claim 19, wherein: the first GUI can provide a second live view that is different from the second live view provided by the second GUI. 24. The shared interactive environment of claim 18, wherein: the GUI is implemented as one or more web pages. 25. The shared interactive environment of claim 18, wherein: the first user can select the second live view by drawing a diagonal in the first live view. 26. The shared interactive environment of claim 18, wherein: the physical device has a pop-up control panel that can be made apparent to the first user through the first GUI; and wherein the pop-up control panel allows the first user to control and configure the physical device. 27. The shared interactive environment of claim 18, wherein: the physical device can be represented by a set of attributes and a set of behaviors. 28. The shared interactive environment of claim 27, wherein: the representation of the physical device is part of a device hierarchy. 29. A non-transitory computer readable memory having instructions stored thereon that when executed by a processor cause a system to: select a first remote physical device in a first live video image that shows a first view of the shared interactive environment, wherein information is associated with the first remote physical device; cause the information to be transferred to a second remote physical device shown in a second live video image that shows a second view of the shared interactive environment, wherein the transfer is brought about by manipulating a visual representation of the information by interacting with the first live video image and the second live video image, querying the second remote physical device to determine if it can receive the information from the first remote physical device, and transferring the information from the first remote physical device to the second remote physical device; wherein at least one of the first remote physical device and the second remote physical device has a statically or dynamically defined hotspot in the first live video image or the second live video image; wherein the first remote physical device and the second remote physical device are part of the shared interactive environment; and wherein the first remote physical device and the second remote physical device are different remote physical devices. 30. The computer readable memory of claim 29 wherein: the manipulation is accomplished by dragging the representation from the first physical device and dropping the representation on the second physical device. 31. The computer readable memory of claim 29 wherein: changes to the physical devices are visible to all participants in the shared interactive environment. 32. The computer readable memory of claim 29 wherein: a physical device can include a display, a projector, a printer, a facsimile machine, a personal digital assistant, a computer, and a portable computer. 33. The computer readable memory of claim 29 further comprising instructions that when executed cause the system to: annotate at least one of the first live video image and the second live video image. 34. The computer readable memory of claim 29 wherein: automatically transferring the annotation to a physical device if the annotation is at least partially drawn over the physical device as it appears in a live video image. 35. The computer readable memory of claim 29 wherein: the first live video image and the second live video image are the same. 36. The computer readable memory of claim 29 wherein: the information can include a digital file, an annotation, a sound, and an audio/video presentation. 37. The computer readable memory of claim 29 wherein: at least one of the first physical device and the second physical device has associated with it a pop-up control panel through which a user can configure and control it. 38. A system, comprising: means for selecting a first remote physical device in a first live video image that shows a first view of the shared interactive environment, wherein information is associated with the first remote physical device; means for causing the information to be transferred to a second remote physical device shown in a second live video image that shows a second view of the shared interactive environment, wherein the transfer is brought about by manipulating a visual representation of the information by interacting with the first live video image and the second live video image, querying the second remote physical device to determine if it can receive the information from the first remote physical device, and transferring the information from the first remote physical device to the second remote physical device; wherein at least one of the first remote physical device and the second remote physical device has a statically or dynamically defined hotspot in the first live video image or the second live video image; wherein the first remote physical device and the second remote physical device are part of the shared interactive environment; and wherein the first remote physical device and the second remote physical device are different remote physical devices. 