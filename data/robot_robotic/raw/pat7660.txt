A robot apparatus generating behavior or performing actions. The robot apparatus comprises a parameter generator for generating one or more parameters of an emotion model defining a predetermined emotion and one or more parameters of an instinct model defining a predetermined instinct. An input signal representative of an external stimulus and an input signal representative of an internal stimulus are provided to the robot apparatus. One or more semantic contents are determined in accordance with the detected input signals, and at least one of the emotion model parameters and the instinct model parameters are changed based upon the semantic content. A behavior model is then generated to generate behavior or actions in accordance with the emotion parameters of the emotion model and the instinct parameters of the instinct model.
Claims What is claimed is: 1. A robot apparatus generating behavior or performing actions, comprising: means for generating one or more parameters of an emotion model, the values of said parameters defining a predetermined emotion; means for detecting an input signal supplied to said robot apparatus from an external stimulus; means for determining one or more semantic contents in accordance with said detected input signal; means for changing at least one of said emotion model parameters based upon said semantic content; means for generating a behavior model to generate behavior or perform actions in accordance with said emotion parameters of said emotion model; and means for controlling a posture of said robot apparatus based upon a posture transition model, said posture transition model including a plurality of nodes representing states of a posture between which transition is allowed; wherein transition between one or more pairs of said plurality of nodes of said posture transition model is defined based upon at least said input signal and a transition between one or more pairs of nodes of said behavior model. 2. The robot apparatus of claim 1, wherein said emotion model comprises a plurality of individual emotion model units, an output value of each of said individual emotion model units varying in accordance with said input signal. 3. The robot apparatus of claim 2, wherein the output values of said emotion model units vary further in accordance with the output values of the others of said plurality of emotion model units. 4. The robot apparatus of claim 1, wherein said determined semantic content affects each of said emotion model parameters in different ways. 5. The robot apparatus of claim 1, further comprising: means for generating a plurality of behavior nodes corresponding to each of a plurality of behavior states of said behavior model; means for generating a plurality of directionally oriented arcs, each of said arcs linking two of said behavior nodes and comprising a predetermined action of said robot upon transitioning from a first of said two linked behavior nodes to a second of said two linked behavior nodes; means for assigning each of said arcs a predetermined weighting coefficient in accordance with external, non-probability based factors; and means for controlling said robot apparatus to transition from a first behavior state corresponding to a first behavior node to a second behavior state corresponding to a second behavior node in along one of said directionally oriented arcs, in accordance with said associated weighting coefficients. 6. The robot apparatus of claim 5, wherein said weighting coefficients are modified in accordance with a user's encouragement of a particular action. 7. The robot apparatus of claim 5, wherein all of the weighting coefficients for all of said directionally oriented arcs emanating from a particular behavior node sum to one. 8. The robot apparatus of claim 5, wherein said first behavior node and said second behavior node are the same. 9. A robot apparatus generating behavior or performing actions, comprising: means for generating one or more parameters of an instinct model, the values of said parameters defining a predetermined instinct; means for detecting an input signal supplied to said robot apparatus from an internal stimulus; means for determining one or more semantic contents in accordance with said detected input signal; means for changing at least one of said instinct model parameters based upon said semantic content; means for generating a behavior model to generate behavior or perform actions in accordance with said instinct parameters of said instinct model; and means for controlling a posture of said robot apparatus based upon a posture transition model, said posture transition model including a plurality of nodes representing states of a posture between which transition is allowed; wherein transition between one or more pairs of said plurality of nodes of said posture transition model is defined based upon at least said input signal and a transition between one or more pairs of nodes of said behavior model. 10. The robot apparatus of claim 9, wherein said instinct model comprises a plurality of individual instinct model units, an output value of each of said individual instinct model units varying in accordance with said input signal. 11. The robot apparatus of claim 10, wherein the output values of said instinct model units vary in accordance with the output values of the others of said plurality of instinct model units. 12. The robot apparatus of claim 9, wherein said determined semantic content affects said instinct model parameters in different ways. 13. The robot apparatus of claim 9, further comprising: means for generating a plurality of behavior nodes corresponding to each of a plurality of behavior states of said behavior model; means for generating a plurality of directionally oriented arcs, each of said arcs linking two of said behavior nodes and comprising a predetermined action of said robot upon transitioning from a first of said two linked behavior nodes to a second of said two linked behavior nodes; means for assigning each of said arcs a predetermined weighting coefficient in accordance with external, non-probability based factors; and means for controlling said robot apparatus to transition from a first behavior state corresponding to a first behavior node to a second behavior state corresponding to a second behavior node in along one of said directionally oriented arcs, in accordance with said associated weighting coefficients. 14. The robot apparatus of claim 13, wherein said weighting coefficients are modified in accordance with a user's encouragement of a particular action. 15. The robot apparatus of claim 13, wherein all of the weighting coefficients for all of said directionally oriented arcs emanating from a particular behavior node sum to one. 16. The robot apparatus of claim 13, wherein said first behavior node and said second behavior node are the same. 17. A robot apparatus generating behavior or performing actions, comprising: means for generating one or more parameters of an emotion model, the values of said parameters defining a predetermined emotion; means for generating one or more parameters of an instinct model, the values of said parameters defining a predetermined instinct; means for detecting an input signal supplied to said robot apparatus from an external stimulus; means for detecting an input signal supplied to said robot apparatus from an internal stimulus; means for determining one or more semantic contents in accordance with said detected input signals; means for changing at least one of said emotion model parameters or said instinct model parameters based upon said semantic content; means for generating a behavior model to generate behavior or perform actions in accordance with said emotion parameters of said emotion model and said instinct parameters of said instinct model; and means for controlling a posture of said robot apparatus based upon a posture transition model, said posture transition model including a plurality of nodes representing states of a posture between which transition is allowed; wherein transition between one or more pairs of said plurality of nodes of said posture transition model is defined based upon at least said input signal and a transition between one or more pairs of nodes of said behavior model. 18. The robot apparatus of claim 17, wherein said emotion model comprises a plurality of individual emotion model units and said instinct model comprises a plurality of individual instinct model units, an output value of each of said individual emotion model units and an output value of each of said individual instinct model units varying in accordance with said input signals. 19. The robot apparatus of claim 18, wherein the output values of said emotion model units and the output values of said instinct model units further vary in accordance with the output values of others of said plurality of emotion model units and instinct model units. 20. The robot apparatus of claim 17, wherein said determined semantic content affects each of said emotion model parameters and each of said instinct model parameters in different ways. 21. The robot apparatus of claim 17, further comprising: means for generating a plurality of behavior nodes corresponding to each of a plurality of behavior states of said behavior model; means for generating a plurality of directionally oriented arcs, each of said arcs linking two of said behavior modes and comprising a predetermined action of said robot upon transitioning from a first of said two linked behavior nodes to a second of said two linked behavior nodes; means for assigning each of said arcs a predetermined weighting coefficient in accordance with external, non-probability based factors; and means for controlling said robot apparatus to transition from a first behavior state corresponding to a first behavior node to a second behavior state corresponding to a second behavior node in along one of said directionally oriented arcs, in accordance with said associated weighting coefficients. 22. The robot apparatus of claim 21, wherein said weighting coefficients are modified in accordance with a user's encouragement of a particular action. 23. The robot apparatus of claim 21, wherein all of the weighting coefficients for all of said directionally oriented arcs emanating from a particular behavior node sum to one. 24. The robot apparatus of claim 21, wherein said first behavior node and said second behavior node are the same. 25. A robot apparatus able to transition between two of a plurality of posture states, comprising: means for generating a plurality of posture nodes corresponding to possible postures taken by said robot apparatus; means for generating a plurality of directionally oriented arcs, each of said arcs linking two of said posture nodes between which said robot apparatus can directly transition, each of said arcs corresponding to one or more actions of said robot apparatus to be implemented upon transition between said two posture nodes linked by said arc; and means for controlling said robot apparatus to transition from a first posture state corresponding to a first posture node and a second posture state corresponding to a second posture node along an arc linking said first and second posture nodes, therefore performing a predetermined action based upon at least an external stimulus and a command from a behavior model defining a plurality of possible behaviors of said robot apparatus. 26. The robot apparatus of claim 25, wherein each of said directionally oriented arcs represents a safe sequence of actions to be taken by said robot apparatus. 27. The robot apparatus of claim 25, wherein if it is desired for said robot apparatus to transition between two posture nodes which said robot apparatus cannot directly transition between, said robot apparatus transitions between one or more intermediate posture nodes. 28. The robot apparatus of claim 25, wherein said first posture node and said second posture node are the same. 29. The robot apparatus of claim 25, wherein at least one of said posture nodes is a neutral node. 30. The robot apparatus of claim 29, wherein said robot apparatus transitions to said neutral node when it is in an unrecognizable posture. 31. The robot apparatus of claim 30, wherein said unrecognizable posture is a result of said robot apparatus being moved while no power is supplied thereto. 32. The robot apparatus of claim 25, wherein at least one of said posture nodes is a fall down node. 33. The robot apparatus of claim 32, wherein said robot apparatus enters said fall down node upon a determination that said robot has fallen down. 34. The robot apparatus of claim 33, further comprising a sensor for determining when said robot has fallen down. 35. The robot apparatus of claim 33, w here in said robot determines its orientation upon a determination that it has fallen down. 36. The robot apparatus of claim 33, wherein said robot apparatus transitions to a neutral node from said fall down node. 37. The robot apparatus of claim 25, wherein: said robot apparatus comprises a plurality of component units, each of said plurality of component units comprising: means for generating a plurality of posture nodes corresponding to possible postures taken by said robot apparatus; means for generating a plurality of directionally oriented discs, each of said arcs linking two of said posture nodes between which said robot apparatus can directly transition, each of said arcs corresponding to one or more actions of said robot apparatus to be implemented upon transition between said two posture nodes linked by said arc; means for controlling said robot apparatus to transition from a first posture state corresponding to a first posture node and a second posture state corresponding to a second posture node along an arc linking said first and second posture nodes, therefore performing a predetermined action. 38. The robot apparatus of claim 37, wherein said transition of each component unit of said robot apparatus is determined independently. 39. The robot apparatus of claim 37, wherein the transitions of each component required for a particular action of said robot apparatus are determined together, and the transitions of the remainder of said components are determined independently. 40. A robot apparatus, comprising: a portion; control means for controlling said portion; and a posture transition model including states of a posture between which transition is allowed; wherein said posture transition model includes a neutral state which is defined such that the actions of said robot apparatus are performed in a safe manner in transitions from said neutral state to other states. 41. The robot apparatus of claim 40, wherein said safe manner is provided by reducing a torque of each of one or more articulation actuators or lowering an operating speed of each of a plurality of components. 42. The robot apparatus of claim 40, wherein said posture transition model comprises a first node indicative of a first posture of said robot apparatus, a second node indicative of a second posture of said robot apparatus, and an arc indicative of capable transitioning directly from said first node to said second node. 43. The robot apparatus of claim 40, wherein said posture transition model transits postures by employing a directional graph in which a plurality of nodes representing postures capable of being taken by said robot apparatus are registered beforehand, and every two among the postures capable of being directly transited from one to the other are coupled by a directional arc. 44. The robot apparatus of claim 43, wherein said posture transition model plans a posture transition schedule by searching a route from a node corresponding to the current posture to a next node while following a direction indicated by each respective directional arc. 45. An autonomous robot apparatus comprising: a main body; moving means for moving said main body; and posture detecting means for detecting a current posture of said robot apparatus from among a plurality of predefined postures; wherein when said posture detecting means cannot detect said current position of said robot apparatus, said robot apparatus is shifted to a safe mode for transition to a predetermined posture. 46. The robot apparatus of claim 45, wherein said safe mode is provided by reducing a torque of each of one or more articulation actuators or lowering an operating speed of each of a plurality of components. 47. The robot apparatus of claim 45, wherein said moving means comprises a posture transition model, said posture transition model comprising a first node indicative of said predetermined posture of said robot apparatus, and an arc indicative of capable transitioning directly to said predetermined posture in said safe mode. 48. The robot apparatus of claim 45, wherein said moving means further comprises a posture transition model, wherein said posture transition model transits postures by employing a directional graph in which a plurality of nodes representing said plurality of predefined postures, and at least one of said postures capable of being directly transited to in said safe mode. 49. The robot apparatus of claim 45, wherein said moving means further comprises a posture transition model, and said posture transition model plans a posture transition schedule by searching a route from a node in said safe mode to a next node while following a directional indicated by each of a plurality of directional arcs. 50. A robot apparatus, comprising: a portion; control means for controlling said portion; and a posture transition model including states of a posture between which transition is allowed; wherein said posture transition model includes a falling-down state which is defined such that the actions of said robot apparatus are performed in a safe manner in transitions from said falling-down state to a predefined one of said states of said posture. 51. The robot apparatus of claim 50, wherein said predefined one of said states of said posture is a neutral state which is defined such that the actions of said robot apparatus are performed in a safe manner in transitions from said neutral state to others of said states of said posture. 52. The robot apparatus of claim 50, wherein said safe manner is provided by reducing a torque of each of one or more articulation actuators or lowering an operating speed of each of a plurality of components. 53. The robot apparatus of claim 50, wherein said posture transition model comprises a first node indicative of a first posture of said robot apparatus, a second node indicative of a second posture of said robot apparatus, and an arc indicative of capable transitioning directly from said first node to said second node. 54. The robot apparatus of claim 50, wherein said posture transition model transits postures by employing a directional graph in which a plurality of nodes representing postures capable of being taken by said robot apparatus are registered beforehand, and every two among the postures capable of being directly transited from one to the other are coupled by a directional arc. 55. The robot apparatus of claim 50, wherein said posture transition model plans a posture transition schedule by searching a route from a node corresponding to the current posture to a next node while following a direction indicated by each respective directional arc. 56. The robot apparatus of claim 50, further comprising an acceleration sensor for determining when said robot apparatus is falling down. 57. A robot apparatus, comprising: a main body; a portion coupled with said main body; detection means for detecting an exterior stimulus; behavior determining means for determining a behavior to be performed by said robot apparatus based at least in part upon the detected external stimulus; an entire posture transition model defining postures between which transition of the entire robot apparatus is allowed; a component posture transition model defining postures between which transition of one or more components of the robot apparatus is allowed; and control means for controlling said entire robot apparatus and said one or more components of said robot apparatus; wherein said control means decides a behavior of said robot apparatus based upon the external stimulus, selects said entire posture transition model or said component posture transition model in accordance with the decided behavior, and controls the entire robot apparatus, or one or more components thereof, based upon the selected posture transition model. 58. The robot apparatus of claim 57, wherein said entire posture transition model defines a movement for a substantial portion of said one or more components. 59. The robot apparatus of claim 58, wherein the movement of said one or more components not defined by said entire posture transition model is defined independently of said entire posture transition model. 60. The robot apparatus of claim 57, wherein said component posture transition model defines a movement for one or more of said one or more components. 61. The robot apparatus of claim 60, wherein the movement of said one or more components not defined by said component posture transition model is defined independently thereof. 62. The robot apparatus of claim 57, wherein said entire posture transition model and said component transition model comprise a first node indicative of a first posture of said robot apparatus, a second node indicative of a second posture of said robot apparatus, and an arc indicative of capable transitioning directly from said first node to said second node. 63. The robot apparatus of claim 57, wherein said entire posture transition model and said component transition model transit postures by employing a directional graph in which a plurality of nodes representing postures capable of being taken by said robot apparatus are registered beforehand, and every two among the postures capable of being directly transited from one to the other are coupled by a directional arc. 64. The robot apparatus of claim 63, wherein said entire posture transition model and said component posture transition model plan a posture transition schedule by searching a route from a node corresponding to the current posture to a next node while following a direction indicated by each respective directional arc. 