An integrated controller for controlling both pan and vergent movements of a stereoscopic vision system, having two cameras, is described. The controller determines motion and direction based on a provided retinal error. Each of the cameras is moved until no retinal error remains which results from camera orientation. A butterfly controller accepts data input relating to retinal errors from any number of sources and provides a single signal relating to common motion and another signal relating to vergent motion to each control circuit. The circuits are designed to operate in common mode or differential mode thereby causing sensors to move in different directions when controlled by same control signals.
Claims What is claimed is: 1. A method of controlling gaze in a binocular vision system having two imaging devices and at least a plant for moving at least an imaging device comprising the steps of: a) providing to a processor a retinal error relating to location of a target as imaged by each of the two imaging devices; b) providing to the processor a model related to each of the two imaging devices; and, c) using the processor, determining from both retinal errors absent calculation of the target location in spatial co-ordinates a control signal related to imaging device motion for reducing the provided retinal errors. 2. A method of controlling gaze in a binocular vision system as defined in claim 1 wherein the control signal comprises two control signals for controlling device motion along a same dimension and within a same plane. 3. A method of controlling gaze in a binocular vision system as defined in claim 2 wherein the controller is a butterfly controller having the following transfer functions ##EQU21## 4. A method of controlling gaze in a binocular vision system as defined in claim 2 wherein motion of each of the two imaging devices is controlled by a separate plant associated with each imaging device and by another plant associated with a movable platform upon which both imaging devices are disposed and wherein the control signal is provided to some of the plants. 5. A method of controlling gaze in a binocular vision system as defined in claim 4 wherein the control signal is provided to each of the plants. 6. A method of controlling gaze in a binocular vision system as defined in claim 5 wherein the controller comprises a butterfly controller having two input ports and two output ports, the two input ports for receiving each of the two retinal errors; the control signal comprising two signal components, a signal component provided at each of the two output ports. 7. A method of controlling gaze in a binocular vision system as defined in claim 2 comprising the step of: providing another sensor input to the processor wherein the sensor input is used to determine the control signal. 8. A method as defined in claim 7 wherein the processor is in the form of a butterfly controller for simultaneously processing each retinal error and the other sensor input, and for determining a same control signal for provision to each plant. 9. A method of controlling gaze in a binocular vision system as defined in claim 2 comprising the step of: providing another sensor input to the processor; providing a model relating to the sensor to the processor, wherein the sensor input is used to determine the control signal for provision to the plant for moving the imaging devices to reduce retinal errors. 10. A method as defined in claim 2 wherein the step (c) comprises the steps of: c1) using the processor, determining from both retinal errors absent calculation of target location in spatial co-ordinates a control value related to imaging device motion for reducing the provided retinal errors; and, c2) providing a control signal based on the control value. 11. A method as defined in claim 2 wherein the control signal is calculated in a simultaneous and integrated fashion for both pan and vergence of both imaging devices in a coordinated fashion. 12. A method as defined in claim 2 wherein the step (a) comprises the steps of: a1) providing image data from a first imaging device; a2) providing image data from a second imaging device; a3) determining a first target location within the image data from a first imaging device and a second target location within image data from a second imaging device; and a4) deriving a retinal error related to each imaging device from the determined target locations. 13. A method as defined in claim 2 wherein the processor is in the form of a butterfly controller for simultaneously processing each retinal error and for determining a same control signal for provision to each plant. 14. A method as defined in claim 2 wherein the control signal relating imaging device motion for reducing the retinal error is determined absent calculation of independent control signals for panning and vergence. 15. A method as defined in claim 2 wherein the same control signal is provided to each plant for controlling motion of any platform upon which at least one of the first imaging device and the second imaging device are disposed. 16. A method as defined in claim 2 comprising the steps of: determining a state of imaging device motion; and, when retinal error is substantially small, determining a value based on vergence of the imaging devices, the value related to a distance from the imaging devices to the target. 17. A method as defined in claim 16 comprising the steps of: adjusting a focus of each imaging device in dependence upon the determined value. 18. A method as defined in claim 16 comprising the steps of: using current position and retinal error, determining estimated focus adjustment of imaging devices. 19. A method as defined in claim 18 comprising the steps of: using current position and retinal error, determining butterfly controller gain adjustment; adjusting gains within the butterfly controller based on the determined butterfly gain adjustments. 20. A method as defined in claim 2 comprising the steps of: providing a known angle of vergence between the two imaging devices; adjusting a distance between the imaging devices and the target to reduce retinal error; and, when retinal error is below a predetermined level, providing an indication, whereby the retinal error is below a predetermined level when the imaging devices are a predetermined distance from the target. 21. A method of controlling gaze in a binocular vision system as defined in claim 1 wherein the control signal comprises at least three control signals for controlling device motion in each of two dimensions. 22. A method of controlling sensor orientation in a bi-sensor system including a first sensory device, a second sensory device and a plurality of plants for controlling motion of the sensory devices, the method comprising the steps of: a) providing to a processor sensory errors relating to a location of a target as sensed by each of the two sensory devices; d) providing a model related to each plant from the plurality of plants to the processor; and, e) using a processor having a symmetric topology determining a same output signal for provision to the plurality of plants for controlling the sensory device motion, the control signal related to sensory device motion for reducing the sensory error from said sensory device, the determination in dependence upon the provided model and the provided sensory errors. 23. A method of controlling sensor orientation in a bi-sensor system as defined in claim 22 wherein the output signal includes a common component output signal and a differential component output signal. 24. A method of controlling sensor orientation in a bi-sensor system as defined in claim 23 wherein the sensory devices are imaging devices and wherein the differential component of the control signal is used to control one of panning and vergent motion of the sensory devices and the common component of the output signal is used for controlling the other of panning and vergent motion of the sensory devices. 25. A method of controlling sensor orientation in a bi-sensor system as defined in claim 22 wherein the sensory devices are imaging devices and wherein the processor is a single processor for calculating in an interdependent fashion the output signal related to the sensory device motion for both pan and vergence of the two imaging devices absent calculation of target location in spatial co-ordinates. 26. A method of controlling sensor orientation in a bi-sensor system as defined in claim 22 wherein the sensory errors are not based on a world co-ordinate system. 27. A method of controlling sensor orientation in a bi-sensor system as defined in claim 22 wherein the sensory devices, the controller and the plants define a feedback loop for accepting sensory errors and providing a control signal for moving the sensory devices in order to reduce the sensory errors, the control signal being provided to the plants until the sensory errors are substantially 0. 28. A method of controlling sensor orientation in a bi-sensor system as defined in claim 27 wherein the feedback loop operates in each of two modes, a first mode for reducing small sensory errors and a saccade mode for reducing sensory errors other than small sensory errors. 29. A method of controlling sensor orientation in a bi-sensor system as defined in claim 28 wherein during saccade mode the control signal relates to substantially rapid motion of the sensory devices. 30. A method of controlling sensor orientation in a bi-sensor system as defined in claim 29 wherein the control signal relates substantially rapid motion including panning and vergence motion. 31. A method of controlling sensor orientation in a bi-sensor system as defined in claim 22 comprising the step of: providing sensory data from another sensory device; wherein the two sensory devices, the other sensory device, the controller and the plants define a feedback loop for accepting sensory errors and sensory data and for providing a control signal for moving the sensory devices in order to reduce the sensory errors, the control signal being provided to the plants until the sensory errors are substantially 0. 32. A controller for a vision system having an imaging device associated with a plant for providing motion to the imaging device, the controller comprising: a first processor for controlling saccade phase movement of the imaging device, the first processor having a first input and a first output; a second processor for controlling slow phase movement of the imaging device, the second processor having a second input and a second output; wherein the second processor and the first processor are substantially same and are provided with same input signal and provide an output signal to a same plant. 33. A controller for a vision system as defined in claim 32, wherein the vision system is a binocular vision system having two imaging devices each associated with a plant for providing motion to the imaging devices; wherein the first processor has first inputs and first outputs; wherein the second processor has second inputs and second outputs; and wherein the second processor and the first processor are provided with same input signals and provide output signals to same plants. 34. A controller for a vision system as defined in claim 32 wherein the first processor and the second processor are a same processor having some different gain parameters. 35. A controller for a vision system as defined in claim 34 wherein the some different gain parameters are zero for a processor of the first processor and the second processor and another non-zero value for the other processor of the first processor and the second processor. 36. A controller for a vision system as defined in claim 32 wherein the second processor comprises a feedback loop having stable open loop dynamics. 