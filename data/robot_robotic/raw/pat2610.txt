Prosthetic devices, methods and systems are disclosed. Eye position and/or neural activity of a primate are recorded and combined. The combination signal is compared with a predetermined signal. The result of the comparison step is used to actuate the prosthetic device.
Claims What is claimed is: 1. A method to control spatial positioning of a prosthetic device, the prosthetic device able to assume multiple spatial positions upon input from a subject, the method comprising: recording eye position information of the subject to produce an eye position signal, the eye position information including a portion recorded during a scan stage that occurs after the subject views a plurality of reach goals but before the subject selects one of the plurality of reach goals; recording neural activity of the subject to produce a neural activity signal, the neural activity including a portion recorded during the scan stage; combining the eye position signal and the neural activity signal to provide a recorded behavioral pattern; comparing the recorded behavioral pattern with at least one predetermined behavioral pattern to identify a matching predetermined behavioral pattern associated with a selection of one of the plurality of reach goals and at least one predetermined spatial position of the prosthetic device; and positioning the prosthetic device in the spatial position associated with the matching predetermined behavioral pattern. 2. The method of claim 1, wherein the eye position and the neural activity are simultaneously recorded. 3. The method of claim 1, wherein the eye position is recorded directly. 4. The method of claim 1, wherein the eye position is recorded indirectly. 5. The method of claim 1, wherein recording the neural activity further comprises detecting spike activity, local field potential ("LFP") activity, or both. 6. The method of claim 1, wherein the subject is a primate. 7. The method of claim 1, wherein the eye position information recorded further includes a portion recorded after the scan stage, and the neural activity recorded further includes a portion recorded after the scan stage. 8. The method of claim 1, wherein the eye position information recorded further includes a portion recorded during a look-reach stage occurring after the scan stage, and the neural activity recorded further includes a portion recorded during a look-reach stage occurring after the scan stage. 9. A method for use with a subject, the method comprising: receiving a first neural activity signal generated by one or more neurons after the subject has viewed the plurality of reach goals but before the subject has selected one of the plurality of reach goals; receiving a second neural activity signal generated by one or more neurons after the subject has viewed the plurality of reach goals but before the subject has selected one of the plurality of reach goals; analyzing the first neural activity signal to obtain positions of the subject's eyes after the subject has viewed the plurality of reach goals but before the subject has selected one of the plurality of reach goals; analyzing the positions of the subject's eyes and the second neural activity signal to determine which of the plurality of reach goals is most likely to be selected by the subject; and positioning a prosthetic device in a spatial position associated with the reach goal determined to be most likely to be selected by the subject. 