A method for processing an image of a microfluidic device. The method includes receiving a first image of a microfluidic device. The first image corresponds to a first state. Additionally, the method includes receiving a second image of the microfluidic device. The second image corresponds to a second state. Moreover, the method includes transforming the first image and the second image into a third coordinate space. Also, the method includes obtaining a third image based on at least information associated with the transformed first image and the transformed second image, and processing the third image to obtain information associated with the first state and the second state.
Claims What is claimed is: 1. A method for processing an image of a microfluidic device, the method comprising: receiving a first image of a microfluidic device, the first image corresponding to a first state; receiving a second image of the microfluidic device, the second image corresponding to a second state; transforming the first image into a third coordinate space, using a processor, the transforming using at least a first fiducial on the first image; transforming the second image into the third coordinate space, using the processor, the transforming using at least a second fiducial on the second image; obtaining a third image based on at least information associated with the transformed first image and the transformed second image; processing the third image to obtain information associated with the first state and the second state using the processor. 2. The method of claim 1, the method further comprising: locating the at least a first fiducial on the first image; locating the at least a second fiducial on the second image. 3. The method of claim 1 wherein the transforming the first image into a third coordinate space comprises: associating the at least a first fiducial to at least a third fiducial in the third coordinate space; performing a first transformation to the first image based on at least information associated with the at least a first fiducial and the at least a third fiducial. 4. The method of claim 3 wherein the performing a first transformation comprises: estimating the first transformation based on at least information associated with the at least a first fiducial and the at least a third fiducial; converting the first image into the third coordinate space, the converting using the first transformation. 5. The method of claim 4 wherein the transforming the second image into the third coordinate space comprises: associating the at least a second fiducial to the at least a third fiducial in the third coordinate space; performing a second transformation to the second image based on at least information associated with the at least a second fiducial and the at least a third fiducial. 6. The method of claim 5 wherein the performing a second transformation comprises: estimating the second transformation based on at least information associated with the at least a second fiducial and the at least a third fiducial; converting the second image into the third coordinate space, the converting using the second transformation. 7. The method of claim 1 wherein the obtaining a third image comprises: obtaining a difference between the first image and the second image. 8. The method of claim 7 wherein the obtaining a third image further comprises: masking at least a first part of the first image, the at least a first part free from information associated with the first state; masking at least a second part of the second image, the at least a second part free from information associated with the second state. 9. The method of claim 8 wherein the at least a second part corresponds to the at least a first part, the at least a second part based on at least information associated with a change of a feature from the first image to the second image. 10. The method of claim 7 wherein the obtaining a third image further comprises masking at least a third part of the third image, the at least a third part free from information associated with the first state and the second state. 11. The method of claim 10 wherein the at least a third part is based on at least information associated with a change of a feature from the first image to the second image. 12. A computer-readable medium including instructions for processing an image of a microfluidic device, the computer-readable medium comprising: one or more instructions for receiving a first image of a microfluidic device, the first image corresponding to a first state; one or more instructions for receiving a second image of the microfluidic device, the second image corresponding to a second state; one or more instructions for transforming the first image into a third coordinate space, the transforming using at least a first fiducial on the first image; one or more instructions for transforming the second image into the third coordinate space, the transforming using at least a second fiducial on the second image; one or more instructions for obtaining a third image based on at least information associated with the transformed first image and the transformed second image; one or more instructions for processing the third image to obtain information associated with the first state and the second state. 13. The computer-readable medium of claim 12, the computer-readable medium further comprising: one or more instructions for locating the at least a first fiducial on the first image; one or more instructions for locating the at least a second fiducial on the second image. 14. The computer-readable medium of claim 12 wherein the one or more instructions for transforming the first image into a third coordinate space comprises: one or more instructions for associating the at least a first fiducial to at least a third fiducial in the third coordinate space; one or more instructions for performing a first transformation to the first image based on at least information associated with the at least a first fiducial and the at least a third fiducial. 15. The computer-readable medium of claim 14 wherein the one or more instructions for performing a first transformation comprises: one or more instructions for estimating the first transformation based on at least information associated with the at least a first fiducial and the at least a third fiducial; one or more instructions for converting the first image into the third coordinate space, the converting using the first transformation. 16. The computer-readable medium of claim 15 wherein the one or more instructions for transforming the second image into the third coordinate space comprises: one or more instructions for associating the at least a second fiducial to the at least a third fiducial in the third coordinate space; one or more instructions for performing a second transformation to the second image based on at least information associated with the at least a second fiducial and the at least a third fiducial. 17. The computer-readable medium of claim 16 wherein the one or more instructions for performing a second transformation comprises: one or more instructions for estimating the second transformation based on at least information associated with the at least a second fiducial and the at least a third fiducial; one or more instructions for converting the second image into the third coordinate space, the converting using the second transformation. 18. The computer-readable medium of claim 12 wherein the one or more instructions for obtaining a third image comprises: one or more instructions for obtaining a difference between the first image and the second image. 19. The computer-readable medium of claim 18 wherein the one or more instructions for obtaining a third image further comprises: one or more instructions for masking at least a first part of the first image, the at least a first part free from information associated with the first state; one or more instructions for masking at least a second part of the second image, the at least a second part free from information associated with the second state. 20. The computer-readable medium of claim 19 wherein the at least a second part corresponds to the at least a first part, the at least a second part based on at least information associated with a change of a feature from the first image to the second image. 21. The computer-readable medium of claim 18 wherein the one or more instructions for obtaining a third image further comprises one or more instructions for masking at least a third part of the third image, the at least a third part free from information associated with the first state and the second state. 22. The computer-readable medium of claim 21 wherein the at least a third part is based on at least information associated with a change of a feature from the first image to the second image. 23. The method of claim 1 wherein the first state is different from the second state. 24. The method of claim 1 wherein the first state is the same as the second state. 25. The method of claim 1 wherein the first state is associated with absence of crystallization. 26. The method of claim 25 wherein the second state is associated with presence of crystallization. 27. The method of claim 25 wherein the second state is associated with absence of crystallization. 28. The computer-readable medium of claim 12 wherein the first state is different from the second state. 29. The computer-readable medium of claim 12 wherein the first state is the same as the second state. 30. The computer-readable medium of claim 12 wherein the first state is associated with absence of crystallization. 31. The computer-readable medium of claim 30 wherein the second state is associated with presence of crystallization. 32. The computer-readable medium of claim 30 wherein the second state is associated with absence of crystallization. 33. The method of claim 1 wherein: the first image comprises a first chamber region associated with a first chamber boundary; the second image comprises a second chamber region associated with a second chamber boundary; the obtaining a third image comprises determining an implosion padding based on information associated with the first image and the second image. 34. The method of claim 33 wherein the determining an implosion padding comprises: processing information associated with the first image; determining a first index related to a first implosion associated with the first chamber boundary based on at least information associated with the first image; processing information associated with the second image; determining a second index related to a second implosion associated with the second chamber boundary based on at least information associated with the second image; processing information associated with the first index and the second index; determining the implosion padding based on at least information associated with the first index and the second index. 35. The method of claim 34 wherein the determining a first index related to a first implosion comprises: selecting a plurality of image areas, the plurality of image areas associated with a plurality of boundaries respectively; determining a plurality of median intensities associated with the plurality of boundaries respectively; processing information associated with the plurality of median intensities; determining the first index based on at least information associated with the plurality of median intensities. 36. The method of claim 35 wherein the determining the first index based on at least information associated with the plurality of median intensities comprises: determining a minimum intensity from the plurality of median intensities, the minimum intensity being associated with one of the plurality of boundaries; determining the first index based on at least information associated with the one of the plurality of boundaries. 37. The computer-readable medium of claim 12 wherein: the first image comprises a first chamber region associated with a first chamber boundary; the second image comprises a second chamber region associated with a second chamber boundary; the one or more instructions for obtaining a third image comprises one or more instructions for determining an implosion padding based on information associated with the first image and the second image. 38. The method of claim 37 wherein the one or more instructions for determining an implosion padding comprises: one or more instructions for processing information associated with the first image; one or more instructions for determining a first index related to a first implosion associated with the first chamber boundary based on at least information associated with the first image; one or more instructions for processing information associated with the second image; one or more instructions for determining a second index related to a second implosion associated with the second chamber boundary based on at least information associated with the second image; one or more instructions for processing information associated with the first index and the second index; one or more instructions for determining the implosion padding based on at least information associated with the first index and the second index. 39. The computer-readable medium of claim 38 wherein the one or more instructions for determining a first index related to a first implosion comprises: one or more instructions for selecting a plurality of image areas, the plurality of image areas associated with a plurality of boundaries respectively; one or more instructions for determining a plurality of median intensities associated with the plurality of boundaries respectively; one or more instructions for processing information associated with the plurality of median intensities; one or more instructions for determining the first index based on at least information associated with the plurality of median intensities. 40. The computer-readable medium of claim 39 wherein the one or more instructions for determining the first index based on at least information associated with the plurality of median intensities comprises: one or more instructions for determining a minimum intensity from the plurality of median intensities, the minimum intensity being associated with one of the plurality of boundaries; determining the first index based on at least information associated with the one of the plurality of boundaries. 