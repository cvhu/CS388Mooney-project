The "next best view" (NBV) problem encountered while acquiring the surface geometry of an object using a range scanner is solved by determining the next position for the range scanner given its previous scans of the object. A new representation, positional space, is used as a unified data structure for representing what must be and what can be scanned. The image of the range scanner in positional space is computed off-line for particular positions of the range scanner in its work space and stored in a file. Then, when the next best view is to be determined during the analysis of the object, each scanner image is simply retrieved from the file instead of being recreated by translating the scanner image calculated for some other position on the work space of the range scanner. A linear objective function of the stored scanner images and images of a seen and an unseen surface of the object is then maximized over all scanner positions to determine the next best view. This approach accommodates all range based sensors and allows arbitrarily shaped positional space surfaces and work spaces to be used while also saving in on-line computation time.
Claims What is claimed is: 1. A method of acquiring a three-dimensional surface image of an object using a range camera, comprising the steps of: storing in a memory positional space representations of ranging rays generated by a range camera for each camera position in a work space of said range camera at which said range camera may be positioned to scan said object; scanning the object with the range camera to create a partial surface image of the object including a seen surface and an unseen surface; determining the next best view position for viewing said unseen surface of the object from a number of possible positions, orientations, and sampling parameters of said range camera by comparing said positional space representations of said ranging rays from certain camera positions stored in said memory with observation rays from seen and unseen surfaces of said object; and scanning the object with the range camera at the determined next best view position and updating said partial surface image to include the image data acquired at the determined next best view position. 2. A method as in claim 1, wherein said step of determining the next best view position comprises the steps of defining void patches on the unseen surface at an edge of the seen surface, computing a representation of the unseen surface in positional space P.sub.v by projecting each observation ray of each void patch into positional space where a value of a cell (w, y) and angles .theta. and .phi. of each projection in a local coordinate system centered at cell (w, y) in positional space is computed as: ##EQU7## where o is an observation ray of a void patch, .parallel.e.sub.T .parallel. is the area of a triangle of the object that the void patch is attached to, and c.sub.o is the confidence of o, where the confidence of o is a function of a surface normal of the void patch and of o, and computing a representation of the seen surface in positional space as: ##EQU8## where o is an observation ray of a triangle T of the object. 3. A method as in claim 2, wherein said step of storing positional space representations of ranging rays generated by the range camera for each camera position in the range camera's work space is performed prior to acquiring any surface data of said object and comprises the step of calculating, for i=1 to n positions in said work space where said range camera may be positioned to scan said object, an image P.sub.c.sup.i in positional space of the range scanner at position i, defined as: ##EQU9## where r is a ranging ray from the range camera at the position i in the range camera's work space. 4. A method as in claim 2, wherein the unseen surface P'.sub.v includes observation rays of triangles of said object having confidences lower than a predetermined confidence u, where confidence c.sub.T of triangle T of the object is the minimum confidence of the three vertices of triangle T whose confidences are the angle between the ranging ray of the vertex and a normal to triangle T, defined as: ##EQU10## where o.sub.s is the observation ray of the triangle T of the object, and o.sub.v is an observation ray of a void patch attached to the triangle e.sub.T. 5. A method as in claim 3, wherein said step of determining the next best view position comprises the step of maximizing an objective function N(i), i=1 to n, defined as: where ##EQU11## and o(v,s) is a function whose parameters represent the amount of unseen surface v and seen surface s visible by the range camera from position i. 6. The method as in claim 5, where: ##EQU12## for a threshold t. 7. A method as in claim 1, wherein said storing step further comprises the step of storing sampling parameters including at least one of field of view, resolution, focus, and magnification data for said range camera at each position in the work space of said range camera at which said range camera may be positioned to scan said object. 8. A method as in claim 1, wherein said positional space representation includes a positional space surface of arbitrary geometry which encloses a viewing volume of said object in such a way that every ranging ray from the range camera in any position in the work space of the range camera would intersect said positional space surface. 9. A method as in claim 8, wherein said positional space representation is either a cylindrical or spherical positional space surface which completely surrounds said viewing volume in positional space. 