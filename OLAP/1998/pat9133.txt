A robot having a vision system for sensing an image of a manipulated object is described. The system includes a robot with an end effector, a transparent gripper mounted on the end effector, a camera for sensing an image of a manipulated object, and an image processing apparatus for processing sensed image data to correct the image data for optical distortion, such as refraction-induced image shifts. Three dimensional image information may be retrieved by including a light plane source and adapting the image processing apparatus to perform three-dimensional image processing.
Claims We claim: 1. A robot for manipulating an object, comprising: (a) an end effector forming a mechanical component of said robot; (b) a substantially entirely transparent gripper, mechanically coupled to said end effector, to grip said object being manipulated; (c) an optical image sensor, optically coupled to said transparent gripper, to sense an image of said object through a surface of said transparent gripper, and for converting a sensed image of said object into image data; and (d) image data processing apparatus, coupled to said sensor, for processing said image data to remove optical artifacts, including distortion due to refraction, introduced by said gripper therefrom. 2. The robot of claim 1, wherein said transparent gripper is a parallel jaw gripper comprising: (a) a mounting piece; and (b) two substantially transparent parallel jaws, each jaw having a top portion, wherein each of said parallel jaws is connected to said mounting piece at said top portion. 3. The robot of claim 2, wherein said mounting piece of said parallel jaw gripper is connected to said top portion of a first of said two parallel jaws by at least one bearing, whereby said first parallel jaw is capable of translational movement with respect to the other of said two parallel jaws. 4. The robot of claim 2, wherein said optical sensor is connected to an outer face of one of said parallel jaws. 5. The robot of claim 1, wherein said transparent gripper is made from a substantially transparent plastic material. 6. The robot of claim 5, wherein said transparent gripper is made from polymethyl methacrylate. 7. The robot of claim 1, wherein said sensor is a charged coupled device sensor. 8. The robot of claim 1, wherein said robot is a robot having at least five degrees of freedom. 9. The robot of claim 1, wherein said image data processing apparatus is further adapted to perform transformation processing prior to performing optical distortion processing, whereby said image data is transformed from data corresponding to a frame of reference of said optical sensor to data corresponding to a world frame of reference. 10. The robot of claim 1, further comprising: (e) a light plane source, optically coupled to said transparent gripper and to said optical sensor, for illuminating said object with a plane of light sensible by said optical sensor; wherein said optical sensor is a light stripe range finder and said image data processing apparatus is further adapted to perform three-dimensional image processing to thereby retrieve three-dimensional information for said object. 11. The robotic vision system of claim 10, further comprising: (f) depth map storage means, coupled to said image processing apparatus, for storing derived three-dimensional information for said object as a depth map. 12. The robotic vision system of claim 11, further comprising: (g) display means, coupled to said depth map storage means, for displaying said depth map as a wireframe on a bitmapped workstation. 13. An apparatus for manipulating an object, comprising: (a) a gripper base; (b) substantially entirely transparent gripper means, connected to said gripper base, for gripping said object; (c) sensor means, optically coupled to said transparent gripper means, to sense an image of said object through a surface of said transparent gripper means and for converting a sensed image of said object into image data; and (d) image data processing means, coupled to said sensor means, for processing said image data to remove optical artifacts, including distortion due to refraction, introduced by said gripper means therefrom. 14. The apparatus of claim 13, wherein said sensor means is an active sensor. 15. The apparatus of claim 13, wherein said sensor means is adapted to sense a plurality of images of said object, and said image data processing means is adapted to perform three-dimensional image processing to thereby retrieve three-dimensional information for said object. 16. The apparatus of claim 15, wherein said gripper base is a rotatable base and said plurality of images of said object are sensed by rotating said base. 17. The robotic vision system of claim 15, further comprising: (e) a movable light plane source, optically coupled to said transparent gripper means and to said sensor means, for illuminating said object with a plane of light sensible by said sensor means, wherein said sensor means is a movable camera, and said plurality of images of said object are sensed by moving said movable light plane source and said camera to a plurality of different positions corresponding to each of said images. 18. A method for manipulating an object by a robot, comprising the steps of: (a) gripping said object with a substantially entirely transparent gripper; (b) sensing an image of said object, through a surface of said substantially entirely transparent gripper; (c) converting said sensed image into image data; and (d) processing said image data to remove any optical artifact, including distortion due to refraction, introduced by said gripper therefrom, whereby data for a substantially undistorted image of said object is generated. 19. The method of claim 18, further comprising illuminating said object with a plane of light prior said sensing step, wherein said sensing step comprises sensing an image of said illuminated object, and said image processing step further comprises performing three-dimensional image processing to thereby retrieve three-dimensional information for said object. 20. The method of claim 18, wherein said sensing step comprises sensing two or more images of said object, and said image processing step further comprises performing three-dimensional image processing to thereby retrieve three-dimensional information for said object. 