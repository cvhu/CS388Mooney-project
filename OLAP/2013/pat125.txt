The present disclosure describes a fused saliency map from visual and auditory saliency maps. The saliency maps are in azimuth and elevation coordinates. The auditory saliency map is based on intensity, frequency and temporal conspicuity maps. Once the auditory saliency map is determined, the map is converted into azimuth and elevation coordinates by processing selected snippets of sound from each of four microphones arranged on a robot head to detect the location of the sound source generating the saliencies.
Claims What is claimed is: 1. A computer program product for computing a fused saliency map derived from visual and auditory sensors, the computer program product comprising a non-transitory computer-readable medium having computer program instructions stored therein for causing at least one computer to perform operations of: computing a first saliency map from data generated by visual sensors; computing a second saliency map in frequency versus time coordinates from data generated by auditory sensors; localizing one or more salient peaks in the second saliency map in azimuth and elevation; constructing an auditory saliency map in azimuth-elevation coordinates by assigning the largest auditory sensor signal for each salient peak in the second saliency map to a weighted distribution centered at the previously localized azimuth and elevation with a standard deviation; fusing the first and auditory saliency maps as a weighted combination of each, into a fused saliency map, then normalizing the fused saliency map. 2. The computer program product of claim 1 having computer program instructions stored therein for causing the at least one computer to perform localization operations of: determining a frequency and time band for each salient peak of the second saliency map; extracting a snippet of sound from each auditory sensor based on the frequency and time band for each salient peak; filtering the snippets of sound to remove echoes and noise; reducing each filtered snippet of sound into an onset envelope signal; converting each onset envelope to a series of weighted Kronecker delta functions; calculating an azimuth Interaural Time Difference by cross correlating corresponding weighted Kronecker Delta functions for each salient peak; calculating an azimuth angle for each salient peak from the azimuth Interaural Time Differences; calculating an elevation Interaural Time Difference by cross correlating corresponding weighted Kronecker delta functions for each salient peak calculating an elevation angle for each salient peak from the elevation Interaural Time Difference. 3. The computer program product of claim 1 wherein the weighted distribution is a Gaussian distribution. 4. A computer program product for computing an auditory saliency map in spatial coordinates from auditory sensor data obtained from auditory sensors, the computer program product comprising a non-transitory computer-readable medium having computer program instructions stored therein for causing at least one computer to perform operations of: computing a first saliency map in frequency versus time coordinates from data generated by the auditory sensors; localizing one or more salient peaks in the first saliency map in azimuth and elevation; constructing an auditory saliency map in azimuth-elevation coordinates by assigning the largest auditory sensor signal for each salient peak centered at the previously localized azimuth and elevation coordinates to a Gaussian distribution with a standard deviation; normalizing the auditory saliency map. 5. The computer program product of claim 4 having computer program instructions stored therein for localizing one or more salient peaks wherein the localization comprises instructions for: determining a frequency and time band for each of one or more salient peak of the first saliency map; extracting a snippet of sound from each auditory sensor based on the frequency and time band for each salient peak; filtering the snippets of sound to remove echoes and noise; reducing each filtered snippet of sound into an onset envelope signal; converting the onset envelope to a series of weighted Kronecker delta functions for each salient peak; calculating an azimuth Interaural Time Difference by cross correlating corresponding weighted Kronecker Delta functions for each snippet of sound; calculating an azimuth angle for each salient peak from the azimuth Interaural Time Differences; calculating an elevation Interaural Time Difference by cross correlating corresponding weighted Kronecker delta functions for each salient peak; calculating an elevation angle for each salient peak from the elevation Interaural Time Difference. 6. A system for robot control comprising: a first eye camera, a second eye camera, at least a left auditory sensor and a right auditory sensor, all mounted on a robot head and all providing data to at least one computer; wherein the robot head has a head centered coordinate system; the at least one computer programmed to execute instructions stored on a computer readable medium for causing the computer to perform operations of: receive said first eye camera, second eye camera, left and right auditory sensors, data; and compute a visual saliency map from the first eye camera and second eye camera data in the head centered coordinate system; compute an auditory saliency map in head centered coordinates from at least the left and right auditory sensor data; fuse the visual and auditory saliency maps according to a weighting function. 7. The system for robot control of claim 6 wherein the computer readable medium further comprises instructions therein for causing the computer to command the robot head to focus on salient objects as determined by computer program inputs. 8. The system for robot control of claim 6 wherein the computer readable medium further comprises instructions stored therein for causing the computer to compute the auditory saliency map by performing operations of: computing a second saliency map in frequency versus time coordinates from data generated by said auditory sensors; determining a frequency and time band for each salient point of the second saliency map; extracting a snippet of sound from each auditory sensor based on the frequency and time band for each salient peak; filtering the snippets of sound to remove echoes and noise; reducing each filtered snippet of sound into an onset envelope signal; converting the onset envelope to a series of weighted Kronecker delta functions; calculating an azimuth Interaural Time Difference by cross correlating corresponding weighted Kronecker delta functions for each salient peak; calculating an azimuth angle for each salient peak from the azimuth Interaural Time Differences; calculating an elevation Interaural Time Difference by cross correlating corresponding weighted Kronecker delta functions; calculating an elevation angle for each salient peak from the elevation Interaural Time Difference; constructing an auditory saliency map in azimuth-elevation coordinates by assigning the largest auditory sensor signal for each salient peak to a weighted distribution centered at the previously calculated azimuth and elevation with a standard deviation. 9. A method of fusing a visual saliency map with an auditory saliency map comprising: computing the visual saliency map in head centered coordinates from visual data; computing the auditory saliency map in head centered coordinates from data generated by auditory sensors; combining the visual and auditory saliency map as a weighted linear combination of the visual saliency map and auditory saliency map. 10. The method of claim 9 wherein the method of computing the visual saliency map uses object based segmentation. 11. The method of claim 9 wherein the method of computing the visual saliency map uses feature based segmentation. 12. The method of claim 9 wherein the method of computing the auditory saliency map comprises: computing a saliency map in frequency versus time coordinates from data generated by auditory sensors; determining the frequency and time band for each salient point of the saliency map; extracting a snippet of sound from each auditory sensor based on the frequency and time band; filtering the snippets of sound to remove echoes and noise; reducing each filtered snippet of sound into an onset envelope signal; converting the onset envelope to a series of weighted Kronecker delta functions; calculating an azimuth Interaural Time Difference by cross correlating corresponding weighted Kronecker Delta functions for each salient peak; calculating an azimuth angle for each salient peak from the azimuth Interaural Time Differences; calculating an elevation Interaural Time Difference by cross correlating corresponding weighted Kronecker Delta functions for each salient peak; calculating an elevation angle for each salient peak from the elevation Interaural Time Difference; constructing an auditory saliency map in azimuth-elevation coordinates by assigning the largest auditory sensor signal for each salient peak to a weighted distribution centered at the previously calculated azimuth and elevation with a standard deviation. 13. At least one computer programmed to execute a process for fusing visual and auditory saliency maps, the process comprising: computing a first saliency map from data generated by visual sensors; computing a second saliency map in frequency versus time coordinates from data generated by auditory sensors; localizing the salient peaks in the second saliency map in azimuth and elevation; constructing an auditory saliency map in azimuth-elevation coordinates by assigning the largest auditory sensor signal for each salient peak in the second saliency map to a weighted distribution centered at the previously localized azimuth and elevation with a standard deviation; fusing the first and auditory saliency maps as a weighted combination of each, then normalizing the fused saliency map. 14. The at least one computer programmed to execute a process of claim 13 wherein the weighted distribution is a Gaussian distribution. 15. The at least one computer programmed to execute a process of claim 13 wherein localizing the salient peaks in azimuth and elevation comprises: determining the frequency and time band for each salient point of the second saliency map; extracting a snippet of sound from each auditory sensor based on the frequency and time band; filtering the snippets of sound to remove echoes and noise; reducing each filtered snippet of sound into an onset envelope signal; converting the onset envelope to a series of weighted Kronecker delta functions; calculating an azimuth Interaural Time Difference by cross correlating corresponding weighted Kronecker Delta functions for each salient peak; calculating an azimuth angle for each salient peak from the azimuth Interaural Time Differences; calculating an elevation Interaural Time Difference by cross correlating corresponding weighted Kronecker delta functions for each salient peak; calculating an elevation angle for each salient peak from the elevation Interaural Time Difference. 16. An apparatus for focusing a robot's attention on one or more salient objects, the apparatus comprising: means for receiving data from a left eye camera, a right eye camera, a left microphone, a right microphone; means for processing said data into a visual saliency map in azimuth and elevation coordinates and an auditory saliency map in frequency versus time coordinates; means for localizing sources of salient data in the auditory saliency map; means for mapping the auditory saliency map into azimuth and elevation coordinates; means for fusing the auditory saliency map with the visual saliency map into a combined saliency map of the one or more salient objects; means for commanding the robot to focus its attention serially on the salient objects in the combined saliency map. 17. The apparatus of claim 16 wherein the means for localizing sources of salient data further comprises: means for determining a frequency and time band for each salient peak of the second saliency map; means for extracting a snippet of sound from each auditory sensor based on the frequency and time band for each salient peak; means for filtering the snippets of sound to remove echoes and noise; means for reducing each filtered snippet of sound into an onset envelope signal; means for converting each onset envelope to a series of weighted Kronecker delta functions; means for calculating an azimuth Interaural Time Difference by cross correlating corresponding weighted Kronecker Delta functions for each salient peak; means for calculating an azimuth angle for each salient peak from the azimuth Interaural Time Differences; means for calculating an elevation Interaural Time Difference by cross correlating corresponding weighted Kronecker delta functions for each salient peak means for calculating an elevation angle for each salient peak from the elevation Interaural Time Difference. 