An intelligent interface device for grasping an object includes a manipulating robot comprising a hinged arm provided with a clamp at its free end and equipped with at least one camera, a computer with a display screen and an input unit, means for controlling the clamp, means for displaying the video image of the object taken by a camera on the display screen, means for graphically identifying a selection area surrounding the object in this image using the input unit.
Claims The invention claimed is: 1. An intelligent interface device for grasping of an object comprising: a manipulating robot comprising a hinged arm provided with a clamp at its free end and equipped with at least one camera, a computer with a display screen and an input unit, means for controlling the clamp, means for displaying a video image of the object taken by a camera on the display screen, characterized in that it also includes: means for graphically identifying a selection area surrounding the object in this image using the input unit, the means for graphically identifying being piloted by four commands for upward, downward, leftward and rightward movement to trace this selection area surrounding the object, and a validation command, and in that the means for controlling the clamp comprises at least one graphic control button able to be actuated from the display screen and responding to at least one of the following commands: move the clamp to the left, move the clamp to the right, move the clamp downward, move the clamp upward move the clamp forward, move the clamp backward, open/close the clamp, turn the clamp clockwise, turn the clamp counterclockwise, validate, cancel, immediate stop. 2. The device according to claim 1, comprising two cameras forming a stereoscopic video sensor. 3. The device according to claim 1, in which the input unit is a mouse, a head tracking, a contactor, a virtual keyboard, a joystick, or an ocular monitoring or voice synthesis system. 4. The device according to claim 1, in which each command corresponds to a click on an icon shown on the display screen. 5. The device according to claim 1, in which the clamp is equipped with an optical barrier, or a proximity detector. 6. The device according to claim 1, in which the robot is fixed to the arm of a wheelchair. 7. The device according to claim 1, in which the robot is fixed on a mobile platform. 8. A method for implementing an intelligent interface device for grasping of an object comprising: a manipulating robot comprising a hinged arm provided with a clamp at its free end and equipped with at least one camera for taking a video image, a computer with a display screen and an input unit, characterized in that it comprises the following steps: bring the object into the field of vision of a camera by controlling the movement of the clamp, the video image taken by the camera being displayed on the display screen, identify a selection area around the object using the input unit, discriminate between the object and its environment, and estimate a distance between the clamp and the object, calculate the center of gravity of the object in the image, calculate a set speed according to the distance to be travelled by the clamp to reach the object, move the clamp up to the vicinity of the object, move the clamp blindly and close the clamp, bring the object back toward the user. 9. The method according to claim 8, in which the selection area surrounding the object is a rectangular area, a graphical lasso defined by several points chosen by the user, or a closed line traced surrounding the object. 10. The method according to claim 8, in which one uses two cameras forming a stereoscopic video sensor. 11. The method according to claim 10, in which one selects points of interest in the two images coming from the two cameras. 12. The method according to claim 11, in which one pairs these points two by two. 13. The method according to claim 10, in which one corrects the images coming from the two cameras. 