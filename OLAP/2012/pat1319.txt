A method of validating a probability of detection (POD) testing system using directed design of experiments (DOE) includes recording an input data set of observed hit and miss or analog data for sample components as a function of size of a flaw in the components. The method also includes processing the input data set to generate an output data set having an optimal class width, assigning a case number to the output data set, and generating validation instructions based on the assigned case number. An apparatus includes a host machine for receiving the input data set from the testing system and an algorithm for executing DOE to validate the test system. The algorithm applies DOE to the input data set to determine a data set having an optimal class width, assigns a case number to that data set, and generates validation instructions based on the case number.
Claims What is claimed as new and desired to be secured by Letters Patent of the United States is: 1. A method of validating the performance of a statistical testing system using directed design of experiments (DOE), the method comprising: recording an input data set in a memory location that is accessible by a host machine, wherein the input data set describes a set of observed probability of hit (POH) data for a plurality of samples as a function of a characteristic of the samples; processing the input data set using the host machine to thereby generate an output data set having an optimal class width; assigning a case number to the output data set; and generating a set of instructions using the assigned case number; wherein the instructions validate the performance of the testing system when the assigned case number equals a predetermined case number, and wherein the instructions inform a user of the testing system regarding required steps for validating the testing system when the assigned case number does not equal the predetermined case number. 2. The method of claim 1, wherein recording an input data set includes recording a flaw in the samples as the characteristic. 3. The method of claim 1, including using a processor to automatically calculate a lower confidence bound using the POH data, and recording the lower confidence bound using the host machine for use in processing the input data set. 4. The method of claim 1, wherein processing the input data set continues until a threshold POD and a lower confidence bound is reached for all samples within a given class width. 5. The method of claim 1, wherein processing the input data set includes generating a first intermediate data set for a first class width, increasing the size of the first class width by a constant value to produce a second class width, and then generating an additional intermediate data set for each of a plurality of different class widths. 6. The method of claim 1, wherein recording the input data set includes recording the results of a false call analysis procedure of a calibrated number of false call samples. 7. A method of validating a probability of detection (POD) testing system, the method comprising: recording an input data set in a memory location accessible by a host machine, the input data set describing a set of observed data for a plurality of sample components as a function of size of a flaw in the sample components; using the host machine to generate an output data set having an optimal class width, wherein the host machine generates the output data set using an algorithm that automatically processes the input data set through multiple class width iterations using directed design of experiments (DOE); selecting a case number from a plurality of predetermined cases using the output data set having the optimal class width; and generating a set of instructions based on the selected case, including at least one of displaying the set of instructions on a display screen, transmitting an electronic copy of the instructions to a remote system, and printing a report; wherein the content of the instructions corresponds to the selected case number and validates the testing system only when the selected case is equal to a predetermined ease number. 8. The method of claim 7, wherein the set of observed data is at least one of: a set of hit and miss data, a set of analog data with a corresponding threshold, and a set of false call data. 9. The method of claim 7, wherein using a host machine to generate an output data set having an optimal class width includes using a binomial solution to generate a data set having a POD that is a 90/95 POD. 10. The method of claim 7, further comprising: receiving a second input data set using the host machine; and processing the second input data set using the host machine to determine the output data set; wherein the second input data set is an additional set of POD data that is generated by one of the testing system and a device that is external to the testing machine. 11. The method of claim 7, further comprising: recording a dimensional limitation of the components; and automatically limiting the number of tests required at large class lengths using the dimensional limitation. 12. The method of claim 7, wherein recording the input data set includes recording the results of a false call analysis procedure of at least 84 false call samples or false call test opportunities. 13. The method of claim 7, wherein using a host machine to generate an output data set having an optimal class width includes processing at least 25 large flaws, wherein the large flaws are flaws that are uniformly distributed between a target flaw size (X.sub.POD) of the optimal class width and the largest expected flaw size. 14. An apparatus adapted for validating the probability of detection (POD) capability of a statistics-based testing system, the apparatus comprising: a host machine having a processor and a memory location, wherein the host machine in communication with the testing system and adapted for receiving an input data set from the testing system and recording the input data set in the memory location, and wherein the input data set describes a set of observed probability of hit (POH) data for a plurality of sample components as a function of size of a flaw in the components; and an algorithm for applying a directed design of experiments (DOE) to the input data set to thereby validate the performance of the testing system; wherein the algorithm is executed via the processor to: apply the DOE to the input data set to determine a data set having an optimal class width; assign a case number to the data set having the optimal class width; and generate a set of instructions having a validation result that is based on the case number. 15. The apparatus of claim 14, wherein the testing system is configured as a non-destructive evaluation inspection (NDE). 16. The apparatus of claim 14, wherein the set of instructions includes detailed steps describing how a user of the testing system may achieve a passing validation result for the testing system. 17. The apparatus of claim 16, wherein the set of instructions includes detailed steps describing how to qualify an inspector for use of the testing system once the testing system has been validated. 18. The apparatus of claim 14, wherein the algorithm determines the optimal class width by iterating the class width by predetermined constant values starting with a minimum class width and continuing to a maximum expected flaw size, and by selecting the data set having a threshold POD for all samples within that particular class width. 