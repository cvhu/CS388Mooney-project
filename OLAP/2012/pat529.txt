A user interface allows an operator to control the visual focus of digital, CG characters and/or physical robotic characters. An interface with one or more tiered shapes is overlaid on a video feed of the digital or physical character's surrounding environment. An operator can move the overlaid tiered shapes around the video feed with a standard input device like a mouse, stylus, or joystick to control the visual focus of the digital or physical character.
Claims What is claimed is: 1. A method for controlling movement of a physical three-dimensional robot, the method comprising the steps of: providing the physical three-dimensional robot; providing a computer system including a display device and an input device; providing a user interface software connected to the display device and the input device, wherein the user interface software is capable of manipulating a plurality of digital controls displayed on the display device in response to input from the input device; providing a control system software connected to the physical three-dimensional robot and the user interface software, wherein the control system software is capable of manipulating the physical three-dimensional robot in response to the manipulation of the plurality of digital controls by the input device; providing an environment on the display device that represents a field of vision of the physical three-dimensional robot, wherein the physical three-dimensional robot is not displayed in the environment on the display device; creating the plurality of digital controls to overlay onto the environment, wherein the plurality of digital controls are capable of being overlaid onto each other by the input device to cause movement of the physical three-dimensional robot; and moving one digital control of the plurality of digital controls from a first position to a second position within the environment on the display device in response to input from the input device, wherein such movement causes a movement of the physical three-dimensional robot. 2. The method of claim 1, wherein the step of moving one of the plurality of digital controls further comprises move a positioning indicator. 3. The method of claim 2, wherein the step of moving the positioning indicator moves a visual focus of the physical three-dimensional robot in multiple degrees of freedom. 4. The method of claim 2, wherein the step of moving the positioning indicator moves a visual focus of the physical three-dimensional robot from a first point to a second point. 5. The method of claim 4, wherein the first and second points can be mapped on a two-dimensional coordinate system. 6. The method of claim 1, wherein the plurality of digital controls are tiered in layers. 7. The method of claim 6, wherein a center of vision indicator is located in an innermost tier of the digital controls. 8. The method of claim 6, wherein the tiered digital controls move in conjunction with one another. 9. The method of claim 1, wherein the plurality of digital controls comprise of one or more graphical shapes. 10. The method of claim 1, wherein the wherein the step of providing an environment on the display device that represents a field of vision of the physical three-dimensional robot further comprises the step of providing environment in two-dimensions. 11. The method of claim 1, wherein the physical three-dimensional robot includes a camera-generated live video feed. 12. The method of claim 1, wherein the environment is real world. 13. The method according to claim 1, wherein the movement is selected from the group consisting of the movement of eyes, a head, a torso, arms, and full body. 14. The method according to claim 1, wherein the one digital control of the plurality of digital controls is a center of vision indicator of the physical three-dimensional robot. 15. The method according to claim 1, wherein the movement is the movement of the physical three-dimensional robot toward the second position. 16. The method according to claim 1, wherein the movement is the movement of the physical three-dimensional robot away from the second position. 17. A method for controlling movement of a computer generated character, the method comprising the steps of: providing the computer generated character; providing a computer system including a display device and an input device; providing a user interface software connected to the display device and the input device, wherein the user interface software is capable of manipulating a plurality of digital controls displayed on the display device in response to input from the input device; providing a control system software linked to the computer generated character and the user interface software, wherein the control system software is capable of manipulating the computer generated character in response to the manipulation of the plurality of digital controls by the input device; providing an environment on the display device that represents a field of vision of the computer generated character, wherein the computer generated character is not displayed in the environment on the display device; creating the plurality of digital controls to overlay onto the environment, wherein the plurality of digital controls are capable of being overlaid onto each other by the input device to cause movement of the computer generated character; and moving one digital control of the plurality of digital controls from a first position to a second position within the environment on the display device in response to input from the input device, wherein such movement causes a movement of the computer generated character. 18. The method of claim 17, wherein the tiered, digital controls comprise of one or more graphical shapes. 19. The method of claim 17, wherein the tiered digital controls move in conjunction with one another. 20. The method of claim 17, wherein the step of providing an environment on the display device that represents a field of vision of the computer generated character further comprises the step of providing the environment in two-dimensions. 21. The method of claim 17, wherein the step of providing an environment on the display device that represents a field of vision of the computer generated character further comprises the step of providing a camera-generated live video feed. 22. The method of claim 17, wherein the environment is real world. 23. The method according to claim 17, wherein the movement is selected from the group consisting of the movement of eyes, a head, a torso, arms, and full body. 24. The method according to claim 17, wherein the one digital control of the plurality of digital controls is a center of vision indicator of the computer generated character. 25. The method according to claim 17, wherein the movement is the movement of the computer generated character toward the second position. 26. The method according to claim 17, wherein the movement is the movement of the computer generated character away from the second position. 27. The method of claim 17, wherein the plurality of digital controls are tiered in layers. 