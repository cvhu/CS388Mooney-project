The invention generally pertains to a combination of a haptic device with a computer-assisted surgery system. The haptic device may be used as an input device, allowing information to pass from the user to the computer-assisted surgery system, and providing functionality similar to common user interface devices, such as a mouse or any other input device. When used as an input device, it may be used for defining anatomical reference geometry, manipulating the position and/or orientation of virtual implants, manipulating the position and/or orientation of surgical approach trajectories, manipulating the positions and/or orientation of bone resections, and the selection or placement of any other anatomical or surgical feature.
Claims What is claimed is: 1. A method for using a haptic device as an input device, comprising: receiving information identifying a virtual haptic object which is modifiable by said haptic device, said virtual haptic object being associated with a processor of a computer-assisted surgery system; receiving with the processor an input from said haptic device; modifying at least one of a position, a size, a shape, and an orientation of said virtual haptic object in the processor in response to receiving the input from said haptic device; and restricting movement of said haptic device relative to at least two directions in accordance with the virtual haptic object, wherein the directions are defined relative to at least a portion of an anatomy of a patient. 2. The method of claim 1, wherein said virtual haptic object comprises one of: a virtual implant, a surgical approach trajectory, an anatomical reference geometry, and a bone resection. 3. The method of claim 1, wherein a representation of said virtual haptic object is displayed on a display device overlaid on an anatomical diagnostic image associated with said computer-assisted surgery system such that the virtual haptic object and the representation are changed concurrently. 4. The method of claim 3, wherein said modifying step comprises modifying said virtual haptic object and the representation of the virtual haptic object based at least in part on a change in pose of said haptic device. 5. The method of claim 3, further including at least one of: steering, moving, and reconfiguring the virtual haptic object and the representation of the haptic device with a force or torque in excess of a threshold applied to the haptic device; and the steering, moving and reconfiguring the virtual haptic object and the representation of the virtual haptic device being in response to a change in at least one of a position and a pose of the haptic device. 6. The method of claim 1, wherein the virtual haptic object constrains movement of the haptic device and further comprising: associating a reference pose with a placement of a medical device coupled with said haptic device; and changing the placement in response to changing the pose of the haptic device without violating the constraints of the virtual haptic object. 7. The method of claim 1, further comprising storing positional information of a tip of said haptic device. 8. The method of claim 1, wherein modifying the virtual haptic object further includes repositioning the virtual haptic object by moving the virtual haptic object with the haptic device whose movement the virtual haptic object restricts. 9. The method of claim 1, wherein modifying the virtual haptic object further includes pivoting the virtual haptic object in response to movement of said haptic device. 10. The method of claim 1, wherein the step of the processor receiving the input from the haptic device includes changing a pose of said haptic device, such that the virtual haptic object is modified in response to changing the pose of the haptic device. 11. The method of claim 10, further comprising controlling a velocity of movement of a controlled object relative to the portion of patient anatomy based at least in part on said change in pose of said haptic device from a reference pose. 12. The method of claim 1, wherein the step of the processor receiving the input from the haptic device includes manually applying a wrench to the haptic device. 13. The method of claim 1, wherein a representation of the virtual haptic object is displayed on a diagnostic image depicting anatomy of the patient and on a display device, said modifying said virtual haptic object comprises changing a position of said virtual haptic object and the representation of the virtual haptic object relative to the diagnostic image on the display device based at least in part on a change in position of a tip of said haptic device. 14. The method of claim 1, wherein a representation of said virtual haptic object is displayed on a display device wherein said virtual haptic object has a plurality of segments with abrupt transitions between segments and further comprising restricting the movement of said haptic device such that said haptic device moves smoothly across the abrupt transitions between the segments of the displayed virtual haptic object representation and inhibits abrupt transitioning. 15. The method of claim 1, wherein modifying the virtual haptic object includes changing the shape of the haptic object. 16. The method of claim 1, wherein said modifying comprises dynamically modifying the virtual haptic object with the processor to prevent the haptic device from following an abrupt transition between segments of the haptic object. 17. The method of claim 1, further comprising: storing a reference pose of said haptic device; and updating the reference based at least in part on changing a current pose of said haptic device. 18. A system for a medical procedure, comprising: a computer-assisted surgery system; a display device; a haptic device communicatively coupled with said computer-assisted surgery system, said haptic device including an end effector configured for sculpting bone and being operable to provide input to said computer-assisted surgery system to control a virtual haptic object which defines bone to be removed by the end effector, the virtual haptic object having a plurality of segments; and a processor associated with said computer-assisted surgery system and programmed to: restrict movement of said haptic device relative to at least one predetermined direction in accordance with the virtual haptic object, wherein the predetermined direction is defined relative to at least a portion of an anatomy of a patient; control the display device to display a diagnostic image and to display a representation of the virtual haptic object overlaid on the diagnostic image; dynamically modify at least one of a position, a size, a shape, and an orientation of the virtual haptic object and the representation of the virtual haptic object as the end effector moves between segments during sculpting to inhibit the end effector from following an abrupt transition between the segments of the virtual haptic object. 19. The system of claim 18, wherein the processor is further programmed to change the shape of the virtual haptic object and the representation of the virtual haptic object in response to interaction between the end effector and the virtual haptic object. 20. The system of claim 18, wherein the processor is further programmed to dynamically modify at least one of a position and an orientation of the virtual haptic object to reposition the virtual haptic object in response to movement of the haptic device such that the haptic object is dynamically modified by movement of the haptic device whose movement is restricted by the virtual haptic object. 21. A system for computer-assisted surgery, comprising: a haptic device including an end effector which is configured to interact with anatomy of a patient undergoing surgery; a virtual haptic object having at least one surface that defines relative resistance to movement of the end effector; a processor operatively associated with said haptic device, the processor being programmed to: receive information identifying the virtual haptic object; receive input from said haptic device; control resistance to movement of said haptic device relative to at least a portion of the anatomy of the patient in accordance with the at least one surface of the virtual haptic object; and modify at least one of a position, a size, a shape, and an orientation of the virtual haptic object in response to movement of the haptic device; and a display device on which a representation of the virtual haptic object and a representation of the end effector are displayed superimposed on an anatomical image of the portion of the anatomy of the patient. 22. The system of claim 21, wherein modifying the representation of the virtual haptic object and the representation of the end effector is achieved without modifying the anatomical image. 23. The system of claim 21, wherein said processor is further programmed to modify the representation of the virtual haptic object and the representation of the end effector in response to interaction between the end effector and a surface of the virtual haptic object. 24. The system of claim 21, wherein the processor is further programmed to reposition the representation of the virtual haptic object relative to the anatomical image in response to a change in pose of said end effector. 25. The system of claim 21, wherein the processor is further programmed to modify an orientation of the virtual haptic object in response to a change in a pose of said haptic device. 26. The system of claim 25, wherein said processor is further programmed to move the representation of the end effector relative to the virtual haptic object with a velocity of movement of said representation of the end effector based at least in part on said change in pose of said end effector relative to a reference pose. 27. The system of claim 21, wherein said processor is further programmed to modify a shape of at least one surface of said representation of said virtual haptic object based on the movement of the end effector. 28. The system of claim 21, wherein said received input includes manually applying a wrench to the haptic device. 29. The system of claim 21, wherein said processor is programmed to change the position of said representation of said virtual haptic object relative to a concurrently displayed anatomical image on the display device based at least in part on an interaction between the end effector of said haptic device and the virtual haptic object. 30. The system of claim 21, wherein the virtual haptic object has a plurality of surfaces, at least two of which surfaces meet at an abrupt edge and said processor is further programmed to restrict the movement of the end effector to inhibit the end effector from moving in an abrupt transition across the abrupt edge between the at least two surfaces. 31. The system of claim 21, wherein said processor is further programmed to cause the end effector of said haptic device to be moved toward a target in the anatomy. 32. The system of claim 21, wherein the end effector is a bone sculpting tool and the virtual haptic object represents a physical object and said processor is further programmed to restrict the movement of said haptic device such that said bone sculpting tool is inhibited from diverting from the shape of the physical object. 33. The system of claim 32, wherein said processor is further programmed to restrict the movement of said haptic device such that the bone sculpting tool is inhibited from moving with abrupt transitions. 34. The system of claim 32, wherein the physical object is a surgical implant and the processor is further programmed to restrict movement of the haptic device such that bone is sculpted to match the shape of the surgical implant. 35. The system of claim 21, wherein said processor is further programmed to store a reference pose of said haptic device and update the reference pose based at least in part on a change in pose of said haptic device. 36. The system of claim 21, wherein the processor is further programmed with a software module for use in connection with portions of an image guided surgical procedure, the module being configured to be used only a predefined number of times. 37. The system of claim 21, wherein the virtual haptic object and the representation of the virtual haptic object is movable from an initial position to a new position and is steered, moved, and reconfigured in response to a force or torque on the haptic device in excess of a threshold. 