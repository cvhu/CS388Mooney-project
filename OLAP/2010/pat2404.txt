A method for driving a robot in a manner of imitation by watching (non-contact manner) based on the movement of a moving object, which has a complicated shape often causing self-occlusion, is provided. A plurality of image data of the robot is associated with pre-arranged operation commands and stored in an image corresponding operation command storing means 11. In order to have the robot perform a movement, the moving objecting caused to perform a desired movement, and at the same time, image data of the moving object are obtained as robot operational image data in time-series. The image data specifying and operation command generating means 14 specifies image data corresponding to the operational image data included in the robot operational image data in time-series among the plurality of image data stored in the image corresponding operation command storing means 11, and provides a pre-arranged operation command corresponding to the specified image data to the robot as an operation command to drive the robot. Owing to this, such problems as complicated shape and self-occlusion of the moving object are eliminated, and the robot performs the movement in an imitating manner by watching.
Claims The invention claimed is: 1. A method for driving a robot according to an operation command comprising: a first step for providing a moving object, corresponding to the robot, a plurality of sensors for detecting movement of the moving object and an operation command generating device for generating the operation command based on output from the plurality of sensors, and storing a pre-arranged operation command of the operation command which the operation command generating device generates based on the output from the plurality of sensors while the moving object performs a same movement as a predetermined movement; a second step for obtaining an operational image data of the moving object, the operational image data being obtained while the moving object is moved in a desired movement or for obtaining the operational image data of the moving object or the imitation thereof, the operational image data being obtained in time series while the moving object or the imitation thereof is moved in a desired movement; a third step for storing the image data and the pre-arranged operation command in an image corresponding operation command storing means, the image data being associated with the pre-arranged operation command; a fourth step for obtaining an operational image data of the moving object or the imitation thereof as a robot operational image data, the operational image data being obtained in time series while the moving object or the imitation thereof is moved in a desired movement in order to have the robot perform the desired movement; a fifth step for specifying an image data corresponding to the operational image data included in the robot operational image data among the image data stored in the image corresponding operation command storing means and providing the pre-arranged operation command corresponding to the specified image data to the robot as the operation command. 2. The method for driving a robot as defined in claim 1, wherein in the fifth step, a similarity between the operational image data stored in the image corresponding operation command storing means and the image data included in the robot operational image data is used for determining a correspondence between the image data stored in the image corresponding operation command storing means and the operational image data included in the robot operational image data. 3. The method for driving a robot as defined in claim 1, wherein the moving object is a human hand, in the first step, a data glove is provided on the human hand, the data glove has a structure where the sensors are arranged at positions on a glove body, the positions corresponding to moving parts of the human hand which correspond to moving parts of a hand of the robot. 4. The method for driving a robot as defined in claim 1, wherein the moving object is a human hand, in the first step, a data glove is provided on the human hand, the data glove has a structure that the sensors are arranged at positions on a glove body, the positions corresponding to moving parts of the human hand which correspond to moving parts of the robot hand; in the second step, a plain glove is provided on the human hand with the data glove, the image data of the human hand which performs a predetermined movement at a same time when the first step is performed. 5. The method for driving a robot as defined in claim 1, wherein the imitation of the moving object is created by a imitation creating technique such as a computer graphics technique or the like and the image data is an imitation image data. 6. The method for driving a robot as defined in claim 1, wherein the imitation of the moving object is created by a computer graphics technique and an image data of the imitation is a computer graphics image data. 7. The method for driving a robot as defined in claim 1, wherein in the second step, the moving object is covered with a cover for covering an outer surface of the moving object with the sensors and the image data of the moving object is obtained at a same time when the first step is performed. 8. The method for driving a robot as defined in claim 5 or 6, wherein the moving object is a human hand and the image data obtained in the second step includes an individual image data created by considering the difference in physical figure of the human hand. 9. The method for driving a robot as defined in claim 5, 6 or 7 wherein the image data includes resolution modified image data made by changing the resolution of the image data. 10. The method for driving a robot as defined in claim 6, wherein in the second step, the image data includes imitation image data between the one image data and the following image data which is obtained after the one image data has been obtained in time series, the imitation image data being created by the computer graphics technique; in the third step, a pre-arranged operation command is stored having a corresponding relationship with the imitation image data, the pre-arranged operation command corresponding to the imitation image data being created based on the one pre-arranged operation command corresponding to the one image data and the following pre-arranged operation command corresponding to the following image data. 11. The method for driving a robot as defined in claim 10, the third step comprising steps of: calculating the feature quantity of each of the image data, calculating a principal component score of each of the image data by a principal component analysis on the feature quantity of each of the image data, determining the number of principal components from a first principal component to a k-th principal component based on a cumulative contribution ratio of the principal component analysis, and storing k-kinds of image data source respectively corresponding to the principal components from the first principal component to the k-th principal component, each of the k-kinds of image data source being obtained by sorting the image data based on each of the principal component scores; and in the fifth step, the image data for matching is extracted from the k-kinds of image data source based on the principal component score, the principal component scores being obtained for each of the operational image data and a plural kinds of changed operational image data which have different resolutions from the operational image data. 12. The method for driving a robot as defined in claim 1, wherein in the fifth step, when an image data corresponding to the operational image data included in the robot operational image data is specified among the image data stored in the image corresponding operation command storing means, a plurality of image data for matching are selected depending on feature quantity of the operational image data and an image data corresponding to the operational image data is specified based on a similarity between the image data for matching and the operational image data. 13. The method for driving a robot as defined in claim 12, the feature of the operational image data is a principal component score on each principal component obtained by a principal component analysis on the operational image data. 