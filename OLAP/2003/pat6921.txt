In a telemanipulation system for manipulating objects located in a workspace at a remote worksite by an operator from an operator's station, such as in a remote surgical system, the remote worksite having a manipulator with an end effector for manipulating an object at the workspace, such as a body cavity, a controller including a hand control at the control operator's station for remote control of the manipulator, an image capture device, such as a camera, and image output device for reproducing a viewable real-time image, the improvement wherein a position sensor associated with the image capture device senses position relative to the end effector and a processor transforms the viewable real-time image into a perspective image with correlated manipulation of the end effector by the hand controller such that the operator can manipulate the end effector and the manipulator as if viewing the workspace in true presence. Image transformation according to the invention includes translation, rotation and perspective correction.
Claims What is claimed is: 1. A telesurgical method comprising: positioning a surgical end effector within an internal surgical site in a patient body, the surgical end effector operatively associated with a hand controller via a processor so that the processor effects a movement of the end effector in response to a movement of the hand controller; capturing an image of the surgical end effector within the internal surgical site with an endoscope; displaying the image of the end effector; moving the endoscope within the internal surgical site; dynamically realigning the movement of the image of the end effector relative to the movement of the hand controller by altering a coordinate transformation of the processor. 2. The telesurgical method of claim 1, wherein the dynamic realigning step is performed after the endoscope moving step. 3. The telesurgical method of claim 2, wherein the dynamically realigning step is performed so as to compensate for the endoscope moving step. 4. The telesurgical method of claim 1, wherein the dynamically realigning step aligns a direction of movement of the displayed image of the end effector with a direction of movement of the hand controller. 5. The telesurgical method of claim 1, further comprising statically realigning a displayed position of the image of the end effector relative to the hand controller. 6. A surgical robotic system comprising: a master controller having an hand input device movable in an operator controller workspace; a manipulator including a slave arm having a surgical end effector; at least one driving servo operatively coupled to the end effector, the driving servo moving the end effector in a surgical workspace in response to slave control signals; an imaging system including an image capture device with a field of view movable in the surgical workspace, the imaging system generating position signals indicating the field of view; and a processor coupling the master controller to the slave arm, the processor generating the slave control signals by mapping the input device in the operator workspace with the end effector in the surgical workspace according to a transformation, the processor deriving the transformation in response to the position signals of the imaging system. 7. The surgical robotic system of claim 6, wherein the image capture device moves independently of the manipulator slave. 8. The surgical robotic system of claim 7, wherein the processor derives the transformation so that an image of the end effector in the display appears substantially connected to the input device in the controller workspace. 9. The surgical robotic system of claim 6, wherein the manipulator slave generates signals responsive to a position of the end effector in the surgical workspace, the processor deriving the transformation using the signals of the slave. 10. The surgical robotic system of claim 9, wherein the processor determines a position and orientation of the input device in the master operator space from position signals of the master controller, wherein the processor determines a position and orientation of the end effector in the surgical workspace from the position signals of the slave, and wherein the processor generates the slave control signals by comparing the position and orientation of the input device and the end effector in the mapped space. 11. The surgical robotic system of claim 6, wherein the processor derives the transformation in real time. 12. A surgical robotic system comprising: a master controller having an hand control input device movable in a operator controller workspace; a slave manipulator having a surgical end effector and at least one driving servo operatively coupled to the end effector, the driving servo moving the end effector in a surgical workspace in response to slave control signals; an imaging system including an image capture device with a field of view movable in the surgical workspace, the imaging system transmitting an image to a display; and a processor coupling the master controller to the slave arm, the processor generating the slave control signals by mapping the input device in the controller workspace with the end effector in the surgical workspace according to a transformation, the processor deriving the transformation so that an image of the end effector in the display appears substantially connected to the input device in the workspace. 13. The surgical robotic system of claim 12, wherein points of articulation of the master controller and points of articulation of the slave manipulator define different locations in the mapped space. 14. The surgical robotic system of claim 12, wherein: the slave comprises an articulated manipulator including multiple points of motion supporting the end effector, the driving servos coupled to the points of motion so as to pivot a rigid shaft of the slave about a first arbitrary entry port for surgical access to a body cavity and move the end effector in response to slave control signals; and the imaging system comprises driving servos and an articulated assembly including multiple points of motion supporting the image capture device, the driving servos coupled to the articulated assembly to move the field of view within the surgical workspace when an endoscope of the image capture device extends through a second arbitrary entry port for surgical access to the body cavity. 15. The surgical robotic system of claim 12, wherein the processor calculates the transformation in response to a signal indicating at least one member of the group consisting of: a movement of the camera, a decoupling and repositioning of one of the master and the slave relative to the other, a change in scale of the mapping, and manual movement of the master or slave. 16. The surgical robotic system of claim 12, wherein the slave senses non-visual sensory information at the surgical workspace, the master controller presenting the non-visual information to a surgeon manipulating the input device. 17. The surgical robotic system of claim 16, wherein the non-visual sensory information includes tactile feedback from at least one manipulator to at least one hand control. 18. The surgical robotic system of claim 12, wherein the master controller presents non-visual sensory information to a surgeon manipulating the input device. 19. The surgical robotic system of claim 18, wherein the master controller provides tactile feedback to the surgeon manipulating the input device. 20. A surgical robotic method comprising: moving a master input device in a controller workspace by moving a plurality of points of articulation of the master; moving a surgical end effector in a surgical workspace by moving a plurality of points of articulation of the slave in response to slave control signals; displaying, on a display, an image of an arbitrary field of view within the surgical workspace adjacent the master controller; and automatically generating the slave control signals in response to moving the master so that an image of the end effector shown in the display appears substantially connected with the input device in the master controller space. 21. A Surgical robotic system comprising: a hand controller having a hand control input device in a operator controller workspace; a surgical end effector; an image capturing device with a field of view that captures an image of the end effector; a display displaying the image of the end effector in a surgical workspace; a processor generating a control signal coupling the hand controller and the end effector, the control signal related to a coordinate transformation; the processor deriving the coordinate transformation so that the image of the end effector in the display appears substantially related to the input device in the workspace; and the processor realigning the image of the end effector relative to the hand controller by altering the coordinate transformation. 