A method and system determines a 3D pose of an object in a scene. Depth edges are determined from a set of images acquired of a scene including multiple objects while varying illumination in the scene. The depth edges are linked to form contours. The images are segmented into regions according to the contours. An occlusion graph is constructed using the regions. The occlusion graph includes a source node representing an unoccluded region of an unoccluded object in scene. The contour associated with the unoccluded region is compared with a set of silhouettes of the objects, in which each silhouette has a known pose. The known pose of a best matching silhouette is selected as the pose of the unoccluded object.
Claims We claim: 1. A method for determining 3D pose of an object in a scene, comprising: determining depth edges from a set of images acquired of a scene including a plurality of objects while varying illumination in the scene; linking the depth edges to form contours; segmenting the images into regions according to the contours; constructing an occlusion graph using the regions, in which the occlusion graph includes a source node representing an unoccluded region of an unoccluded object in the scene; comparing the contour associated with the unoccluded region with a set of silhouettes of the plurality of objects, in which each silhouette has a known pose; and selecting the known pose of a best: matching silhouette as the pose of the unoccluded object, the steps are performed by a processor. 2. The method of claim 1, further comprising: picking the unoccluded object from the scene according to the pose. 3. The method of claim 1, in which the picking is performed by a robotic arm. 4. The method of claim 3, in which the camera is arranged on the robot arm. 5. The method of claim 1, in which, the plurality of objects are similar in appearance and shape. 6. The method of claim 1, in which the objects have a non-Lambertian surface. 7. The method, of claim 1, in which the varying illumination is from light sources above, below, and left and right of the camera. 8. The method of claim 1, in which the camera is a video camera. 9. The method of claim 1, further comprising: defining the depth edges as discontinuities between a boundary off the object and a background in the scene; and defining the shadow edges as discontinuities between a shadow cast by the object and the background. 10. The method of claim 9, in which linking has constraints that there is a parallel shadow edge for each depth edge, and the depth edge and shadow edge cannot coexist at a same pixel in the set of images. 11. The method of claim 1, in which the plurality of objects include specularities. 12. The method of claim 11, in which the set of images are and further comprising: determining an intrinsic image for each image I.sub.median from medians of gradient at each pixel in the set of images; replacing each image I.sub.i by I.sub.i=min(I.sub.i, I.sub.median); obtaining ratio images I.sub.i/I.sub.median; and determining the depth edges from the ratio images to minimize the specularities. 13. The method of claim 1, in which a directed arc runs from a first node to a second node when a first region represented by the first node casts a shadow on a second region represented by the second node, and the source node does not have an incoming arc edge. 14. The method of claim 13, further comprising: merging the first node and the second node if there is no arc between the first node and the second node. 15. The method of claim 3, in which the silhouettes and known poses are prestored in a memory or database. 16. The method of claim 3, in which the silhouettes and known poses are obtained from computer aided design model of different views of the plurality of objects. 17. The method of claim 1, in which the silhouettes include partial silhouettes. 18. The method of claim 1, in which the set of images are acquired by multiple cameras. 