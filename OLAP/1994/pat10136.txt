A method for calibrating a tool control frame (TCF) on a robot with respect to a known calibration reference claim (CRF), wherein the (CRF) is in rigid body relationship with a robot link. The method includes the steps of (a) attaching a sensory tool to the robot link, (b) calibrating the sensory tool with appropriate units of measurement, (c) identifying a calibration feature to be mapped by the sensory tool, (d) causing relative movement of the calibration feature within sensing range of the sensory tool, (e) recording robot configuration and pose as a first data record, (f) causing relative movement of the calibration feature and sensory tool along a known direction to a new position within sensing range, (g) recording configuration and pose as a second data record, and (h) applying coordinate transformations to the respective data records to generate a correct tool control frame (TCF) pose with respect to the (CRF).
Claims We claim: 1. A method for calibrating a tool control frame (TCF) of a robot with respect to a known calibration reference frame (CRF), which CRF moves with and is associated with a robot link in rigid body relationship, said method comprising the steps of: a) attaching a sensory tooling assembly to a link of the robot in rigid body relationship, which link has a known positional and orientational relationship with respect to the CRF and which allows for feedback of positional and/or orientational information with respect to a sensory reference frame associated with the sensory tooling assembly; b) calibrating the sensory tooling assembly and any data output systems associated with the tooling assembly to enable sensor output in units capable of defining physical dimensions; c) identifying a calibration feature separate from the robot which is capable of being mapped by the sensory tooling assembly; d) causing relative movement of the calibration feature and sensory tooling assembly to bring the calibration feature within sensing range without need of manually jogging the sensory tooling assembly to a specific alignment position with respect to the calibration feature; e) recording robot configuration and new relative position and orientation (pose) of the calibration feature with respect to the sensory reference frame as an initial configuration data record; f) causing relative movement of the calibration feature and sensory tooling assembly along a known direction such that the calibration feature and sensory tooling assembly are still within sensing range; g) recording robot configuration and new relative location and orientation of the calibration feature with respect to the sensory reference frame as a secondary configuration data record; h) determining if the orientation of the secondary configuration is the same as the orientation of the initial configuration data record; i) if the orientation of the initial and secondary configurations are the same, an additional orientational change is required and is accomplished and recorded by causing relative movement of the calibration feature and the sensory tooling assembly such that the calibration feature has a different orientation from the orientation as determined in the initial and secondary data records, and recording robot configuration and new relative location and orientation of the calibration feature with respect to the sensory reference frame as a third configuration data record; j) applying coordinate transformations to the initial and secondary configuration data records, and to the third configuration data record if required, to generate a correct tool control frame (TCF) pose with respect to the CRF. 2. A method as defined in claim 1, wherein steps c) through j) are repeated to develop a statistical average of data representing a more accurate definition of pose for the TCF. 3. A method as defined in claim 1, wherein step a) comprises the more specific step of attaching a vision sensory tooling assembly including a camera to a link of the robot in rigid body relationship, which link has a known positional and orientational relationship with respect to the CRF and which allows for feedback of positional and/or orientational information with respect to a sensory reference frame associated with the sensory tooling assembly, which sensory reference frame is physically located in a focal plane of the camera. 4. A method as defined in claim 3, wherein the TCF calibration is accomplished by the following steps: a) placing a calibration plate having a calibration dot in sensing range of the camera, b) adjusting the camera to a near normal orientation with respect to the calibration plate, c) moving the robot arm to a position such that the calibration dot will appear near a center portion of a vision window of the camera, comprising the initial configuration, d) activating the vision assembly to take a picture of the calibration dot and processing the image to record dot coordinates in sensory reference frame, e) recording current robot configuration as a set of joint angles or homogeneous transformation relating link joint frame to robot base frame, f) moving the robot along a direction and retaining the dot in the vision window, representing the secondary configuration, the image, recording dot coordinates in the sensory frame, h) recording current robot configuration as a set of joint angles or homogeneous transformation relating link frame to robot base frame, i) moving the robot to a third configuration if necessary wherein dot coordinates are in the sensory reference frame to obtain a new orientation and recording current robot configuration, and j) applying transformations to collected data to determine TCF calibration. 5. A method as defined in claim 4, wherein the step of calibrating the sensory tooling assembly comprises the steps of determining the aspect ratio and size of each pixel dot of the camera to define the correct physical dimensions represented by data output from the sensory tooling assembly. 6. A method as defined in claim 5, further comprising the more specific steps of: a) developing initial calibration for the pixel aspect ratio and pixel sizes using a circular calibration dot with known diameter; b) recording the initial calibration to update vision system pixel parameters within a workcell database; c) processing automatic vision camera TCF calibration using initial pixel calibration to initially calibrate the vision camera TCF; d) repeatedly moving the vision camera around the calibration dot whose parameters have been recorded in the workcell data base with a unique offset angle to build up new statistical calibration data for a precise pixel calibration; e) statistically averaging the new calibration data and updating the vision system with new pixel parameters based on the new calibration data; and f) conducting automatic vision camera TCF calibration with the new calibrated pixel parameters. 7. A method as defined in claim 1, wherein the steps of the invention include locating the TCF such that it can be superimposed over the target frame when an end effector is applied at the feature or part to be operated on. 8. A method as defined in claim 1, wherein the steps of the invention include locating the TCF at a point of action including a tip of an axisymmetric vacuum gripper. 9. A method as defined in claim 1, wherein the steps of the invention include locating the TCF at a point of action including a tip of an axisymmetric touch probe. 10. A method as defined in claim 1, wherein the steps of the invention include locating the TCF at an intermediate point of symmetry in association with a finger gripper. 