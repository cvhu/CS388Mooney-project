A data processing system and method for solving pattern classification problems and function-fitting problems includes a neural network in which N-dimensional input vectors are augmented with at least one element to form an N+j-dimensional projected input vector, whose magnitude is then preferably normalized to lie on the surface of a hypersphere. Weight vectors of at least a lowest intermediate layer of network nodes are preferably also constrained to lie on the N+j-dimensional surface. To train the network, the system compares network output values with known goal vectors, and an error function (which depends on all weights and threshold values of the intermediate and output nodes) is then minimized. In order to decrease the network's learning time even further, the weight vectors for the intermediate nodes are initially preferably set equal to known prototypes for the various classes of input vectors. Furthermore, the invention also allows separation of the network into sub-networks, which are then trained individually and later recombined. The network is able to use both hyperspheres and hyperplanes to form decision boundaries, and, indeed, can converge to the one even if it initially assumes the other.
Claims We claim: 1. A data processing system comprising: a) input means for representing each of a series of input data groups as a sequence of N numerical values to form corresponding N-dimensional base input vector, and for storing each base input vector; b) neural network means including: i) input layer storage means, intermediate layer storage means and output layer storage means; ii) said input layer storage means comprising xat least N+j projected input memory units, where j is a predetermined positive integer, for storing a normalized projected input vector having N+j numerical elements, with each projected input vector corresponding to one of the base input vectors; iii) said intermediate layer storage means comprising a plurality of intermediate memory units for storing predetermined intermediate threshold values and intermediate weight vectors; iii) said intermediate layer storage means comprising a plurality of intermediate memory units for storing hidden node network values; iv) said output layer storage means comprising a network output node for storing a network output value; v) connection means for connecting each projected input memory unit with predetermined ones of the intermediate memory units and for connecting the output node with predetermined ones of intermediate memory units; c) processor and control means; i) for augmenting each N-dimensional base input vector with j projection elements to form said projected input vector; ii) for computing an intermediate threshold value and an intermediate weight vector, with each weight vector having N+j weight elements, for each intermediate memory unit in a lowest intermediate layer; and iii) for computing an output value as a predetermined function of the intermediate weight vectors, the intermediate thresholds values and the projected input vectors; d) connection means; i) for connecting the input means to the processor and control means; ii) for connecting the input means to the neural network means; and iii) for connecting the neural network means to the processor and control means. 2. A system as defined in claim 1, in which the processor and control means is further provided for normalizing the elements of the projected input vector so that the magnitude of the projected input vector is equal to a predetermined input normalization value; and for normalizing the elements of the intermediate weight vectors so that the magnitude of each intermediate weight vector is equal to a predetermined weight normalization value. 3. A system as defined in claim 2, including N+j weight elements for each weight vector in the lowest layer of intermediate layer storage means in the neural network means. 4. A system according to claim 1, wherein said network output value is recursively compared to a predetermined goal vector, further including: comparison means for comparing the network output value with predetermined goal vectors; and in which the processor and control means is further provided for recomputing the intermediate threshold values and intermediate weight vectors until the network output values differ by less than a predetermined minimum threshold amount from the corresponding goal vectors. 5. A system as defined in claim 1 which further includes a plurality of output nodes, in which the processor and control means is further provided for computing an output threshold value and an output weight vector for each output node and in which the processor and control means is further provided for recomputing the intermediate and output threshold values and intermediate and output weight vectors until the network output values differ by less than the predetermined minimum threshold from the corresponding goal vectors. 6. A system as defined in claim 1, in which the input means includes pattern resolution means for representing an input pattern, each input pattern representing one of the input data groups, as the sequence of N numerical values. 7. A system as defined in claim 1, in which the input means includes means for inputting N input variable values and data compilation means for combining said N input variable values into one of the input data groups. 8. A system as defined in claim 1, in which: a) the intermediate layer storage means includes intermediate storage units for each of a plurality of intermediate storage layers; b) said plurality of intermediate storage layers includes the lowest intermediate layer and higher layers connected by the connection means between the lowest layer and the output layer storage means; and c) each intermediate memory unit has a corresponding intermediate weight vector and intermediate threshold value. 9. A system as defined in claim 8, in which the processor and control means is further provided for projecting the weight vectors in predetermined ones of the intermediate layers by augmenting these weight vectors with at least one projection value, and for normalizing these weight vectors. 10. A data processing method including the steps: a) in an input processor, converting each of a series of input data groups into a sequence of N numerical values to form a corresponding N-dimensional base input vector and storing each N-dimensional base input vector in an input memory device; b) in a projection unit, augmenting each N-dimensional base input vector with j projection elements to form a projected input vector having N+j projected input elements, where j is a predetermined positive integer, and storing each projected input vector in projection memory device; c) in a normalization circuit, normalizing the elements of the projected input vector so that the magnitude of the projected input vector is equal to a predetermined input normalization value, and storing each resulting normalized projection input vector in a normalization projection memory device; d) in at least one intermediate node processor, for each of a plurality of intermediate nodes in a lowest intermediate layer: i) forming a weight vector having N+j weight elements; ii) constraining the magnitude of the weight vector to be equal to a predetermined weight normalization value; and iii) forming an intermediate nodal value as a weighted sum of the N+j input projection elements; iv) storing the weighted sum in a weighted sum memory device; and e) forming an output node value as a predetermined weight function of the intermediate nodal values, and storing the output node value in an output node memory device. 11. A method as defined in claim 10, in which: the input vectors are 2-dimensional, representing vectors in a plane; the projected input vectors are 3-dimensional and represent vectors extending from the center of a sphere to the surface of the sphere; and the closed decision groups each correspond to closed regions on the surface of the sphere. 12. A method as defined in claim 10, in which j=1. 13. A system as defined in claim 10, in which the weight normalization value is equal to the input normalization value. 14. A method as defined in claim 13, in which the weight normalization value and input normalization value are constants. 15. A method as defined in claim 11, further including the following steps: a) selecting a training set of known training vectors and a corresponding set of known goal vectors; b) generating an initial set of the N+j-dimensional weight vectors; c) for each intermediate node, selecting an initial intermediate threshold value; d) sequentially setting the base input vector equal to the training vectors; e) in a plurality of processors, computing an error function value as a predetermined error function of the projected input training vectors, each of the weight vectors, and each of the threshold values; and f) in a plurality processors, adjusting the threshold values and the weight elements of each weight vector and repeating steps d) and e) until the error function value is less than a predetermined minimum error value. 16. A method as defined in claim 15, in which the threshold values and the weight vectors are adjusted in a plurality of processor as follows: for each set of threshold values and weight vectors for which the error function exceeds the minimum error value, optimizing the threshold values and weight vectors according to the following steps: a) recomputing the threshold values and weight vectors according to a predetermined minimization routine; b) adjusting the recomputed weight vectors so that the magnitude of each weight vector is equal to the predetermined weight normalization value; and c) sequentially reapplying the projected input training vectors as the projected input vectors. 17. A method as defined in claim 15, in which the initial weight vectors are set equal to predetermined N+j-dimensional prototype vectors, whereby each prototype vector corresponds to a respective one of the known training vectors. 18. A method as defined in claim 10, in which the input data groups consist of input patterns in a plurality of classes, further including the step of providing an output signal for each class corresponding to a probability that a current input pattern is in the corresponding class; whereby, increasing the complexity of the input vectors from dimension N to dimension at least N+j and normalizing both the weight vectors and the input vectors defines closed decision groups of possible output values using a single N+j-dimensional boundary region for each decision group. 19. A method as defined in claim 18, further including the following steps: a) separating the weight vectors into pattern weight groups, with each pattern weight group corresponding to one of the input patterns; and b) separately optimizing each pattern weight group. 20. A method as defined in claim 18, in which each decision boundary is a hyperplane when the corresponding intermediate threshold value is given an extreme value, and a hypersphere when the corresponding intermediate threshold value differs from the extreme value. 21. A method as defined in claim 10, in which the input data groups consist of sets of N input signals, corresponding to N input variables defining a K-dimensional output function, further including the step of providing at least K output nodal values for representing a current value of the output function; whereby, increasing the complexity of the input vectors from dimension N to dimension at least N+j and normalizing both the weight vectors and the input vectors defines closed decision groups of possible output values using a single at least N+j dimensional boundary region for each decision group. 22. A method as defined in claim 10, further including the step of providing a plurality of intermediate layers, including the lowest intermediate layer and an uppermost intermediate layer, each having a plurality of intermediate nodes, each intermediate node having a corresponding intermediate nodal value, a corresponding intermediate weight vector and a corresponding intermediate threshold value. 23. A system as defined in claim 10, further including the step of transforming the intermediate nodal values using a transformation function, whereby each intermediate nodal value is represented as a smoothly interpolated transformed intermediate value constrained to lie between a finite maximum value and a finite minimum value. 24. A system as defined in claim 23, further including the step of computing an output weight vector for each output node, and for determining the value of each output node as a predetermined function of the weighted and biassed sums of the uppermost intermediate nodal values. 25. A method as defined in claim 10, in which the steps of the method are performed utilizing the input processing circuit, projection unit, normalization circuit, and intermediate node processor which are included in a single processing unit. 26. A method as defined in claim 10, in which the steps of the method are performed utilizing the input memory device, projection memory device, normalized projection memory device, weighted sum memory device, and output node memory device which are included in a single memory unit. 27. A method for identifying and classifying patterns, including the following steps: a) in an input processing circuit, representing each of a series of input data groups as a sequence of N numerical values to form a corresponding N-dimensional base input vector, each input data group consisting of input patterns in a plurality of classes, and each N-dimensional base input vector stored in an input memory device; b) in a projection unit, augmenting each N-dimensional base input vector with j projection elements to form a projected input vector having N+j projected input elements, where j is a predetermined positive integer, and storing each projected input vector in a projection memory device; c) in a normalization circuit, normalizing the elements of the projected input vector so that the magnitude of the projected input vector is equal to a predetermined normalization value, and storing each resulting normalized projection input vector in a normalized projection memory unit; d) for each of a plurality of intermediate nodes: i) forming a weight vector having N+j weight elements and storing them in a plurality of weight vector memory units; ii) constraining the magnitude of the weight vector to be equal to the normalization value; iii) forming an intermediate nodal value as a weighted sum of the N+j input projection elements; iv) storing the weighted sum in a weighted sum memory device; e) forming an output node value as a predetermined weight function of the intermediate nodal values, and storing the output node value in an output node memory device, and further including the step of providing an output signal for each class corresponding to a probability that a current input pattern is in the corresponding class; further including, in a training mode, the following steps: f) selecting a training set of known training vectors and a corresponding set of known goal vectors; g) in a weight vector processing circuit, generating an initial set of the N+j-dimensional weight vectors; h) for each intermediate node, selecting an initial intermediate threshold value; i) sequentially setting the base input vector equal to the training vectors; j) in an error function processing circuit, computing an error function value as a predetermined error function of the projected input training vectors, each of the weight vectors, and each of the threshold values; and k) adjusting the intermediate threshold values and the weight elements of each weight vector as follows, and thereafter repeating steps I) and J) until the error function value is less than a predetermined minimum error value: in an optimization processing unit, for each set of intermediate threshold values and weight vectors for which the error function exceeds the minimum error value, optimizing the intermediate threshold values and weight vectors according to the following steps: i) recomputing the intermediate threshold values and weight vectors according to a predetermined minimization routine; ii) adjusting the recomputed weight vectors so that the magnitude of each weight vector is equal to the normalization value; and iii) sequentially reapplying the projected input training vectors as the projected input vectors; whereby, increasing the complexity of the input vectors from dimension N to dimension N+j and normalizing both the weight vectors and the input vectors defines a plurality of closed decision groups of possible output values using a single N+j dimensional boundary region for each decision group. 28. A method as defined in claim 27, in which the initial weight vectors are set equal to predetermined N+j-dimensional prototype vectors, whereby each prototype vector corresponds to a respective one of the known training vectors. 29. A method as defined in claim 27, further including the following steps: a) separating the weight vectors and thresholds into pattern weight/threshold groups, with each pattern weight/threshold group corresponding to one of the input pattern classes; and b) separately optimizing each pattern weight/threshold group. 30. A method as defined in claim 27, in which the steps of the method are performed utilizing the input processing circuit, projection unit, normalization circuit, intermediate node processor, weight vector processing circuit, error function processing circuit, and optimization processing unit which are included in a single processing unit. 31. A method as defined in claim 27, in which the steps of the method are performed utilizing the input memory device, projection memory device, normalized projection memory device, weight vector memory units, weighted sum memory device, and output node memory device which are included in a single processing unit. 32. A data processing method including the steps: a) in an input processor, converting each of a series of input data groups into a sequence of N numerical values to form a corresponding N-dimensional base input vector and storing each N-dimensional base input vector in an input memory device; b) in a projection unit, augmenting each N-dimensional base input vector with j projection elements to form a projected input vector having N+j projected input element, where j is a predetermined positive integer, and storing each projected input vector in projection memory device; c) in a normalization circuit, normalizing the elements of the projected input vector so that the magnitude of the projected input vector is equal to a predetermined input normalization value, and storing each resulting normalized projection input vector in a normalization projection memory device; d) in at least one intermediate node processor, for each of a plurality of intermediate nodes in a lowest intermediate layer, chosen among a plurality of sequential, intermediate nodal layers; i) forming a weight vector having N+j weight elements; ii) constraining the magnitude of the weight vector to be equal to a predetermined weight normalization value; and iii) forming an intermediate nodal value as a weighted sum of the N+j input projection elements; iv) storing the weighted sum in a weighted sum memory device; e) for each of the plurality of intermediate nodes in each of the plurality of sequential, intermediate nodal layers other than the lowest intermediate nodal layer; i) forming a threshold value and forming a weight vector having at least N+p weight elements, where p is the number of nodes in the immediately preceding lower intermediate nodal layer; and ii) forming an intermediate nodal output value as a weighted sum of the intermediate nodal values of the preceding, lower nodal layer; f) for each intermediate nodal layer pre-chosen as a projection layer, constraining the magnitude of the corresponding weight vectors to be equal to a predetermined corresponding weight normalization value; and g) for each output node in an output layer, forming an output weight vector and forming an output node value as a predetermined weight function of the intermediate nodal values, and storing the output node value in an output node. 33. A method as defined in claim 32, in which j=1. 34. A system as defined in claim 32, in which the weight normalization value is equal to the input normalization value. 35. A method as defined in claim 34, in which the weight normalization value and input normalization value are constants. 36. A method as defined in claim 32, further including the following steps: a) selecting a training set of known training vectors and a corresponding set of known goal vectors; b) generating an initial set of weight vectors; c) for each intermediate node, selecting an initial intermediate threshold value; d) sequentially setting the base input vector equal to the training vectors; e) computing an error function value as a predetermined error function of the projected input training vectors, each of the weight vectors, and each of the threshold values; and f) adjusting the threshold values and the weight elements of each weight vector and repeating steps d) and e) until the error function value is less than a predetermined minimum error value. 37. A method as defined in claim 36, in which the threshold values and the weight vectors are adjusted as follows: for each set of threshold values and weight vectors for which set the error function exceeds the minimum error value, optimizing the threshold values and weight vectors according to the following steps: i) recomputing the threshold values and weight vectors according to a predetermined minimization routine; ii) adjusting the recomputed weight vectors so that the magnitude of each weight vector is equal to the predetermined weight normalization value; and iii) sequentially reapplying the projected input training vectors as the projected input vectors. 38. A method as defined in claim 36, in which the initial weight vectors are set equal to predetermined prototype vectors, whereby each prototype vector corresponds to a sampling based on the known training vectors. 39. A method as defined in claim 32, in which the input data groups consist of input patterns in a plurality of classes, further including the step of providing an output signal for each class corresponding to a probability that a current input pattern is in the corresponding class; whereby, increasing the complexity of the input vectors from dimension N to dimension at least N+j and normalizing both the weight vectors and the input vectors defines closed decision groups of possible output values using a single N+j-dimensional boundary region for each decision group. 40. A method as defined in claim 35, further including the following steps: a) separating the weight vectors and thresholds into pattern weight/threshold groups, with each pattern weight/threshold group corresponding to one of the input pattern classes; and b) separately optimizing each pattern weight group. 41. A method as defined in claim 39, in which each decision boundary is a hyperplane when the corresponding intermediate threshold value is set to a hyperplane value, and a hypersphere when the corresponding intermediate threshold value differs from the hyperplane value. 42. A method as defined in claim 32, in which the input data groups consist of sets of input signals, corresponding to N input variables defining a K-dimensional output function, further including the step of providing at least K output nodal values for representing a current value of the output function; whereby, increasing the complexity of the input vectors from dimension N to dimension at least N+j and normalizing both the weight vectors and the input vectors defines closed decision groups of possible output values using a single at least N+j dimensional boundary region for each decision group. 43. A system as defined in claim 32, further including the step of transforming the intermediate nodal values using a transformation function, whereby each intermediate nodal value is represented as a smoothly interpolated transformed intermediate value constrained to lie between a finite maximum value and a finite minimum value. 44. A method as defined in claim 36, in which the steps of the method are performed utilizing the input processing circuit, projection unit, normalization circuit, and intermediate node processor which are included in a single processing unit. 45. A method as defined in claim 36, in which the steps of the method are performed utilizing the input memory device, projection memory device, normalized projection memory device, weighted sum memory device, and output node memory unit which are included in a single memory unit. 46. A data processing system comprising: a) input means for representing each of a series of input data groups as a sequence of N numerical values to form a corresponding N-dimensional base input vector; b) memory means; c) means for storing N+j projected inputs; d) neural network means including: i) input layer storage means, intermediate layer storage means and output layer storage means; ii) said input layer storage means comprising at least N+j projected input memory units, where j is a predetermined positive integer, for storing a normalized projected input vector having N+j numerical elements, with each projected input vector corresponding to one of the base input vectors; iii) said intermediate layer storage means comprising a plurality of intermediate memory units for storing intermediate threshold values and intermediate weight vectors; iv) said output layer storage means comprising a network output node for storing a network output value; v) connection means for connecting each projected input memory unit with predetermined ones of the intermediate memory units and for connecting the output node with predetermined ones of intermediate memory units; e) processor and control means i) for augmenting each N-dimensional base input vector with j projection elements to form said projected input vector; ii) for computing an intermediate threshold value and an intermediate weight vector, with each weight vector having N+j weight elements for each intermediate memory unit in a lowest intermediate layer; and iii) for computing an output value as a predetermined function of the intermediate weight vectors, the intermediate threshold values and the projected input vectors; f) connection means for connecting said processor and control means to (i) said input means, (ii) said digital memory means, and, (iii) said neural network means. 