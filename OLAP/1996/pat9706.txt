Method and apparatus are disclosed for determining the position and attitude of objects, together with robotic systems employing same, and methods of targeting objects for such purposes. Particularly of interest is the application to continuous conveyors, particularly in the process of automobile manufacture. Also disclosed is the use of naturally occuring object features as targets in a machine vision based robot (or other) guidance system. In one embodiment, a special high speed processor finds at least 3 preselected feature points on an object, which when considered with the data base for the object, allows a rapid 6 degree of freedom solution for the object location relative to the camera and thence connected automation. While primarily envisioned for industrial robots, the invention is useful for all sorts of machines including vehicles, construction machinery and the like--anywhere the target object has a known data base relative to the features in question.
Claims I claim: 1. A method of assembling a first object to a second object comprising the steps of: providing a robot arm with a plurality of sensors mounted thereon; associating the first object with the robot arm for manipulation thereby; electro-optically sensing the location of a plurality of known references points on one of the first and second objects using a respective one of the plurality of sensors for each reference point; determining the location of the robot arm relative to the one of the objects using the sensed locations of the reference points; moving the robot arm to precisely position the first object relative to the second object; and assembling the first object to the second object while the first object is precisely positioned relative to the second object by the robot arm. 2. A method of assembling as claimed in claim 1 wherein said sensing step includes the steps of electro-optically sensing the location of a plurality of known references points on the first object using a respective sensor for each reference point which sensors are mounted on a robot arm and determining the location of the first object relative to the robot arm using the sensed locations of the reference points. 3. A method of assembling as claimed in claim 2 wherein said sensing step further includes, after sensing of the location of the first object, the steps of initially moving the first object with the robot arm adjacent the second object and then electrooptically sensing the position of a plurality of known references points of the second object relative to the robot arm using the respective sensors on the robot arm. 4. A method of assembling as claimed in claim 2 and further comprising the step of initially attaching the first object to the robot arm before the sensing and the determining step. 5. A method of assembling as claimed in claim 2 and further comprising the step of attaching the first object to the robot arm after the sensing and the determining step. 6. A method of assembling as claimed in claim 2 wherein the sensing step includes the sensing of designated targets on the first object selected from specially applied targets, natural features of the object and holes in the object. 7. A method of assembling as claimed in claim 1 wherein said sensing step includes the steps of initially moving the first object with the robot arm adjacent the second object and then electro-optically sensing the position of a plurality of known references points of the second object relative to the robot arm using the respective sensors on the robot arm. 8. A method of assembling as claimed in claim 1 wherein the sensing step includes the sensing of designated targets on one of the first and second objects selected from specially applied targets, natural features of the objects and holes in the objects. 9. A method of assembling as claimed in claim 1 wherein said moving step includes the steps of: illuminating a portion of the second object with light, detecting the light reflected from the portion with one of the sensors mounted on the robot arm, and determining a distance of the first object from the second object by triangulation using the detected light. 